{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56c60e9-fe84-4d03-bf05-0bd36c08e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain chromadb ctransformers transformers sentence_transformers\n",
    "# Apple silicon:\n",
    "# !pip uninstall ctransformers\n",
    "# !CT_METAL=1 pip install ctransformers --no-binary ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d3155f-1e4b-4f01-9056-05e2be6aaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "SNAPSHOTS_DIR = DATA_DIR / \"platform-docs-snapshots\"\n",
    "VERSIONS_DIR = DATA_DIR / \"platform-docs-versions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece42cd-9d32-4eda-99a6-984393c105aa",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7370951-a3d5-408f-961f-03b88d3e94a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"How to get the number of likes of a TikTok post. I'd like an example query and an explanation of the parameters used.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import get_training_data\n",
    "\n",
    "train_queries, train_answers, train_context = get_training_data()\n",
    "\n",
    "query = [train_queries[-3]]\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "febb8e8b-c1aa-4bb1-9230-2a5ddf97dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader, DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "docs = DirectoryLoader(VERSIONS_DIR, glob=\"[!.]*/[!.]*.md\", loader_cls=TextLoader).load()\n",
    "docs = [d for d in docs if Path(d.metadata['source']) != VERSIONS_DIR / \"README.md\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aab2336-8f05-4e14-8fe8-57634f7a564e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'en': 131, 'fr': 8})\n"
     ]
    }
   ],
   "source": [
    "import langdetect\n",
    "from collections import Counter\n",
    "\n",
    "languages = [langdetect.detect(d.page_content) for d in docs]\n",
    "\n",
    "for doc, language in zip(docs, languages):\n",
    "    doc.metadata[\"language\"] = language\n",
    "\n",
    "print(Counter(languages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c9a46-5ede-4176-84e4-bec90ca1a186",
   "metadata": {},
   "source": [
    "# Load Retriever, build index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc18b8c5-1fb3-4ab1-bf6a-be3a0a1f690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index from .ragatouille/colbert/indexes/DSA...\n",
      "[Feb 02, 10:33:22] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelco/.pyenv/versions/3.10.13/envs/rag/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from retrievers.chroma_dpr import ChromaRetriever\n",
    "from retrievers.colbert import ColbertRetriever\n",
    "import re\n",
    "\n",
    "retriever = ColbertRetriever()\n",
    "collection_name = \"DSA\"\n",
    "retriever.build(docs, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815650d9-38b6-4792-9c77-4f0230755f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index DSA for the first time... This may take a few seconds\n",
      "[Feb 02, 10:33:26] #> Loading codec...\n",
      "[Feb 02, 10:33:26] #> Loading IVF...\n",
      "[Feb 02, 10:33:26] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Feb 02, 10:33:26] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2193.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 02, 10:33:26] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 56.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 02, 10:33:26] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 02, 10:33:26] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelco/.pyenv/versions/3.10.13/envs/rag/lib/python3.10/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . How do I get activity logs from the Twitter API?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2129,  2079,  1045,  2131,  4023, 15664,  2013,  1996,\n",
      "        10474, 17928,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 107.98it/s]\n"
     ]
    }
   ],
   "source": [
    "results = retriever.query(\n",
    "    query=[\"How do I get activity logs from the Twitter API?\"],\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dfa1f7-f746-475c-9a88-6d86a6c31b35",
   "metadata": {},
   "source": [
    "# Load Generator\n",
    "\n",
    "### Quantized Mistral 7B, finetuned on code instructions\n",
    "- https://huggingface.co/TheBloke/OpenHermes-2.5-Mistral-7B-16k-GGUF#provided-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9beb64f0-baab-4759-b1f1-19205dbbad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def print_chat(chat_log):\n",
    "    for entry in chat_log:\n",
    "        if entry['role'] != 'system':\n",
    "            display(Markdown(f\"**{entry['role'].capitalize()}:** \\n{entry['content']}\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9670d536-80c1-47f6-b478-5821d93ad8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66346cf3d5434aeca1dbc6274a7f292f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923ae5fbc78d47c089c38df05f06f49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from generators.mistral import MistralRAGGenerator\n",
    "\n",
    "rag_generator = MistralRAGGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3398395-f6c3-4c86-8d3d-1d63f011ea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 136.74it/s]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "results = retriever.query(query, k)\n",
    "\n",
    "context = [r['content'] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a82a9d9-7fec-46f6-8f3f-c9f1fa182841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a762913e534aa4b9587b73fa786254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_logs = rag_generator.generate_batch(context, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0889d9b-3cbd-4059-9a52-400b99a79907",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_chat(chat_logs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916457b-c3d5-4e14-9855-0408049b65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluation\n",
    "\n",
    "answer = [c[-1][\"content\"] for c in chat_logs]\n",
    "\n",
    "for q, a in zip(query, answer):\n",
    "    print(\"Q:\", q)\n",
    "    print(\"A\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d11f19-2400-4efc-87d6-43aaabb4f58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
