{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56c60e9-fe84-4d03-bf05-0bd36c08e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain chromadb ctransformers transformers sentence_transformers\n",
    "# Apple silicon:\n",
    "# !pip uninstall ctransformers\n",
    "# !CT_METAL=1 pip install ctransformers --no-binary ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d3155f-1e4b-4f01-9056-05e2be6aaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "SNAPSHOTS_DIR = DATA_DIR / \"platform-docs-snapshots\"\n",
    "VERSIONS_DIR = DATA_DIR / \"platform-docs-versions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece42cd-9d32-4eda-99a6-984393c105aa",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7370951-a3d5-408f-961f-03b88d3e94a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_training_data\n",
    "\n",
    "train_queries, train_answers, train_context = get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4250af91-c680-4560-a15e-fb04ea5c8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translation import Translator\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "train_queries_translated = [translator.translate(q, 'en') for q in train_queries]\n",
    "train_queries, source_languages = zip(*train_queries_translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febb8e8b-c1aa-4bb1-9230-2a5ddf97dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader, DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "docs = DirectoryLoader(VERSIONS_DIR, glob=\"[!.]*/[!.]*.md\", loader_cls=TextLoader).load()\n",
    "docs = [d for d in docs if Path(d.metadata['source']) != VERSIONS_DIR / \"README.md\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aab2336-8f05-4e14-8fe8-57634f7a564e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'en': 131, 'fr': 8})\n"
     ]
    }
   ],
   "source": [
    "import langdetect\n",
    "from collections import Counter\n",
    "\n",
    "languages = [langdetect.detect(d.page_content) for d in docs]\n",
    "\n",
    "for doc, language in zip(docs, languages):\n",
    "    doc.metadata[\"language\"] = language\n",
    "\n",
    "print(Counter(languages))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c9a46-5ede-4176-84e4-bec90ca1a186",
   "metadata": {},
   "source": [
    "# Load Retriever, build index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc18b8c5-1fb3-4ab1-bf6a-be3a0a1f690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index from .ragatouille/colbert/indexes/DSA...\n"
     ]
    }
   ],
   "source": [
    "from retrievers.chroma_dpr import ChromaRetriever\n",
    "from retrievers.colbert import ColbertRetriever\n",
    "import re\n",
    "\n",
    "retriever = ColbertRetriever()\n",
    "collection_name = \"DSA\"\n",
    "retriever.build(docs, collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dfa1f7-f746-475c-9a88-6d86a6c31b35",
   "metadata": {},
   "source": [
    "# Load Generator\n",
    "\n",
    "### Quantized Mistral 7B, finetuned on code instructions\n",
    "- https://huggingface.co/TheBloke/OpenHermes-2.5-Mistral-7B-16k-GGUF#provided-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9beb64f0-baab-4759-b1f1-19205dbbad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def print_chat(chat_log):\n",
    "    for entry in chat_log:\n",
    "        if entry['role'] != 'system':\n",
    "            display(Markdown(f\"**{entry['role'].capitalize()}:** \\n{entry['content']}\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9670d536-80c1-47f6-b478-5821d93ad8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3cf6df32b44e7fa94d16a344187308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9b3ee5cd874242999ea656c74fed3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from generators.mistral import MistralRAGGenerator\n",
    "\n",
    "rag_generator = MistralRAGGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3398395-f6c3-4c86-8d3d-1d63f011ea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index DSA for the first time... This may take a few seconds\n",
      "[Feb 02, 13:15:04] #> Loading codec...\n",
      "[Feb 02, 13:15:04] #> Loading IVF...\n",
      "[Feb 02, 13:15:04] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelco/.pyenv/versions/3.10.13/envs/rag/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 02, 13:15:04] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2661.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 02, 13:15:04] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 56.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 02, 13:15:04] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 02, 13:15:04] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . I am writing a curl request. This request is intended to enable me to obtain from Facebook the political advertisements containing the word 'europe' which have reached France and Belgium. The answer must contain only the curl request code., \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1045,  2572,  3015,  1037, 15390,  5227,  1012,  2023,\n",
      "         5227,  2003,  3832,  2000,  9585,  2033,  2000,  6855,  2013,  9130,\n",
      "         1996,  2576, 14389,  4820,  1996,  2773,  1005,  2885,  1005,  2029,\n",
      "         2031,   102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelco/.pyenv/versions/3.10.13/envs/rag/lib/python3.10/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "1it [00:00, 110.58it/s]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "queries = train_queries[:1]\n",
    "source_languages = source_languages[:1]\n",
    "\n",
    "results = retriever.query(queries, k)\n",
    "\n",
    "context = [r['content'] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a82a9d9-7fec-46f6-8f3f-c9f1fa182841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13618eb94a1b4d40961edc490cea9dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_logs = rag_generator.generate_batch(context, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6cb1a43-5b7f-4676-820f-8728d7903d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [c[-1][\"content\"] for c in chat_logs]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "500e37c9-6b26-472f-a69a-c3b936c1558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [translator.translate(ans, lang)[0] for ans, lang in zip(answers, source_languages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0889d9b-3cbd-4059-9a52-400b99a79907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a916457b-c3d5-4e14-9855-0408049b65b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: I am writing a curl request. This request is intended to enable me to obtain from Facebook the political advertisements containing the word 'europe' which have reached France and Belgium. The answer must contain only the curl request code.\n",
      "A Pour obtenir une liste des annonces politiques sur Facebook qui contiennent le mot « Europe » et qui ont atteint tant la France que la Belgique, vous pouvez utiliser le commandement curl suivant :\n",
      "` `battre\n",
      "curl -X GET -G 'https://graph.facebook.com/v13.0/act_<AD_ACCOUNT_ID>/adsinsights?fields=name,adtype,reach_locations&location=FR-fr,BE-nl,location_search_text=europe' --header \"Access_Token: <ACCESS_TOKEN\"\n",
      "` ` ` ` ` ` ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́ ́\n",
      "Remplacez `<AD_ACCOUNT_ID>` par l'ID du compte d'affichage et `<ACCESS_TOKEN>` par votre token d'accès Facebook. Assurez-vous que vous êtes autorisé à consulter les Permis de lecture d'Ads Insights dans vos paramètres de cote.<\n"
     ]
    }
   ],
   "source": [
    "# For evaluation\n",
    "\n",
    "for q, a in zip(queries, answers):\n",
    "    print(\"Q:\", q)\n",
    "    print(\"A\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d11f19-2400-4efc-87d6-43aaabb4f58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
