{
    "0": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/overview\n\nContent: \n# Resource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/overview\nOverview  \n**Please note:**  \nWe have released a new version of [search Tweets](https://developer.twitter.com/en/docs/twitter-api/tweets/search)\u00a0and [Tweet counts](https://developer.twitter.com/en/docs/twitter-api/tweets/counts) in [Twitter API v2](https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api). While we have not announced a deprecation timeline for this API yet, we do encourage you to start to experiment and [review what's new](https://developer.twitter.com/en/docs/twitter-api/migrate) with Twitter API v2.  \nThese endpoints have been updated to include Tweet edit metadata. Learn more about these metadata on the [\"Edit Tweets\" fundamentals page](https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets).\n",
        "line_start": 0,
        "line_end": 5
    },
    "1": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/overview\n\tOverview\n\nContent: \n## Overview  \nEnterprise  \n_The enterprise APIs are available within our managed access levels only. To use these APIs, you must first set up an account with our enterprise sales team. To learn more see\u00a0[HERE](https://developer.twitter.com/content/developer-twitter/en/enterprise)._  \n_You can view all of the Twitter API search Tweet offerings [HERE](https://developer.twitter.com/en/docs/twitter-api/search-overview)._  \nThere are two enterprise search APIs:  \n1. 30-Day Search API provides data from the previous 30 days.\n2. Full-Archive Search API provides complete and instant access to the full corpus of Twitter data dating all the way back to the first Tweet in March 2006.  \nThese RESTful APIs supports a single query of up to 2,048 characters per request. Queries are written with the PowerTrack rule syntax - see\u00a0[Rules and filtering](https://developer.twitter.com/en/docs/twitter-api/enterprise/rules-and-filtering/building-a-rule)\u00a0for more details. Users can specify any time period, to the granularity of a minute. However, responses will be limited to the lesser of your specified maxResults OR 31 days and include a next token to paginate for the next set of results. If time parameters are not specified, the API will return matching data from the 30 most recent days.  \nThe enterprise search APIs provide low-latency, full-fidelity, query-based access to the Tweet archive with minute granularity. Tweet data is served in reverse chronological order, starting with the most recent Tweet that matches your query. Tweets are available from the search API approximately 30 seconds after being published.  \nThese search endpoints provide edited Tweet metadata. All objects for Tweets created since September 29, 2022, include Tweet edit metadata, even if the Tweet was never edited. Each time a Tweet is edited, a new Tweet ID is created. A Tweet's edit history is documented by an array of Tweet IDs, starting with the original ID.  \nThese endpoints will always return the most recent edit, along with any edit history. Any Tweet collected after its 30-minute edit window will represent its final version. To learn more about Edit Tweet metadata, check out the [Edit Tweets fundamentals](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/edit-tweets) page.  \nRequests include a\u00a0maxResults\u00a0parameter that specifies the maximum number of Tweets to return per API response. If more Tweets are associated with the query than this maximum amount of results per response, a next token is included in the response. These\u00a0next\u00a0tokens are used in subsequent requests to page through the entire set of Tweets associated with the query.  \nThese enterprise search APIs provide a _counts_ endpoint that enables users to request the data volume associated with their query.\n",
        "line_start": 9,
        "line_end": 22
    },
    "2": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/overview\n\tOverview\n\tRequest types\n\nContent: \n### Request types  \nThe enterprise search APIs support two types of requests:  \n#### Search requests (data)  \nSearch requests to the enterprise search APIs allow you to retrieve up to 500 results per response for a given timeframe, with the ability to paginate for additional data. Using the maxResults parameter, you can specify smaller page sizes for display use cases (allowing your user to request more results as needed) or larger page sizes (up to 500) for larger data pulls. The data is delivered in reverse chronological order and compliant at the time of delivery.  \n#### Counts requests (Tweet count)  \nCounts requests provide the ability to retrieve historical activity counts, which reflect the number of activities that occurred which match a given query during the requested timeframe. The response will essentially provide you with a histogram of counts, bucketed by day, hour, or minute (the default bucket is\u00a0_hour_).\u00a0It's important to note that counts results do not always reflect compliance events (e.g., Tweets deletes) that happen well after (7+ days) a Tweet is published; therefore, it is expected that the counts metric may not always match that of a data request for the same query.  \n**Billing note:**\u00a0each request \u2013\u00a0_including pagination requests_\u00a0\u2013 made against the data and counts endpoints are counted as a billed request. Therefore, if there are multiple pages of results for a single query, paging through the X pages of results would equate to X requests for billing.\n",
        "line_start": 34,
        "line_end": 41
    },
    "3": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/overview\n\tOverview\n\tAvailable operators\n\nContent: \n### Available operators  \nEnterprise search APIs support rules with up to 2,048 characters. The enterprise search APIs support the operators listed below. For detailed descriptions see [HERE](https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/search-api/enterprise-operators).  \n|     |     |     |     |\n| --- | --- | --- | --- |\n| **Matching on Tweet contents:** | **Matching on accounts of interest:** | **Tweet attributes:** | **Geospatial operators:** |\n| * keyword<br>* \u201cquoted phrase\u201d<br>* \u201ckeyword1 keyword2\u201d~N<br>* #<br>* @<br>* $<br>* url:<br>* lang: | * from:<br>* to:<br>* retweets\\_of: | * is:retweet  <br>    <br>* has:mentions<br>* has:hashtags<br>* has:media<br>* has:videos<br>* has:images<br>* has:links<br>* has:symbols<br>* is:verified  <br>    <br>* \\-is:nullcast\u00a0(negation only operator) | * bounding\\_box:\\[west\\_long south\\_lat east\\_long north\\_lat\\]<br>* point\\_radius:\\[lon lat radius\\]<br>* has:geo<br>* place:<br>* place\\_country:<br>* has:profile\\_geo<br>* profile\\_country:<br>* profile\\_region:<br>* profile\\_locality: |  \nNotes: Do not embed/nest operators (\"#cats\") will resolve to cats with the search APIs.\u00a0 \u00a0The \u2018lang:\u2019 operator and all \u2018is:\u2019 and \u2018has:\u2019 operators cannot be used as standalone operators and must be combined with another clause (e.g. @twitterdev has:links).  \nSearch APIs use a limited set of operators due to tokenization/matching functionality. enterprise real-time and batched historical APIs provide additional operators. See [HERE](https://developer.twitter.com/en/docs/twitter-api/enterprise/rules-and-filtering/operators-by-product) for more details.  \nFor more details, please see the\u00a0[Getting started with operators](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/rules-and-filtering/building-a-rule)\u00a0guide.\n",
        "line_start": 48,
        "line_end": 57
    },
    "4": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/overview\n\tOverview\n\tData availability / important date\n\nContent: \n### Data availability / important date  \nWhen using the Full-Archive search API, keep in mind that the Twitter platform has continued to evolve since 2006. As new features were added, the underlying JSON objects have had new metadata added to it. For that reason it is important to understand when Tweet attributes were added that search operators match on. Below are some of the more fundamental 'born on' dates of important groups of metadata. To learn more about when Tweet attributes were first introduced, see\u00a0[this guide](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/search-api/guides/changelog).  \n* First Tweet: 3/21/2006\n* First Native Retweets: 11/6/2009\n* First Geo-tagged Tweets: 11/19/2009\n* URLs first indexed for filtering: 8/27/2011\n* Enhanced URL expansion metadata (website titles and descriptions): 12/1/2014\n* Profile Geo enrichment metadata and filtering: 2/17/2015\n",
        "line_start": 64,
        "line_end": 72
    },
    "5": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/overview\n\tOverview\n\tData Updates and Mutability\n\nContent: \n### Data Updates and Mutability  \nWith the enterprise search APIs, some of the data within a Tweet is mutable, i.e. can be updated or changed after initial archival.  \nThis mutable data falls into two categories:  \n* User object metadata:\n* User\u2019s @handle (numeric ID does not ever change)\n* Bio description\n* Counts: statuses, followers, friends, favorites, lists\n* Profile location\n* Other details such as time zone and language\n* Tweet statistics - i.e. anything that can be changed on the platform by user actions (examples below):\n* Favorites count\n* Retweet count  \nIn most of these cases, the search APIs will return data as it exists on the platform at _query-time_, rather than Tweet generation time. However, in the case of queries using select operators (e.g. from, to, @, is:verified), this may not be the case. Data is updated in our index on a regular basis, with an increased frequency for most recent timeframes. As a result, in some cases, the data returned may not exactly match the current data as displayed on Twitter.com, but matches data at the time it was last indexed.  \nNote, this issue of inconsistency only applies to queries where the operator applies to mutable data. One example is filtering for usernames, and the best workaround would be to use user numeric IDs rather than @handles for these queries.\n",
        "line_start": 75,
        "line_end": 89
    },
    "6": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/overview\n\tOverview\n\tSingle vs. Multi-threaded Requests\n\nContent: \n### Single vs. Multi-threaded Requests  \nEach customer has a defined rate limit for their search endpoint. The default per-minute rate limit for Full-Archive search is 120 requests per minute, for an average of 2 queries per second (QPS). This average QPS means that, in theory, 2 requests can be made of the API every second. Given the pagination feature of the product, if a one-year query has one million Tweets associated with it, spread evenly over the year, over 2,000 requests would be required (assuming a \u2018maxResults\u2019 of 500) to receive all the data. Assuming it takes two seconds per response, that is 4,000 seconds (or just over an hour) to pull all of that data serially/sequentially through a single thread (1 request per second using the prior response\u2019s \u201cnext\u201d token). Not bad!  \nNow consider the situation where twelve parallel threads are used to receive data. Assuming an even distribution of the one million Tweets over the one-year period, you could split the requests into twelve parallel threads (multi-threaded) and utilize more of the per-second rate limit for the single \u201cjob\u201d. In other words, you could run one thread per-month you are interested in and by doing so, data could be retrieved 12x as fast (or ~6 minutes).  \nThis multi-threaded example applies equally well to the counts endpoint. For example, if you wanted to receive Tweet counts for a two-year period, you could make a single-threaded request and page back through the counts 31 days at a time. Assuming it takes 2 seconds per response, it would take approximately 48 seconds to make the 24 API requests and retrieve the entire set of counts. However, you also have the option to make multiple one-month requests at a time. When making 12 requests per second, the entire set of counts could be retrieved in approximately 2 seconds.\n",
        "line_start": 95,
        "line_end": 99
    },
    "7": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/overview\n\tOverview\n\tRetry Logic\n\nContent: \n### Retry Logic  \nIf you experience a 503 error with the enterprise search APIs, it is likely a transient error and can be resolved by re-trying the request a short time later.  \nIf the request fails 4 times in a row, and you have waited at least 10 minutes between failures, use the following steps to troubleshoot:  \n* Retry the request after reducing the amount of time it covers. Repeat this down to a 6-hour time window if unsuccessful.\n* If you are ORing a large number of terms together, split them into separate rules and retry each individually.\n* If you are using a large number of exclusions in your rule, reduce the number of negated terms in the rule and retry.\n",
        "line_start": 103,
        "line_end": 109
    },
    "8": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/overview\n\tOverview\n\tNext steps\n\nContent: \n### Next steps  \n* [Continue to the enterprise search API reference](https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/api-reference/enterprise-search)\n* [Learn more about search operators](https://developer.twitter.com/en/docs/twitter-api/enterprise/guides/enterprise-operators)  \n* [See simple scripts in several languages to help get started](https://github.com/gnip/support/blob/master/Search%20API/readme.md)\n* [See an example Python client library](https://github.com/twitterdev/search-tweets-python)\n* [See an example Ruby client library](https://github.com/twitterdev/search-tweets-ruby)\n",
        "line_start": 113,
        "line_end": 119
    },
    "9": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-30-day\n\nContent: \n# Resource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-30-day\nEnterprise Search Tweets: 30-Day API\n",
        "line_start": 122,
        "line_end": 124
    },
    "10": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-30-day\n\tGetting started with enterprise Search Tweets: 30-Day API\n\nContent: \n## Getting started with enterprise Search Tweets: 30-Day API  \n**\u23f1 10 min read**  \nThe enterprise Search Tweets: 30-Day API provides you with Tweets posted within the last 30 days.\u00a0Tweets are matched and sent back to you based on the query you specify in your request. A query is a rule in which you define what the Tweet you get back should contain. In this tutorial, we will search for Tweets originating from the Twitter account @TwitterDev in English.  \nThe Tweets you get back in your payload can be in a\u00a0data\u00a0format, which provides you with the full Tweet payload, or it can be in a counts format which gives you numerical count data of matched Tweets. We will be using cURL to make requests to the data and counts endpoints.  \nYou will need the following:  \n* [An enterprise account](https://developer.twitter.com/en/enterprise)\n* Your username, password, and account name\n* Label associated with your search endpoint, as displayed at console.gnip.com\n",
        "line_start": 125,
        "line_end": 133
    },
    "11": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-30-day\n\tGetting started with enterprise Search Tweets: 30-Day API\n\tAccessing the data endpoint\n\nContent: \n### Accessing the data endpoint  \nThe data endpoint will provide us with the full Tweet payload of matched Tweets. We will use the `from:` and `lang:` operators to find Tweets originating from @TwitterDev in English.\u00a0_For more operators\u00a0[click here](https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/enterprise-operators)._  \n* [cURL](#tab1)\n* [cURL example](#tab2)\n* [](#tab4)  \ncURL  \ncURL example  \n_cURL is a command-line tool for getting or sending files using the URL syntax._  \nCopy the following cURL request into your command line after making changes to the following:  \n* **Username** `<USERNAME>`\u00a0e.g. `email@domain.com`  \n* **Account name**\u00a0`<ACCOUNT-NAME>`\u00a0e.g. `john-doe`  \n* **Label** `<LABEL>`\u00a0e.g. `prod`  \n* **fromDate and toDate** e.g. `\"fromDate\":\"201811010000\", \"toDate\":\"201811122359\"`  \n_After sending your request, you will be prompted for your password._  \n`curl -X POST -u<USERNAME> \"https://gnip-api.twitter.com/search/30day/accounts/<ACCOUNT-NAME>/<LABEL>.json\" -d '{\"query\":\"from:TwitterDev lang:en\",\"maxResults\":\"500\",\"fromDate\":\"<yyyymmddhhmm>\",\"toDate\":\"<yyyymmddhhmm>\"}'`  \n_This is an example cURL request. If you try to run this it will not work._  \n`curl -X POST -uemail@domain.com \"https://gnip-api.twitter.com/search/30day/accounts/john-doe/prod.json\" -d '{\"query\":\"from:TwitterDev lang:en\",\"maxResults\":\"500\",\"fromDate\":\"201811100000\",\"toDate\":\"201812012359\"}'`  \n#### Data endpoint response payload  \nThe payload you get back from your API request will appear in JSON format, as shown below.  \n`{ \t\"results\": [ \t\t{ \t\t\t\"created_at\": \"Fri Nov 02 17:18:31 +0000 2018\", \t\t\t\"id\": 1058408022936977409, \t\t\t\"id_str\": \"1058408022936977409\", \t\t\t\"text\": \"RT @harmophone: \\\"The innovative crowdsourcing that the Tagboard, Twitter and TEGNA collaboration enables is surfacing locally relevant conv\u2026\", \t\t\t\"source\": \"<a href=\\\"http:\\/\\/twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client<\\/a>\", \t\t\t\"truncated\": false, \t\t\t\"in_reply_to_status_id\": null, \t\t\t\"in_reply_to_status_id_str\": null, \t\t\t\"in_reply_to_user_id\": null, \t\t\t\"in_reply_to_user_id_str\": null, \t\t\t\"in_reply_to_screen_name\": null, \t\t\t\"user\": { \t\t\t\t\"id\": 2244994945, \t\t\t\t\"id_str\": \"2244994945\", \t\t\t\t\"name\": \"Twitter Dev\", \t\t\t\t\"screen_name\": \"TwitterDev\", \t\t\t\t\"location\": \"Internet\", \t\t\t\t\"url\": \"https:\\/\\/developer.twitter.com\\/\", \t\t\t\t\"description\": \"Your official source for Twitter Platform news, updates & events. Need technical help? Visit https:\\/\\/twittercommunity.com\\/ \u2328\ufe0f #TapIntoTwitter\", \t\t\t\t\"translator_type\": \"null\", \t\t\t\t\"protected\": false, \t\t\t\t\"verified\": true, \t\t\t\t\"followers_count\": 503828, \t\t\t\t\"friends_count\": 1477, \t\t\t\t\"listed_count\": 1437, \t\t\t\t\"favourites_count\": 2199, \t\t\t\t\"statuses_count\": 3380, \t\t\t\t\"created_at\": \"Sat Dec 14 04:35:55 +0000 2013\", \t\t\t\t\"utc_offset\": null, \t\t\t\t\"time_zone\": null, \t\t\t\t\"geo_enabled\": true, \t\t\t\t\"lang\": \"en\", \t\t\t\t\"contributors_enabled\": false, \t\t\t\t\"is_translator\": false, \t\t\t\t\"profile_background_color\": \"null\", \t\t\t\t\"profile_background_image_url\": \"null\", \t\t\t\t\"profile_background_image_url_https\": \"null\", \t\t\t\t\"profile_background_tile\": null, \t\t\t\t\"profile_link_color\": \"null\", \t\t\t\t\"profile_sidebar_border_color\": \"null\", \t\t\t\t\"profile_sidebar_fill_color\": \"null\", \t\t\t\t\"profile_text_color\": \"null\", \t\t\t\t\"profile_use_background_image\": null, \t\t\t\t\"profile_image_url\": \"null\", \t\t\t\t\"profile_image_url_https\": \"https:\\/\\/pbs.twimg.com\\/profile_images\\/880136122604507136\\/xHrnqf1T_normal.jpg\", \t\t\t\t\"profile_banner_url\": \"https:\\/\\/pbs.twimg.com\\/profile_banners\\/2244994945\\/1498675817\", \t\t\t\t\"default_profile\": false, \t\t\t\t\"default_profile_image\": false, \t\t\t\t\"following\": null, \t\t\t\t\"follow_request_sent\": null, \t\t\t\t\"notifications\": null \t\t\t}, \t\t\t\"geo\": null, \t\t\t\"coordinates\": null, \t\t\t\"place\": null, \t\t\t\"contributors\": null, \t\t\t\"retweeted_status\": { \t\t\t\t\"created_at\": \"Tue Oct 30 21:30:25 +0000 2018\", \t\t\t\t\"id\": 1057384253116289025, \t\t\t\t\"id_str\": \"1057384253116289025\", \t\t\t\t\"text\": \"\\\"The innovative crowdsourcing that the Tagboard, Twitter and TEGNA collaboration enables is surfacing locally relev\u2026 https:\\/\\/t.co\\/w46U5TRTzQ\", \t\t\t\t\"source\": \"<a href=\\\"http:\\/\\/twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client<\\/a>\", \t\t\t\t\"truncated\": true, \t\t\t\t\"in_reply_to_status_id\": null, \t\t\t\t\"in_reply_to_status_id_str\": null, \t\t\t\t\"in_reply_to_user_id\": null, \t\t\t\t\"in_reply_to_user_id_str\": null, \t\t\t\t\"in_reply_to_screen_name\": null, \t\t\t\t\"user\": { \t\t\t\t\t\"id\": 175187944, \t\t\t\t\t\"id_str\": \"175187944\", \t\t\t\t\t\"name\": \"Tyler Singletary\", \t\t\t\t\t\"screen_name\": \"harmophone\", \t\t\t\t\t\"location\": \"San Francisco, CA\", \t\t\t\t\t\"url\": \"http:\\/\\/medium.com\\/@harmophone\", \t\t\t\t\t\"description\": \"SVP Product at @Tagboard. Did some Data, biz, and product @Klout & for @LithiumTech; @BBI board member; @Insightpool advisor. World's worst whiteboarder.\", \t\t\t\t\t\"translator_type\": \"null\", \t\t\t\t\t\"protected\": false, \t\t\t\t\t\"verified\": false, \t\t\t\t\t\"followers_count\": 1982, \t\t\t\t\t\"friends_count\": 1877, \t\t\t\t\t\"listed_count\": 245, \t\t\t\t\t\"favourites_count\": 23743, \t\t\t\t\t\"statuses_count\": 12708, \t\t\t\t\t\"created_at\": \"Thu Aug 05 22:59:29 +0000 2010\", \t\t\t\t\t\"utc_offset\": null, \t\t\t\t\t\"time_zone\": null, \t\t\t\t\t\"geo_enabled\": false, \t\t\t\t\t\"lang\": \"en\", \t\t\t\t\t\"contributors_enabled\": false, \t\t\t\t\t\"is_translator\": false, \t\t\t\t\t\"profile_background_color\": \"null\", \t\t\t\t\t\"profile_background_image_url\": \"null\", \t\t\t\t\t\"profile_background_image_url_https\": \"null\", \t\t\t\t\t\"profile_background_tile\": null, \t\t\t\t\t\"profile_link_color\": \"null\", \t\t\t\t\t\"profile_sidebar_border_color\": \"null\", \t\t\t\t\t\"profile_sidebar_fill_color\": \"null\", \t\t\t\t\t\"profile_text_color\": \"null\", \t\t\t\t\t\"profile_use_background_image\": null, \t\t\t\t\t\"profile_image_url\": \"null\", \t\t\t\t\t\"profile_image_url_https\": \"https:\\/\\/pbs.twimg.com\\/profile_images\\/719985428632240128\\/WYFHcK-m_normal.jpg\", \t\t\t\t\t\"profile_banner_url\": \"https:\\/\\/pbs.twimg.com\\/profile_banners\\/175187944\\/1398653841\", \t\t\t\t\t\"default_profile\": false, \t\t\t\t\t\"default_profile_image\": false, \t\t\t\t\t\"following\": null, \t\t\t\t\t\"follow_request_sent\": null, \t\t\t\t\t\"notifications\": null \t\t\t\t}, \t\t\t\t\"geo\": null, \t\t\t\t\"coordinates\": null, \t\t\t\t\"place\": null, \t\t\t\t\"contributors\": null, \t\t\t\t\"is_quote_status\": false, \t\t\t\t\"extended_tweet\": { \t\t\t\t\t\"full_text\": \"\\\"The innovative crowdsourcing that the Tagboard, Twitter and TEGNA collaboration enables is surfacing locally relevant conversations in real-time and enabling voters to ask questions during debates,\u201d \u200a-- @adamostrow, @TEGNA\\nLearn More: https:\\/\\/t.co\\/ivAFtanfje\", \t\t\t\t\t\"display_text_range\": [ \t\t\t\t\t\t0, \t\t\t\t\t\t259 \t\t\t\t\t], \t\t\t\t\t\"entities\": { \t\t\t\t\t\t\"hashtags\": [], \t\t\t\t\t\t\"urls\": [ \t\t\t\t\t\t\t{ \t\t\t\t\t\t\t\t\"url\": \"https:\\/\\/t.co\\/ivAFtanfje\", \t\t\t\t\t\t\t\t\"expanded_url\": \"https:\\/\\/blog.tagboard.com\\/twitter-and-tagboard-collaborate-to-bring-best-election-content-to-news-outlets-with-tagboard-e85fc864bcf4\", \t\t\t\t\t\t\t\t\"display_url\": \"blog.tagboard.com\\/twitter-and-ta\u2026\", \t\t\t\t\t\t\t\t\"unwound\": { \t\t\t\t\t\t\t\t\t\"url\": \"https:\\/\\/blog.tagboard.com\\/twitter-and-tagboard-collaborate-to-bring-best-election-content-to-news-outlets-with-tagboard-e85fc864bcf4\", \t\t\t\t\t\t\t\t\t\"status\": 200, \t\t\t\t\t\t\t\t\t\"title\": \"Twitter and Tagboard Collaborate to Bring Best Election Content to News Outlets With Tagboard\u2026\", \t\t\t\t\t\t\t\t\t\"description\": \"By Tyler Singletary, Head of Product, Tagboard\" \t\t\t\t\t\t\t\t}, \t\t\t\t\t\t\t\t\"indices\": [ \t\t\t\t\t\t\t\t\t236, \t\t\t\t\t\t\t\t\t259 \t\t\t\t\t\t\t\t] \t\t\t\t\t\t\t} \t\t\t\t\t\t], \t\t\t\t\t\t\"user_mentions\": [ \t\t\t\t\t\t\t{ \t\t\t\t\t\t\t\t\"screen_name\": \"adamostrow\", \t\t\t\t\t\t\t\t\"name\": \"Adam Ostrow\", \t\t\t\t\t\t\t\t\"id\": 5695942, \t\t\t\t\t\t\t\t\"id_str\": \"5695942\", \t\t\t\t\t\t\t\t\"indices\": [ \t\t\t\t\t\t\t\t\t204, \t\t\t\t\t\t\t\t\t215 \t\t\t\t\t\t\t\t] \t\t\t\t\t\t\t}, \t\t\t\t\t\t\t{ \t\t\t\t\t\t\t\t\"screen_name\": \"TEGNA\", \t\t\t\t\t\t\t\t\"name\": \"TEGNA\", \t\t\t\t\t\t\t\t\"id\": 34123003, \t\t\t\t\t\t\t\t\"id_str\": \"34123003\", \t\t\t\t\t\t\t\t\"indices\": [ \t\t\t\t\t\t\t\t\t217, \t\t\t\t\t\t\t\t\t223 \t\t\t\t\t\t\t\t] \t\t\t\t\t\t\t} \t\t\t\t\t\t], \t\t\t\t\t\t\"symbols\": [] \t\t\t\t\t} \t\t\t\t}, \t\t\t\t\"quote_count\": 0, \t\t\t\t\"reply_count\": 1, \t\t\t\t\"retweet_count\": 6, \t\t\t\t\"favorite_count\": 19, \t\t\t\t\"entities\": { \t\t\t\t\t\"hashtags\": [], \t\t\t\t\t\"urls\": [ \t\t\t\t\t\t{ \t\t\t\t\t\t\t\"url\": \"https:\\/\\/t.co\\/w46U5TRTzQ\", \t\t\t\t\t\t\t\"expanded_url\": \"https:\\/\\/twitter.com\\/i\\/web\\/status\\/1057384253116289025\", \t\t\t\t\t\t\t\"display_url\": \"twitter.com\\/i\\/web\\/status\\/1\u2026\", \t\t\t\t\t\t\t\"indices\": [ \t\t\t\t\t\t\t\t117, \t\t\t\t\t\t\t\t140 \t\t\t\t\t\t\t] \t\t\t\t\t\t} \t\t\t\t\t], \t\t\t\t\t\"user_mentions\": [], \t\t\t\t\t\"symbols\": [] \t\t\t\t}, \t\t\t\t\"favorited\": false, \t\t\t\t\"retweeted\": false, \t\t\t\t\"possibly_sensitive\": false, \t\t\t\t\"filter_level\": \"low\", \t\t\t\t\"lang\": \"en\" \t\t\t}, \t\t\t\"is_quote_status\": false, \t\t\t\"quote_count\": 0, \t\t\t\"reply_count\": 0, \t\t\t\"retweet_count\": 0, \t\t\t\"favorite_count\": 0, \t\t\t\"entities\": { \t\t\t\t\"hashtags\": [], \t\t\t\t\"urls\": [], \t\t\t\t\"user_mentions\": [ \t\t\t\t\t{ \t\t\t\t\t\t\"screen_name\": \"harmophone\", \t\t\t\t\t\t\"name\": \"Tyler Singletary\", \t\t\t\t\t\t\"id\": 175187944, \t\t\t\t\t\t\"id_str\": \"175187944\", \t\t\t\t\t\t\"indices\": [ \t\t\t\t\t\t\t3, \t\t\t\t\t\t\t14 \t\t\t\t\t\t] \t\t\t\t\t} \t\t\t\t], \t\t\t\t\"symbols\": [] \t\t\t}, \t\t\t\"favorited\": false, \t\t\t\"retweeted\": false, \t\t\t\"filter_level\": \"low\", \t\t\t\"lang\": \"en\", \t\t\t\"matching_rules\": [ \t\t\t\t{ \t\t\t\t\t\"tag\": null \t\t\t\t} \t\t\t] \t\t} \t], \t\"requestParameters\": { \t\t\"maxResults\": 100, \t\t\"fromDate\": \"201811010000\", \t\t\"toDate\": \"201811060000\" \t} }`\n",
        "line_start": 139,
        "line_end": 159
    },
    "12": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-30-day\n\tGetting started with enterprise Search Tweets: 30-Day API\n\tAccessing the counts endpoint\n\nContent: \n### Accessing the counts endpoint  \nWith the counts endpoint, we\u2019ll retrieve the number of Tweets originating from the @TwitterDev account in English grouped by `day`.  \n* [cURL](#tab1)\n* [cURL example](#tab2)\n* [](#tab4)  \ncURL  \ncURL example  \n_cURL is a command-line tool for getting or sending files using the URL syntax._  \nCopy the following cURL request into your command line after making changes to the following:  \n* **Username** `<USERNAME>`\u00a0e.g. `email@domain.com`  \n* **Account name**\u00a0`<ACCOUNT-NAME>`\u00a0e.g. `john-doe`  \n* **Label** `<LABEL>`\u00a0e.g. `prod`  \n* **fromDate and toDate** e.g. `\"fromDate\":\"201811010000\", \"toDate\":\"201811122359\"`  \n_After sending your request, you will be prompted for your password._  \n`curl -X POST -u<USERNAME> \"https://gnip-api.twitter.com/search/30day/accounts/<ACCOUNT-NAME>/<LABEL>/counts.json\" -d '{\"query\":\"from:TwitterDev lang:en\",\"fromDate\":\"<yyyymmddhhmm>\",\"toDate\":\"<yyyymmddhhmm>\",\"bucket\":\"day\"}'`  \n_This is an example cURL request. If you try to run this it will not work._  \n`curl -X POST -uemail@domain.com \"https://gnip-api.twitter.com/search/30day/accounts/john-doe/prod/counts.json\" -d '{\"query\":\"from:TwitterDev lang:en\",\"fromDate\":\"201811100000\",\"toDate\":\"201812012359\",\"bucket\":\"day\"}'`  \n#### Counts endpoint response payload  \nThe payload you get back from your API request will appear in JSON format, as shown below.  \n`{ \t\"results\": [ \t\t{ \t\t\t\"timePeriod\": \"201811010000\", \t\t\t\"count\": 0 \t\t}, \t\t{ \t\t\t\"timePeriod\": \"201811020000\", \t\t\t\"count\": 1 \t\t}, \t\t{ \t\t\t\"timePeriod\": \"201811030000\", \t\t\t\"count\": 0 \t\t}, \t\t{ \t\t\t\"timePeriod\": \"201811040000\", \t\t\t\"count\": 0 \t\t}, \t\t{ \t\t\t\"timePeriod\": \"201811050000\", \t\t\t\"count\": 0 \t\t} \t], \t\"totalCount\": 1, \t\"requestParameters\": { \t\t\"bucket\": \"day\", \t\t\"fromDate\": \"201811010000\", \t\t\"toDate\": \"201811060000\" \t} }`  \nGreat job! Now you've successfully accessed the enterprise Search Tweets: 30-Day API.\n",
        "line_start": 181,
        "line_end": 202
    },
    "13": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-30-day\n\tGetting started with enterprise Search Tweets: 30-Day API\n\tReferenced articles\n\nContent: \n### Referenced articles  \n* [Introduction to Tweet objects](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/data-dictionary/overview)\n* [Premium search operators](https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/enterprise-operators)\n* [Tweet objects and payloads](https://developer.twitter.com/en/docs/twitter-api/enterprise/data-dictionary/native-enriched-objects)\n",
        "line_start": 224,
        "line_end": 228
    },
    "14": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-30-day\n\tNext Steps\n\nContent: \n## Next Steps  \n* [Discover more about the counts endpoint](https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/api-reference/enterprise-search)  \n* [Join the conversation on Twitter community forums](https://twittercommunity.com/)\n",
        "line_start": 230,
        "line_end": 233
    },
    "15": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-full-archive\n\nContent: \n# Resource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-full-archive\nEnterprise Search Tweets: Full-Archive API\n",
        "line_start": 236,
        "line_end": 238
    },
    "16": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-full-archive\n\tGetting started with enterprise Search Tweets: Full-Archive API\n\nContent: \n## Getting started with enterprise Search Tweets: Full-Archive API  \n**\u23f1 10 min read**  \nThe enterprise Search Tweets: Full-Archive API provides you with Tweets since the first one posted in 2006.\u00a0Tweets are matched and sent back to you based on the query you specify in your request. A query is a rule in which you define what the Tweet you get back should contain. In this tutorial, we will search for Tweets originating from the Twitter account @TwitterDev in English.  \nThe Tweets you get back in your payload can be in a\u00a0data\u00a0format, which provides you with the full Tweet payload, or it can be in a counts format which gives you numerical count data of matched Tweets. We will be using cURL to make requests to the data and counts endpoints.  \nYou will need the following:  \n* [An enterprise account](https://developer.twitter.com/en/enterprise)\n* Your username, password, and account name\n* Label associated with your search endpoint, as displayed at console.gnip.com\n",
        "line_start": 239,
        "line_end": 247
    },
    "17": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-full-archive\n\tGetting started with enterprise Search Tweets: Full-Archive API\n\tAccessing the data endpoint\n\nContent: \n### Accessing the data endpoint  \nThe data endpoint will provide us with the full Tweet payload of matched Tweets. We will use the `from:` and `lang:` operators to find Tweets originating from @TwitterDev in English.\u00a0_For more operators\u00a0[click here](https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/enterprise-operators)._  \n* [cURL](#tab1)\n* [cURL example](#tab2)\n* [](#tab4)  \ncURL  \ncURL example  \n_cURL is a command-line tool for getting or sending files using the URL syntax._  \nCopy the following cURL request into your command line after making changes to the following:  \n* **Username** `<USERNAME>`\u00a0e.g. `email@domain.com`  \n* **Account name**\u00a0`<ACCOUNT-NAME>`\u00a0e.g. `john-doe`  \n* **Label** `<LABEL>`\u00a0e.g. `prod`  \n* **fromDate and toDate** e.g. `\"fromDate\":\"201802010000\", \"toDate\":\"201802282359\"`  \n_After sending your request, you will be prompted for your password._  \n`curl -X POST -u<USERNAME> \"https://gnip-api.twitter.com/search/fullarchive/accounts/<ACCOUNT-NAME>/<LABEL>.json\" -d '{\"query\":\"from:TwitterDev lang:en\",\"maxResults\":\"500\",\"fromDate\":\"<yyyymmddhhmm>\",\"toDate\":\"<yyyymmddhhmm>\"}'`  \n_This is an example cURL request. If you try to run this it will not work._  \n`curl -X POST -uemail@domain.com \"https://gnip-api.twitter.com/search/fullarchive/accounts/john-doe/prod.json\" -d '{\"query\":\"from:TwitterDev lang:en\",\"maxResults\":\"500\",\"fromDate\":\"201802010000\",\"toDate\":\"201802282359\"}'`  \n#### Data endpoint response payload  \nThe payload you get back from your API request will appear in JSON format, as shown below.  \n`{ \t\"results\": [ \t\t{ \t\t\t\"created_at\": \"Fri Nov 02 17:18:31 +0000 2018\", \t\t\t\"id\": 1058408022936977409, \t\t\t\"id_str\": \"1058408022936977409\", \t\t\t\"text\": \"RT @harmophone: \\\"The innovative crowdsourcing that the Tagboard, Twitter and TEGNA collaboration enables is surfacing locally relevant conv\u2026\", \t\t\t\"source\": \"<a href=\\\"http:\\/\\/twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client<\\/a>\", \t\t\t\"truncated\": false, \t\t\t\"in_reply_to_status_id\": null, \t\t\t\"in_reply_to_status_id_str\": null, \t\t\t\"in_reply_to_user_id\": null, \t\t\t\"in_reply_to_user_id_str\": null, \t\t\t\"in_reply_to_screen_name\": null, \t\t\t\"user\": { \t\t\t\t\"id\": 2244994945, \t\t\t\t\"id_str\": \"2244994945\", \t\t\t\t\"name\": \"Twitter Dev\", \t\t\t\t\"screen_name\": \"TwitterDev\", \t\t\t\t\"location\": \"Internet\", \t\t\t\t\"url\": \"https:\\/\\/developer.twitter.com\\/\", \t\t\t\t\"description\": \"Your official source for Twitter Platform news, updates & events. Need technical help? Visit https:\\/\\/twittercommunity.com\\/ \u2328\ufe0f #TapIntoTwitter\", \t\t\t\t\"translator_type\": \"null\", \t\t\t\t\"protected\": false, \t\t\t\t\"verified\": true, \t\t\t\t\"followers_count\": 503828, \t\t\t\t\"friends_count\": 1477, \t\t\t\t\"listed_count\": 1437, \t\t\t\t\"favourites_count\": 2199, \t\t\t\t\"statuses_count\": 3380, \t\t\t\t\"created_at\": \"Sat Dec 14 04:35:55 +0000 2013\", \t\t\t\t\"utc_offset\": null, \t\t\t\t\"time_zone\": null, \t\t\t\t\"geo_enabled\": true, \t\t\t\t\"lang\": \"en\", \t\t\t\t\"contributors_enabled\": false, \t\t\t\t\"is_translator\": false, \t\t\t\t\"profile_background_color\": \"null\", \t\t\t\t\"profile_background_image_url\": \"null\", \t\t\t\t\"profile_background_image_url_https\": \"null\", \t\t\t\t\"profile_background_tile\": null, \t\t\t\t\"profile_link_color\": \"null\", \t\t\t\t\"profile_sidebar_border_color\": \"null\", \t\t\t\t\"profile_sidebar_fill_color\": \"null\", \t\t\t\t\"profile_text_color\": \"null\", \t\t\t\t\"profile_use_background_image\": null, \t\t\t\t\"profile_image_url\": \"null\", \t\t\t\t\"profile_image_url_https\": \"https:\\/\\/pbs.twimg.com\\/profile_images\\/880136122604507136\\/xHrnqf1T_normal.jpg\", \t\t\t\t\"profile_banner_url\": \"https:\\/\\/pbs.twimg.com\\/profile_banners\\/2244994945\\/1498675817\", \t\t\t\t\"default_profile\": false, \t\t\t\t\"default_profile_image\": false, \t\t\t\t\"following\": null, \t\t\t\t\"follow_request_sent\": null, \t\t\t\t\"notifications\": null \t\t\t}, \t\t\t\"geo\": null, \t\t\t\"coordinates\": null, \t\t\t\"place\": null, \t\t\t\"contributors\": null, \t\t\t\"retweeted_status\": { \t\t\t\t\"created_at\": \"Tue Oct 30 21:30:25 +0000 2018\", \t\t\t\t\"id\": 1057384253116289025, \t\t\t\t\"id_str\": \"1057384253116289025\", \t\t\t\t\"text\": \"\\\"The innovative crowdsourcing that the Tagboard, Twitter and TEGNA collaboration enables is surfacing locally relev\u2026 https:\\/\\/t.co\\/w46U5TRTzQ\", \t\t\t\t\"source\": \"<a href=\\\"http:\\/\\/twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client<\\/a>\", \t\t\t\t\"truncated\": true, \t\t\t\t\"in_reply_to_status_id\": null, \t\t\t\t\"in_reply_to_status_id_str\": null, \t\t\t\t\"in_reply_to_user_id\": null, \t\t\t\t\"in_reply_to_user_id_str\": null, \t\t\t\t\"in_reply_to_screen_name\": null, \t\t\t\t\"user\": { \t\t\t\t\t\"id\": 175187944, \t\t\t\t\t\"id_str\": \"175187944\", \t\t\t\t\t\"name\": \"Tyler Singletary\", \t\t\t\t\t\"screen_name\": \"harmophone\", \t\t\t\t\t\"location\": \"San Francisco, CA\", \t\t\t\t\t\"url\": \"http:\\/\\/medium.com\\/@harmophone\", \t\t\t\t\t\"description\": \"SVP Product at @Tagboard. Did some Data, biz, and product @Klout & for @LithiumTech; @BBI board member; @Insightpool advisor. World's worst whiteboarder.\", \t\t\t\t\t\"translator_type\": \"null\", \t\t\t\t\t\"protected\": false, \t\t\t\t\t\"verified\": false, \t\t\t\t\t\"followers_count\": 1982, \t\t\t\t\t\"friends_count\": 1877, \t\t\t\t\t\"listed_count\": 245, \t\t\t\t\t\"favourites_count\": 23743, \t\t\t\t\t\"statuses_count\": 12708, \t\t\t\t\t\"created_at\": \"Thu Aug 05 22:59:29 +0000 2010\", \t\t\t\t\t\"utc_offset\": null, \t\t\t\t\t\"time_zone\": null, \t\t\t\t\t\"geo_enabled\": false, \t\t\t\t\t\"lang\": \"en\", \t\t\t\t\t\"contributors_enabled\": false, \t\t\t\t\t\"is_translator\": false, \t\t\t\t\t\"profile_background_color\": \"null\", \t\t\t\t\t\"profile_background_image_url\": \"null\", \t\t\t\t\t\"profile_background_image_url_https\": \"null\", \t\t\t\t\t\"profile_background_tile\": null, \t\t\t\t\t\"profile_link_color\": \"null\", \t\t\t\t\t\"profile_sidebar_border_color\": \"null\", \t\t\t\t\t\"profile_sidebar_fill_color\": \"null\", \t\t\t\t\t\"profile_text_color\": \"null\", \t\t\t\t\t\"profile_use_background_image\": null, \t\t\t\t\t\"profile_image_url\": \"null\", \t\t\t\t\t\"profile_image_url_https\": \"https:\\/\\/pbs.twimg.com\\/profile_images\\/719985428632240128\\/WYFHcK-m_normal.jpg\", \t\t\t\t\t\"profile_banner_url\": \"https:\\/\\/pbs.twimg.com\\/profile_banners\\/175187944\\/1398653841\", \t\t\t\t\t\"default_profile\": false, \t\t\t\t\t\"default_profile_image\": false, \t\t\t\t\t\"following\": null, \t\t\t\t\t\"follow_request_sent\": null, \t\t\t\t\t\"notifications\": null \t\t\t\t}, \t\t\t\t\"geo\": null, \t\t\t\t\"coordinates\": null, \t\t\t\t\"place\": null, \t\t\t\t\"contributors\": null, \t\t\t\t\"is_quote_status\": false, \t\t\t\t\"extended_tweet\": { \t\t\t\t\t\"full_text\": \"\\\"The innovative crowdsourcing that the Tagboard, Twitter and TEGNA collaboration enables is surfacing locally relevant conversations in real-time and enabling voters to ask questions during debates,\u201d \u200a-- @adamostrow, @TEGNA\\nLearn More: https:\\/\\/t.co\\/ivAFtanfje\", \t\t\t\t\t\"display_text_range\": [ \t\t\t\t\t\t0, \t\t\t\t\t\t259 \t\t\t\t\t], \t\t\t\t\t\"entities\": { \t\t\t\t\t\t\"hashtags\": [], \t\t\t\t\t\t\"urls\": [ \t\t\t\t\t\t\t{ \t\t\t\t\t\t\t\t\"url\": \"https:\\/\\/t.co\\/ivAFtanfje\", \t\t\t\t\t\t\t\t\"expanded_url\": \"https:\\/\\/blog.tagboard.com\\/twitter-and-tagboard-collaborate-to-bring-best-election-content-to-news-outlets-with-tagboard-e85fc864bcf4\", \t\t\t\t\t\t\t\t\"display_url\": \"blog.tagboard.com\\/twitter-and-ta\u2026\", \t\t\t\t\t\t\t\t\"unwound\": { \t\t\t\t\t\t\t\t\t\"url\": \"https:\\/\\/blog.tagboard.com\\/twitter-and-tagboard-collaborate-to-bring-best-election-content-to-news-outlets-with-tagboard-e85fc864bcf4\", \t\t\t\t\t\t\t\t\t\"status\": 200, \t\t\t\t\t\t\t\t\t\"title\": \"Twitter and Tagboard Collaborate to Bring Best Election Content to News Outlets With Tagboard\u2026\", \t\t\t\t\t\t\t\t\t\"description\": \"By Tyler Singletary, Head of Product, Tagboard\" \t\t\t\t\t\t\t\t}, \t\t\t\t\t\t\t\t\"indices\": [ \t\t\t\t\t\t\t\t\t236, \t\t\t\t\t\t\t\t\t259 \t\t\t\t\t\t\t\t] \t\t\t\t\t\t\t} \t\t\t\t\t\t], \t\t\t\t\t\t\"user_mentions\": [ \t\t\t\t\t\t\t{ \t\t\t\t\t\t\t\t\"screen_name\": \"adamostrow\", \t\t\t\t\t\t\t\t\"name\": \"Adam Ostrow\", \t\t\t\t\t\t\t\t\"id\": 5695942, \t\t\t\t\t\t\t\t\"id_str\": \"5695942\", \t\t\t\t\t\t\t\t\"indices\": [ \t\t\t\t\t\t\t\t\t204, \t\t\t\t\t\t\t\t\t215 \t\t\t\t\t\t\t\t] \t\t\t\t\t\t\t}, \t\t\t\t\t\t\t{ \t\t\t\t\t\t\t\t\"screen_name\": \"TEGNA\", \t\t\t\t\t\t\t\t\"name\": \"TEGNA\", \t\t\t\t\t\t\t\t\"id\": 34123003, \t\t\t\t\t\t\t\t\"id_str\": \"34123003\", \t\t\t\t\t\t\t\t\"indices\": [ \t\t\t\t\t\t\t\t\t217, \t\t\t\t\t\t\t\t\t223 \t\t\t\t\t\t\t\t] \t\t\t\t\t\t\t} \t\t\t\t\t\t], \t\t\t\t\t\t\"symbols\": [] \t\t\t\t\t} \t\t\t\t}, \t\t\t\t\"quote_count\": 0, \t\t\t\t\"reply_count\": 1, \t\t\t\t\"retweet_count\": 6, \t\t\t\t\"favorite_count\": 19, \t\t\t\t\"entities\": { \t\t\t\t\t\"hashtags\": [], \t\t\t\t\t\"urls\": [ \t\t\t\t\t\t{ \t\t\t\t\t\t\t\"url\": \"https:\\/\\/t.co\\/w46U5TRTzQ\", \t\t\t\t\t\t\t\"expanded_url\": \"https:\\/\\/twitter.com\\/i\\/web\\/status\\/1057384253116289025\", \t\t\t\t\t\t\t\"display_url\": \"twitter.com\\/i\\/web\\/status\\/1\u2026\", \t\t\t\t\t\t\t\"indices\": [ \t\t\t\t\t\t\t\t117, \t\t\t\t\t\t\t\t140 \t\t\t\t\t\t\t] \t\t\t\t\t\t} \t\t\t\t\t], \t\t\t\t\t\"user_mentions\": [], \t\t\t\t\t\"symbols\": [] \t\t\t\t}, \t\t\t\t\"favorited\": false, \t\t\t\t\"retweeted\": false, \t\t\t\t\"possibly_sensitive\": false, \t\t\t\t\"filter_level\": \"low\", \t\t\t\t\"lang\": \"en\" \t\t\t}, \t\t\t\"is_quote_status\": false, \t\t\t\"quote_count\": 0, \t\t\t\"reply_count\": 0, \t\t\t\"retweet_count\": 0, \t\t\t\"favorite_count\": 0, \t\t\t\"entities\": { \t\t\t\t\"hashtags\": [], \t\t\t\t\"urls\": [], \t\t\t\t\"user_mentions\": [ \t\t\t\t\t{ \t\t\t\t\t\t\"screen_name\": \"harmophone\", \t\t\t\t\t\t\"name\": \"Tyler Singletary\", \t\t\t\t\t\t\"id\": 175187944, \t\t\t\t\t\t\"id_str\": \"175187944\", \t\t\t\t\t\t\"indices\": [ \t\t\t\t\t\t\t3, \t\t\t\t\t\t\t14 \t\t\t\t\t\t] \t\t\t\t\t} \t\t\t\t], \t\t\t\t\"symbols\": [] \t\t\t}, \t\t\t\"favorited\": false, \t\t\t\"retweeted\": false, \t\t\t\"filter_level\": \"low\", \t\t\t\"lang\": \"en\", \t\t\t\"matching_rules\": [ \t\t\t\t{ \t\t\t\t\t\"tag\": null \t\t\t\t} \t\t\t] \t\t} \t], \t\"requestParameters\": { \t\t\"maxResults\": 100, \t\t\"fromDate\": \"201811010000\", \t\t\"toDate\": \"201811060000\" \t} }`\n",
        "line_start": 139,
        "line_end": 159
    },
    "18": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-full-archive\n\tGetting started with enterprise Search Tweets: Full-Archive API\n\tAccessing the counts endpoint\n\nContent: \n### Accessing the counts endpoint  \nWith the counts endpoint, we\u2019ll retrieve the number of Tweets originating from the @TwitterDev account in English grouped by `day`.  \n* [cURL](#tab1)\n* [cURL example](#tab2)\n* [](#tab4)  \ncURL  \ncURL example  \n_cURL is a command-line tool for getting or sending files using the URL syntax._  \nCopy the following cURL request into your command line after making changes to the following:  \n* **Username** `<USERNAME>`\u00a0e.g. `email@domain.com`  \n* **Account name**\u00a0`<ACCOUNT-NAME>`\u00a0e.g. `john-doe`  \n* **Label** `<LABEL>`\u00a0e.g. `prod`  \n* **fromDate and toDate** e.g. `\"fromDate\":\"201802010000\", \"toDate\":\"201802282359\"`  \n_After sending your request, you will be prompted for your password._  \n`curl -X POST -u<USERNAME> \"https://gnip-api.twitter.com/search/fullarchive/accounts/<ACCOUNT-NAME>/<LABEL>/counts.json\" -d '{\"query\":\"from:TwitterDev lang:en\",\"fromDate\":\"<yyyymmddhhmm>\",\"toDate\":\"<yyyymmddhhmm>\",\"bucket\":\"day\"}'`  \n_This is an example cURL request. If you try to run this it will not work._  \n`curl -X POST -uemail@domain.com \"https://gnip-api.twitter.com/search/fullarchive/accounts/john-doe/prod/counts.json\" -d '{\"query\":\"from:TwitterDev lang:en\",\"fromDate\":\"201802010000\",\"toDate\":\"201802282359\",\"bucket\":\"day\"}'`  \n#### Counts endpoint response payload  \nThe payload you get back from your API request will appear in JSON format, as shown below.  \n`{ \t\"results\": [ \t\t{ \t\t\t\"timePeriod\": \"201811010000\", \t\t\t\"count\": 0 \t\t}, \t\t{ \t\t\t\"timePeriod\": \"201811020000\", \t\t\t\"count\": 1 \t\t}, \t\t{ \t\t\t\"timePeriod\": \"201811030000\", \t\t\t\"count\": 0 \t\t}, \t\t{ \t\t\t\"timePeriod\": \"201811040000\", \t\t\t\"count\": 0 \t\t}, \t\t{ \t\t\t\"timePeriod\": \"201811050000\", \t\t\t\"count\": 0 \t\t} \t], \t\"totalCount\": 1, \t\"requestParameters\": { \t\t\"bucket\": \"day\", \t\t\"fromDate\": \"201811010000\", \t\t\"toDate\": \"201811060000\" \t} }`  \nGreat job! Now you've successfully accessed the enterprise Search Tweets: Full-Archive API.\n",
        "line_start": 181,
        "line_end": 202
    },
    "19": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-full-archive\n\tGetting started with enterprise Search Tweets: Full-Archive API\n\tReferenced articles\n\nContent: \n### Referenced articles  \n* [Introduction to Tweet objects](https://developer.twitter.com/en/docs/twitter-api/enterprise/data-dictionary/overview)\n* [Premium search operators](https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/premium-operators)\n* [Tweet objects and payloads](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/data-dictionary/native-enriched-objects)\n",
        "line_start": 224,
        "line_end": 228
    },
    "20": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-full-archive\n\tNext Steps\n\nContent: \n## Next Steps  \n* [Discover more about the counts endpoint](https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/api-reference/enterprise-search#CountsEndpoint)  \n* [Join the conversation on Twitter community forums](https://twittercommunity.com/)\n",
        "line_start": 230,
        "line_end": 233
    },
    "21": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/operators\n\nContent: \n# Resource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/operators\nBuilding search queries  \nPremium and enterprise operators  \n===================================  \nBelow is a list of all operators supported in Twitter's premium and enterprise search APIs:  \n* Enterprise 30-day search API\n* Enterprise Full-archive search API  \nFor a side-by-side comparison of available operators by product see [HERE](https://developer.twitter.com/en/docs/twitter-api/enterprise/rules-and-filtering/operators-by-product).  \nOperatorDescriptionkeyword  \nMatches a tokenized keyword within the body or urls of a Tweet. This is a tokenized match, meaning that your keyword string will be matched against the tokenized text of the Tweet body \u2013 tokenization is based on punctuation, symbol, and separator Unicode basic plane characters. For example, a Tweet with the text \u201cI like coca-cola\u201d would be split into the following tokens: I, like, coca, cola. These tokens would then be compared to the keyword string used in your rule. To match strings containing punctuation (for example, coca-cola), symbol, or separator characters, you must use a quoted exact match as described below.  \n**Note:** With the Search API, accented and special characters are normalized to standard latin characters, which can change meanings in foreign languages or return unexpected results:  \nFor example,\u00a0\"m\u00fasic\" will match \u201cmusic\u201d and vice versa.\nFor example,\u00a0common phrases like \"Feliz A\u00f1o Nuevo!\" in Spanish, would be indexed as \"Feliz Ano Nuevo\", which changes the meaning of the phrase.  \n**Note:**\u00a0This operator will match on both URLs and unwound URLs within a Tweet.  \nemoji\nMatches an emoji within the body of a Tweet. Emojis are a tokenized match, meaning that your emoji will be matched against the tokenized text of the Tweet body \u2013 tokenization is based on punctuation, symbol/emoji, and separator Unicode basic plane characters. For example, a Tweet with the text \u201cI like \ud83c\udf55\u201d would be split into the following tokens: I, like, \ud83c\udf55. These tokens would then be compared to the emoji used in your rule. Note that if an emoji has a variant, you must use \u201cquotations\u201d to add to a rule.\n\"exact phrase match\"  \nMatches the tokenized and ordered phrase within the body or urls of a Tweet.\u00a0This is a tokenized match, meaning that your keyword string will be matched against the tokenized text of the Tweet body \u2013 tokenization is based on punctuation, symbol, and separator Unicode basic plane characters.  \n**Note:**\u00a0Punctuation is not tokenized and is instead treated as whitespace.\nFor example,\u00a0quoted \u201c#hashtag\u201d will match \u201chashtag\u201d but not #hashtag (use the hashtag # operator without quotes to match on actual hashtags.\nFor example,\u00a0quoted \u201c$cashtag\u201d will match \u201ccashtag\u201d but not $cashtag (use the cashtag $ operator without quotes to match on actual cashtags.\nFor example,\u00a0\"Love Snow\" will match \"#love #snow\"\nFor example,\u00a0\"#Love #Snow\" will match \"love snow\"  \n**Note:** This operator will match on both URLs and unwound URLs within a Tweet.  \n\"keyword1 keyword2\"~N  \nCommonly referred to as a proximity operator, this matches a Tweet where the keywords are no more than N tokens from each other.  \nIf the keywords are in the opposite order, they can not be more than N-2 tokens from each other. Can have any number of keywords in quotes.\u00a0N cannot be greater than 6.  \nNote that this operator is only available in the\u00a0enterprise\u00a0search APIs.  \nfrom:  \nMatches any Tweet from a specific user.  \nThe value must be the user\u2019s Twitter numeric Account ID or username (excluding the @ character). See\u00a0[HERE](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/users/lookup)\u00a0or\u00a0[HERE](http://gettwitterid.com/)\u00a0for methods for looking up numeric Twitter Account IDs.  \nto:  \nMatches any Tweet that is in reply to a particular user.  \nThe value must be the user\u2019s numeric Account ID or username (excluding the @ character). See\u00a0[HERE](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/users/lookup)\u00a0for methods for looking up numeric Twitter Account IDs.  \nurl:\nPerforms a tokenized (keyword/phrase) match on the expanded URLs of a tweet (similar to url\\_contains). Tokens and phrases containing punctuation or special characters should be double-quoted. For example, url:\"/developer\". While generally not recommended, if you want to match on a specific protocol, enclose in double-quotes: url:\"https://developer.twitter.com\".  \n**Note:**\u00a0When using PowerTrack or Historical PowerTrack, this operator will match on URLs contained within the original Tweet of a Quote Tweet. For example, if your rule includes url:\"developer.twitter.com\", and a Tweet contains that URL, any Quote Tweets of that Tweet will be included in the results. This is not the case when using the Search API.\u00a0#  \nMatches any Tweet with the given hashtag.  \nThis operator performs an exact match, NOT a tokenized match, meaning the rule \u201c2016\u201d will match posts with the exact hashtag \u201c2016\u201d, but not those with the hashtag \u201c2016election\u201d  \nNote: that the hashtag operator relies on Twitter\u2019s entity extraction to match hashtags, rather than extracting the hashtag from the body itself. See [HERE](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/data-dictionary/native-enriched-objects/entities#hashtags) for more information on Twitter Entities JSON attributes.  \n@  \nMatches any Tweet that mentions the given username.  \nThe to: operator returns a subset match of the @mention operator.  \n$  \nMatches any Tweet that contains the specified \u2018cashtag\u2019 (where the leading character of the token is the \u2018$\u2019 character).  \nNote that the cashtag operator relies on Twitter\u2019s \u2018symbols\u2019 entity extraction to match cashtags, rather than trying to extract the cashtag from the body itself.\u00a0See\u00a0[HERE](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/data-dictionary/native-enriched-objects/entities#symbols)\u00a0for more information on Twitter Entities JSON attributes.  \nNote that this operator is only available in the enterprise search APIs.  \nretweets\\_of:  \n_Available alias_: retweets\\_of\\_user:  \nMatches tweets that are retweets of a specified user. Accepts both usernames and numeric Twitter Account IDs (NOT tweet status IDs).\nSee\u00a0[HERE](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/users/lookup) for methods for looking up numeric Twitter Account IDs.  \nlang:  \nMatches Tweets that have been classified by Twitter as being of a particular language (if, and only if, the tweet has been classified). It is important to note that each Tweet is currently only classified as being of one language, so AND\u2019ing together multiple languages will yield no results.  \n**Note:**\u00a0if no language classification can be made the provided result is \u2018und\u2019 (for undefined).  \nThe list below represents the current supported languages and their corresponding BCP 47 language indentifier:  \n|     |     |     |     |\n| --- | --- | --- | --- |\n| Amharic: am | German: de | Malayalam: ml | Slovak: sk |\n| Arabic: ar | Greek: el | Maldivian: dv | Slovenian: sl |\n| Armenian: hy | Gujarati: gu | Marathi: mr | Sorani Kurdish: ckb |\n| Basque: eu | Haitian Creole: ht | Nepali: ne | Spanish: es |\n| Bengali: bn | Hebrew: iw | Norwegian: no | Swedish: sv |\n| Bosnian: bs | Hindi: hi | Oriya: or | Tagalog: tl |\n| Bulgarian: bg | Latinized Hindi: hi-Latn | Panjabi: pa | Tamil: ta |\n| Burmese: my | Hungarian: hu | Pashto: ps | Telugu: te |\n| Croatian: hr | Icelandic: is | Persian: fa | Thai: th |\n| Catalan: ca | Indonesian: in | Polish: pl | Tibetan: bo |\n| Czech: cs | Italian: it | Portuguese: pt | Traditional Chinese: zh-TW |\n| Danish: da | Japanese: ja | Romanian: ro | Turkish: tr |\n| Dutch: nl | Kannada: kn | Russian: ru | Ukrainian: uk |\n| English: en | Khmer: km | Serbian: sr | Urdu: ur |\n| Estonian: et | Korean: ko | Simplified Chinese: zh-CN | Uyghur: ug |\n| Finnish: fi | Lao: lo | Sindhi: sd | Vietnamese: vi |\n| French: fr | Latvian: lv | Sinhala: si | Welsh: cy |\n| Georgian: ka | Lithuanian: lt |     |  \nplace:  \nMatches Tweets tagged with the specified location\u00a0_or_\u00a0Twitter place ID (see examples). Multi-word place names (\u201cNew York City\u201d, \u201cPalo Alto\u201d) should be enclosed in quotes.  \n**Note:**\u00a0See the\u00a0[GET geo/search](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/v1/geo/place-information/overview)\u00a0public API endpoint for how to obtain Twitter place IDs.  \n**Note:** This operator will not match on Retweets, since Retweet's places are attached to the original Tweet. It will also not match on places attached to the original Tweet of a Quote Tweet.  \nplace\\_country:  \nMatches Tweets where the country code associated with a tagged\u00a0[place](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/v1/geo/place-information/overview)\u00a0matches the given ISO alpha-2 character code.  \nValid ISO codes can be found here:\u00a0[http://en.wikipedia.org/wiki/ISO\\_3166-1\\_alpha-2](http://en.wikipedia.org/wiki/ISO_3166-1_alpha-2)  \n**Note:** This operator will not match on Retweets, since Retweet's places are attached to the original Tweet. It will also not match on places attached to the original Tweet of a Quote Tweet.  \npoint\\_radius:\\[lon lat radius\\]  \nMatches against the Exact Location (x,y) of the Tweet when present, and in Twitter, against a \u201cPlace\u201d geo polygon, where the Place is fully contained within the defined region.  \n* Units of radius supported are miles (mi) and kilometers (km).\n* Radius must be less than 25mi.\n* Longitude is in the range of \u00b1180\n* Latitude is in the range of \u00b190\n* All coordinates are in decimal degrees.\n* Rule arguments are contained with brackets, space delimited.  \n**Note:** This operator will not match on Retweets, since Retweet's places are attached to the original Tweet. It will also not match on places attached to the original Tweet of a Quote Tweet.  \nbounding\\_box:\\[west\\_long south\\_lat east\\_long north\\_lat\\]  \n_Available alias_: geo\\_bounding\\_box:  \nMatches against the Exact Location (long, lat) of the Tweet when present, and in Twitter, against a \u201cPlace\u201d geo polygon, where the Place is fully contained within the defined region.  \n* west\\_long south\\_lat represent the southwest corner of the bounding box where west-long is the longitude of that point, and south\\_lat is the latitude.\n* east\\_long and north\\_lat represent the northeast corner of the bounding box, where east\\_long is the longitude of that point, and north\\_lat is the latitude.\n* Width and height of the bounding box must be less than 25mi\n* Longitude is in the range of \u00b1180\n* Latitude is in the range of \u00b190\n* All coordinates are in decimal degrees.\n* Rule arguments are contained with brackets, space delimited.  \n**Note:** This operator will not match on Retweets, since Retweet's places are attached to the original Tweet. It will also not match on places attached to the original Tweet of a Quote Tweet.  \nprofile\\_country:  \nExact match on the \u201ccountryCode\u201d field from the \u201caddress\u201d object in the Profile Geo enrichment.  \nUses a normalized set of two-letter country codes, based on ISO-3166-1-alpha-2 specification. This operator is provided in lieu of an operator for \u201ccountry\u201d field from the \u201caddress\u201d object to be concise.  \nprofile\\_region:  \nMatches on the \u201cregion\u201d field from the \u201caddress\u201d object in the Profile Geo enrichment.  \nThis is an exact full string match. It is not necessary to escape characters with a backslash. For example, if matching something with a slash, use \u201cone/two\u201d, not \u201cone\\\\/two\u201d. Use double quotes to match substrings that contain whitespace or punctuation.  \nprofile\\_locality:  \nMatches on the \u201clocality\u201d field from the \u201caddress\u201d object in the Profile Geo enrichment.  \nThis is an exact full string match. It is not necessary to escape characters with a backslash. For example, if matching something with a slash, use \u201cone/two\u201d, not \u201cone\\\\/two\u201d. Use double quotes to match substrings that contain whitespace or punctuation.  \n**NOTE:**\u00a0All is: and has: operators cannot be used as standalone operators when using the Search API, and must be combined with another clause.  \nFor example, @TwitterDev has:links  \n|     |     |\n| --- | --- |\n| has:geo | Matches Tweets that have Tweet-specific geo location data provided from Twitter. This can be either \u201cgeo\u201d lat-long coordinate, or a \u201clocation\u201d in the form of a Twitter\u00a0[\u201cPlace\u201d](https://dev.twitter.com/overview/api/places), with corresponding display name, geo polygon, and other fields.<br><br>  <br><br>**Note:** When using the Search API, this operator must be used in conjunction with other operators that don't include `is:` or `has:`. |\n| has:profile\\_geo | _Available alias_: has:derived\\_user\\_geo<br><br>Matches Tweets that have any\u00a0[Profile Geo](http://support.gnip.com/enrichments/profile_geo.html)\u00a0metadata, regardless of the actual value.  <br>  <br><br>**Note:** When using the Search API, this operator must be used in conjunction with other operators that don't include `is:` or `has:`. |\n| has:links | This operators matches Tweets which contain links in the message body.  <br>  <br><br>**Note:** When using the Search API, this operator must be used in conjunction with other operators that don't include `is:` or `has:`. |\n| is:retweet | Deliver only explicit retweets that match a rule. Can also be negated to exclude retweets that match a rule from delivery and only original content is delivered.<br><br>This operator looks only for true Retweets, which use Twitter\u2019s retweet functionality. Quoted Tweets and Modified Tweets which do not use Twitter\u2019s retweet functionality will not be matched by this operator.<br><br>  <br><br>**Note:** When using the Search API, this operator must be used in conjunction with other operators that don't include `is:` or `has:`. |\n| is:reply | An operator to filter Tweets based on whether they are or are not replies to Tweets. Deliver only explicit replies that match a rule. Can also be negated to exclude replies that match a rule from delivery.<br><br>Note that this operator is available for paid premium and enterprise search and is not available in Sandbox dev environments.<br><br>  <br><br>**Note:** When using the Search API, this operator must be used in conjunction with other operators that don't include `is:` or `has:`. |\n| is:quote | Delivers only Quote Tweets, or Tweets that reference another Tweet, as identified by the \"is\\_quote\\_status\":true in Tweet payloads. Can also be negated to exclude Quote Tweets.  <br><br>**Note:** When using the Search API, this operator must be used in conjunction with other operators that don't include `is:` or `has:`. |\n| is:verified | Deliver only Tweets where the author is \u201cverified\u201d by Twitter. Can also be negated to exclude Tweets where the author is verified.  <br>  <br><br>**Note:** When using the Search API, this operator must be used in conjunction with other operators that don't include `is:` or `has:`. |\n| has:mentions | Matches Tweets that mention another Twitter user.  <br>  <br><br>**Note:** When using the Search API, this operator must be used in conjunction with other operators that don't include `is:` or `has:`. |\n| has:hashtags | Matches Tweets that contain a hashtag.  <br>  <br><br>**Note:** When using the Search API, this operator must be used in conjunction with other operators that don't include `is:` or `has:`. |\n| has:media | _Available alias_: has:media\\_link<br><br>Matches Tweets that contain a media url classified by Twitter. For example, pic.twitter.com.  <br>  <br><br>**Note:** When using the Search API, this operator must be used in conjunction with other operators that don't include `is:` or `has:`. |\n| has:images | Matches Tweets that contain a media url classified by Twitter.\u00a0For example, pic.twitter.com.  <br>  <br><br>**Note:** When using the Search API, this operator must be used in conjunction with other operators that don't include `is:` or `has:`. |\n| has:videos | _Available alias_: has:video\\_link<br><br>Matches Tweets that contain native Twitter videos, uploaded directly to Twitter. This will not match on videos created with Vine, Periscope, or Tweets with links to other video hosting sites.  <br>  <br><br>**Note:** When using the Search API, this operator must be used in conjunction with other operators that don't include `is:` or `has:`. |\n| has:symbols | Matches Tweets that contain a cashtag symbol (with a leading \u2018$\u2019 character.\u00a0For example, $tag). \u00a0Note that this operator is only available in the\u00a0enterprise\u00a0search APIs.  <br>  <br><br>**Note:** When using the Search API, this operator must be used in conjunction with other operators that don't include `is:` or `has:`. |\n",
        "line_start": 353,
        "line_end": 482
    },
    "22": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/changelog\n\nContent: \n# Resource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/changelog\nFull-archive search - Metadata and filtering timeline\n",
        "line_start": 557,
        "line_end": 559
    },
    "23": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/changelog\n\tFull-Archive Search metadata timeline\n\nContent: \n## Full-Archive Search metadata timeline  \nThat article discusses how the historical changes of the full-archive roadmap affects creating the filters needed to find your historical signal of interest. This article and a complementary [article about Historical PowerTrack](https://developer.twitter.com/en/docs/twitter-api/enterprise/historical-powertrack-api/guides/hpt-timeline), will serve as a \u2018compare and contrast\u2019 discussion of the two Twitter historical products.\n",
        "line_start": 560,
        "line_end": 562
    },
    "24": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/changelog\n\tFull-Archive Search metadata timeline\n\tProduct overview\n\nContent: \n### Product overview  \nThe enterprise-tier Full-archive Search was launched in August 2015, and the premium-tier version was launched in February 2018. These search products enable customers to immediately access any publicly available Tweet. With\u00a0Full-archive Search you submit a single query and receive a response in classic RESTful fashion.\u00a0Full-archive Search implements (up to) 500-Tweets-per-response pagination, and supports up to a 60-requests-per-minute (rpm) rate-limit for premium, 120 rpm for enterprise.\u00a0Given these details,\u00a0Full-archive Search can be used to rapidly retrieve Tweets, and at large scale using concurrent requests.  \nUnlike Historical PowerTrack, whose archive is based on a set of Tweet flat-files on disk, the\u00a0Full-archive Search Tweet archive is much like an on-line database. As with all databases, it supports making queries on its contents. It also makes use of an _index_ to enable high-performance data retrieval. With Full-archive search endpoints, the querying language is made up of PowerTrack Operators, and these Operators each correspond to a Tweet JSON attribute that is indexed.  \nAlso, like Historical PowerTrack, there are Tweet attributes that are current to the time a query is made. For example, if you are using Search API to access a Tweet posted in 2010 today, the user's profile description, account 'home' location, display name, and Tweet metrics for Favorites and Retweet counts will be updated to today\u2019s values and not what they were in 2010.\n",
        "line_start": 564,
        "line_end": 568
    },
    "25": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/changelog\n\tFull-Archive Search metadata timeline\n\tMetadata timelines\n\nContent: \n### Metadata timelines  \nBelow is a timeline of when Full-archive search endpoint Operators begin matching. In some cases Operator matching began well _after_ a \u2018communication convention\u2019 became commonplace on Twitter. For example, @Replies emerged as a user convention in 2006, but did not become a _first-class object_ or _event_ with \u2018supporting\u2019 JSON until early 2007. Accordingly, matching on @Replies in 2006 requires an examination of the Tweet body, rather than relying on the `to:` and `in_reply_to_status_id:` PowerTrack Operators.  \nThe details provided here were generated using Full-Archive Search (a product of hundreds of searches). This timeline is not 100% complete or precise. If you identify another filtering/metadata \u201cborn on date\u201d fundamental to your use-case, please let us know.  \nNote that the underlying Search index is subject to being rebuilt. Accordingly, these timeline details are subject to change.  \n#### 2006  \n* March 26 - `lang:`. An example of Tweet metadata being backfilled while generating the Search index.\n* July 13 - `has:mentions` begins matching.\n* October 6 - `has:symbols`. $cashtags (or symbols) for discussing stock symbols does not become common until early 2009. Until then most usages were probably slang (e.g., $slang).\n* October 26 - `has:links` begins matching.\n* November 23 - `has:hashtags` begins matching.  \n#### 2007  \n* January 30 - First first-class @reply (in\\_reply\\_to\\_user\\_id), `reply_to_status_id:` begins matching.\n* August 23 - Hashtags emerge as a common convention for organizing topics and conversations. First real use a week later.  \n#### 2009  \n* May 15 - `is:retweet`. Note that this Operator starts matching with the \u2018beta\u2019 release of official Retweets and its \u201cVia @\u2019 pattern. During this beta period, the Tweet verb is \u2018post\u2019 and the original Tweet is not included in the payload.\n* August 13 - Final version of official Retweets is released with \u201cRT @\u201d pattern, a verb set to \u2018share\u2019, and the \u2018retweet\\_status\u2019 attribute containing the original Tweet (thus approximately doubling the JSON payload size).  \n#### 2010  \n* March 6 - `has:geo`, `bounding_box:` and `point_radius:` geo Operators begin matching.\n* August 28 - `has:videos` (Until February 2015, this Operator matches on Tweets with links to select video hosting sites such as youtube.com, vimeo.com, and vivo.com).  \n#### 2011  \n* July 20 - `has:media` and `has:images` begin matching. Native photos officially announced August 9, 2010.  \n#### 2014  \n* December 3 - (Approximately) _Some_ [Enhanced URL metadata](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/enrichments/overview/expanded-and-enhanced-urls) with HTML title and description begins in payloads. Enhanced metadata more fully emerged in May 2016.  \n#### 2015  \n* February 10 - `has:videos` matches on \u2018native\u2019 Twitter videos.\n* February 17 - `has:profile_geo`, `profile_country:`, `profile_region:`, `profile_locality:` [Profile Geo](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/enrichments/overview/profile-geo) Operators begin matching.\n* February 17 - `place_country:` and `place:` Tweet geo Operators begin matching.  \n#### 2016  \n* May 1 - [Enhanced URL metadata](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/enrichments/overview/expanded-and-enhanced-urls) more fully available, and was officially announced as part of the [Gnip 2.0 launch in August 2016](https://blog.twitter.com/2016/gnip-2-is-here). No associated Operators for these metadata with Search APIs.  \n#### 2017  \n* February 22 - Poll metadata become available in enriched native format. No associated Operators for these metadata.  \n#### 2022  \n* September 27 - All Tweet objects created since this date have Edited Tweet metadata available. All Enterprise endpoints that provide Tweet objects were updated to provide this metadata starting on this date. The edit metadata provided includes\u00a0edit\\_history\u00a0and\u00a0edit\\_controls\u00a0objects. These metadata will not be returned for Tweets that were created before September 27, 2022. Currently, there are no Enterprise Operators available that match these metadata.\u00a0 To learn more about Edit Tweet metadata, check out the [Edit Tweets fundamentals](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/edit-tweets) page.  \n#### 2022  \n* September 29 - All Tweet objects created since this date have Edited Tweet metadata available. All Enterprise endpoints that provide Tweet objects were updated to provide this metadata starting on this date. The edit metadata provided includes\u00a0edit\\_history\u00a0and\u00a0edit\\_controls\u00a0objects. These metadata will not be returned for Tweets that were created before September 27, 2022. Currently, there are no Enterprise Operators available matching these metadata.\u00a0 To learn more about Edit Tweet metadata, check out the [Edit Tweets fundamentals](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/edit-tweets) page.\n",
        "line_start": 572,
        "line_end": 607
    },
    "26": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/changelog\n\tFull-Archive Search metadata timeline\n\tFiltering tips\n\nContent: \n### Filtering tips  \nGiven all the above timeline information, it is clear that there are a lot of details to consider when writing Search APIs filters. There are two key things to consider:  \n* Some metadata have \u2018born-on\u2019 dates so filters can result in _false negatives_. Such searches include Operators reliant on metadata that did not exist for all of part of the search period. For example, if you are searching for Tweets with the `has:images` Operator, you will not have any matches for periods before July 2011. That is because that Operator matches on _native_ photos (attached to a Tweet using the Twitter user-interface). For a more complete data set of photo-sharing Tweets, filters for before July 2011 would need to contain rule clauses that match on common URLs for photo hosting.\n* Some metadata has been backfilled with metadata from a time _after_ the Tweet was posted.  \nThere are several attribute types that are commonly focused on when creating PowerTrack queries:  \n* Twitter Profiles\n* Original or shared Tweets\n* Tweet language classification\n* Geo-referencing Tweets\n* Shared links media  \nSome of these have product-specific behavior while others have identical behavior. See below for more details.  \n#### Twitter Profiles  \nThe Search APIs serves historical Tweets with the user profile data set as it is at the _time of retrieval_. If you request a Tweet from 2014, the user\u2019s profile metadata will reflect how it exists at query-time.  \n#### Original Tweets and Retweets  \nThe PowerTrack `_is:retweet_` Operator enables users to either include or exclude Retweets. Users of this Operator need to have two strategies for Retweet matching (or not matching) for data before August 2009. Before August 2009, the Tweet message itself needs to be checked, using exact phrase matching, for matches on the \u201c@RT \u201d pattern (Actually, if you are filtering on Retweets from between May-August 2009, the \u201cVia @\u201d pattern should be included). For periods after August 2009, the _is:retweet_ Operator is available.  \n#### Tweet language classifications  \nFor filtering on a Tweet\u2019s language classification, Twitter\u2019s historical products are quite different. When the Search archive was built, all Tweets were backfilled with the Twitter language classification. Therefore the lang: Operator is available for the entire Tweet archive.  \n#### Geo-referencing Tweets  \nThere are three primary ways to geo-reference Tweets:  \n* **Geographical references in Tweet message.** Matching on geographic references in the Tweet message, while often the most challenging method since it depends on local knowledge, is an option for the entire Tweet archive. [Here](https://twitter.com/biz/statuses/28311) is an example geo-referenced match from 2006 for the San Francisco area based on a \u2018golden gate\u2019 filter.  \n* **Tweets geo-tagged by the user.**\u00a0With the search APIs the ability to start matching on Tweets with some Geo Operators started in March 2010, and with others in February 2015:  \n* March 6, 2010: `has:geo`, `bounding_box:` and `point_radius:`\n* February 17, 2015: `place_country:` and `place:`\n* **Account profile \u2018home\u2019 location set by the user.**\u00a0Profile Geo Operators are available in both Historical PowerTrack and the Search APIs. With the Search APIs, these Profile Geo metadata is available starting in February 2015. For Tweets posted before Profile Geo metadata became available, the `bio_location:` Operator is available which can be used to match on non-normalized user input.  \n#### Shared links and media  \nIn March 2012, the expanded URL enrichment was introduced. Before this time, the Tweet payloads included only the URL as provided by the user. So, if the user included a shortened URL it can be challenging to match on (expanded) URLs of interest. With the Search APIs, these metadata are available starting in March 2012.  \nIn July 2016, the enhanced URL enrichment was introduced. This enhanced version provides a web site\u2019s HTML title and description in the Tweet payload, along with Operators for matching on those. These metadata begin emerging in December 2014.  \nIn September 2016 Twitter introduced \u2018native attachments\u2019 where a trailing shared link is not counted against the 140 Tweet character limit. Both URL enrichments still apply to these shared links.  \nHere are when related Search Operators begin matching:  \n* 2006 October 26 - `has:links`\n* 2011 July 20 - `has:images` and `has:media`\n* 2011 August - `url:` with the [Expanded URLs enrichment](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/enrichments/overview/expanded-and-enhanced-urls) As early as September 2006 `(url:\"spotify.com\" OR url:gnip OR url:microsoft OR url:google OR url:youtube)` matches http://twitter.com/Adam/statuses/16602, even though there is no urls\\[\\] metadata in twitter\\_entities and gnip objects. \u201cyoutube.com\u201d is an example of message content that, without any urls\\[\\] metadata, matches url:youtube.\n* 2015 February 10 - `has:videos` for native videos. Between 2010/08/28 and 2015/02/10, this Operator matches on Tweets with links to select video hosting sites such as youtube.com, vimeo.com, and vivo.com.\n* 2016 May 1 - `url_title:` and `url_description:`, based on the [Enhanced URLs enrichment](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/enrichments/overview/expanded-and-enhanced-urls), generally available. First Enhanced URL metadata began appearing in December 2014.\n",
        "line_start": 633,
        "line_end": 667
    },
    "27": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/guides/changelog\n\tFull-Archive Search metadata timeline\n\tNext steps\n\nContent: \n### Next steps  \n* [Learn more about the Full-Archive Search API](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/search-api/overview)\n* [Learn more about Historical PowerTrack and its metadata and filtering timeline](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/historical-powertrack-api/guides/hpt-timeline)\n* [Choosing between Historical PowerTrack and Full-Archive Search APIs](https://developer.twitter.com/content/developer-twitter/en/docs/tutorials/choosing-historical-api)\n",
        "line_start": 113,
        "line_end": 117
    },
    "28": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/faq\n\nContent: \n# Resource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/faq\nFAQ\n",
        "line_start": 697,
        "line_end": 699
    },
    "29": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/faq\n\tFrequently asked questions\n\tGeneral Search Tweet API questions\n\nContent: \n## Frequently asked questions  \n### General Search Tweet API questions  \n**The number of Tweets I receive with the data endpoint doesn't match the number of Tweets identified by the counts endpoint. Why is this the case?**  \nThere is a known difference between results provided by the counts endpoint and the data endpoint. You may see a discrepancy in your results because the counts endpoint is pre-compliance (meaning that it does not account for things like deleted Tweets, scrub geo, etc.) whereas the data endpoint is compliant at the time of delivery and accounts for all compliance events. For further reference, please go to [this document](https://developer.twitter.com/content/developer-twitter/en/docs/tweets/search/api-reference/premium-search#CountsEndpoint) on our support site.  \n**\nI didn't receive a Tweet that should match my query. Why?**  \nThere are a few different reasons why this might have happened, including  \n1. the Tweet you expected to see is from a protected account\n2. because the data endpoint accounts for all compliance events (meaning that deleted Tweets, scrubbed geos, etc. will not be included in the response).  \n**\nMy query matched a Tweet but includes a keyword that I negated. Why is this happening?**  \nThis is likely due to a\u00a0wrong usage of our premium rules & filtering. Please review our documentation [here](https://developer.twitter.com/en/docs/tweets/rules-and-filtering/guides/using-premium-operators) and ensure you understand the restrictions around building rules.  \n**\nAre there any libraries that I can use to get started using the Search Tweet APIs?**  \nYes, there are, including:  \n* [Tweepy](http://www.tweepy.org/) - good for using the standard search/tweets product (Python)\n* [Twitter API](https://github.com/geduldig/TwitterAPI) - good for using both the standard and premium Search Tweet APIs (Python)\n* [Search Tweets Python](https://github.com/twitterdev/search-tweets-python) and [Search Tweets Ruby](https://github.com/twitterdev/search-tweets-ruby) - two good tools that can be used for both premium and enterprise (and v2!) Search Tweet\u00a0APIs  \nAll of the libraries that we directly support can be found on our TwitterDev GitHub page:\u00a0[https://github.com/twitterdev](https://github.com/twitterdev).  \nThere are [other third-party libraries](https://developer.twitter.com/en/docs/developer-utilities/twitter-libraries) that may also be helpful; however, please note that some of these may not work with our premium and enterprise products.  \n**\nWill\u00a0I ever receive less volume of Tweets than the value I set as the `maxResults` in my request to the data endpoint?**  \nYes. Our data endpoint paginates at either the specified `maxResults` or after 30 days.  \nFor example, if you have 800 Tweets in a given 30 day period, you will have to make two requests to pull the complete results; because the maximum number of Tweets that can be returned per request is 500 (`maxResults`). And if you just have 400 Tweets in month one, and then 100 Tweets in month two, you will also have to use two requests to pull the full results; because pagination takes place after a period of 30 days even if the first request returns less than the specified `maxResults` Tweets.  \n**\nIn what order are the matching Tweets returned?**  \nTweets are returned in reverse chronological order. For example, the first page of results will show the most recent Tweets that match the query, pagination will continue until the results posted dates get to the `fromDate` initially requested.  \n**How do Edit Tweets impact my usage and billing?**  \nOnly the original Tweet will count for billing purposes. Any subsequent edits will be ignored and not contribute to your overall activity count.  \nEnterprise  \n**I'm interested in learning more about the pricing of the enterprise Search Tweet API and in applying for this offering. How can I do this?**  \nOur enterprise solutions are customized with predictable pricing to meet the needs of your business. Please apply [here](https://developer.twitter.com/content/developer-twitter/en/enterprise-application) for more information.  \n**\nHow do I build a rule set that matches my use case?**  \n* Please refer to our enterprise Search Tweet APIs documentation [here](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/search-api/api-reference/enterprise-search)\n* Useful information on rules and filering can be found [here](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/rules-and-filtering/guides/using-enterprise-operators)\n* Useful information for using the data endpoint can be found [here](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/search-api/api-reference/enterprise-search#DataEndpoint)\n* Useful information for using the counts endpoint can be found [here](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/search-api/api-reference/enterprise-search#CountsEndpoint)\n* A list of available operators can be found [here](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/enterprise/search-api/overview#AvailableOperators)  \n**\nI have exceeded my request caps/limits for the month, but I need to access more data - what can I do?**  \nPlease get in touch with your Account Manager at Twitter who will be able to help you with this.\n",
        "line_start": 700,
        "line_end": 742
    },
    "30": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/faq\n\tFrequently asked questions\n\tError troubleshooting guide\n\nContent: \n### Error troubleshooting guide  \n**Code 404 - Not Found**  \n1. Please ensure you are using the right parameters for each endpoint (e.g. the `buckets`field can only be used with the counts endpoint, not the data endpoint)\n2. Please double check the `:product` `:account_name` and `:label` fields are correct. You can find your `:label` field in the GNIP Console (enterprise customers only).  \nl\n",
        "line_start": 770,
        "line_end": 775
    },
    "31": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tResource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/api-reference/enterprise-search\n\nContent: \n# Resource URL: https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/api-reference/enterprise-search\nEnterprise search APIs  \nenterprise-search\n",
        "line_start": 779,
        "line_end": 782
    },
    "32": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\nContent: \n# Enterprise search APIs  \nJump to on this page  \n[Introduction](#Introduction)  \n[Methods](#Methods)  \n[Authentication](#Authentication)  \n[Request/response behavior](#RequestResponseBehavior)  \n[Pagination](#Pagination)  \n[Data endpoint](#DataEndpoint)  \n[Data request parameters](#DataParameters)  \n[Example data requests and responses](#DataRequestExamples)  \n[Counts endpoint](#CountsEndpoint)  \n[Counts request parameters](#CountsParameters)  \n[Example counts requests and responses](#CountsRequestExamples)  \n[HTTP response codes](#HTTPCodes)\n",
        "line_start": 784,
        "line_end": 798
    },
    "33": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tIntroduction\u00a0[\u00b6](#introduction- \"Permalink to this headline\")\n\nContent: \n## Introduction\u00a0[\u00b6](#introduction- \"Permalink to this headline\")  \nThere are two enterprise search APIs:  \n* 30-Day Search API - provides Tweets posted with the last 30 days.\n* Full-Archive Search API - provides Tweets from as early as 2006, starting with the first Tweet posted in March 2006.  \nThese search APIs share a common design and the documentation below applies to both. Note that for Tweets created starting September 29, 2022, Tweet objects will include Tweet edit metadata that describes its edit history. See the [\"Edit Tweets\"](https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets) fundamentals page for more details.  \nBelow you will find important details needed when integrating with the enterprise search APIs:  \n* Methods for requesting Tweet data and counts\n* Authentication\n* Pagination\n* API request parameters and example requests\n* API response JSON payloads and example responses\n* HTTP response codes  \nThe enterprise APIs provide low-latency, full-fidelity, query-based access to the Tweet archive. The only difference in the two APIs is the time frame you can search, either the previous 30 days or from as early as 2006. Time frames can be specified with minute granularity. Tweet data is served in reverse chronological order, starting with the most recent Tweet that matches your query. Tweets are available from the search API approximately 30 seconds after being published.\n",
        "line_start": 812,
        "line_end": 825
    },
    "34": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tMethods\u00a0[\u00b6](#methods- \"Permalink to this headline\")\n\nContent: \n## Methods\u00a0[\u00b6](#methods- \"Permalink to this headline\")  \nThe base URI for enterprise search is `https://gnip-api.twitter.com/search/`.  \n| Method | Description |\n| --- | --- |\n| [POST /search/:product/accounts/:account\\_name/:label](#SearchRequests) | Retrieve Tweets from the past 30 days that match the specified PowerTrack rule. |\n| [POST /search/:product/accounts/:account\\_name/:label/counts](#CountRequests) | Retrieve the number of Tweets from the past 30 days that match the specified PowerTrack rule. |  \nWhere:  \n* `:product` indicates the search endpoint you are making requests to, either `30day` or `fullarchive`.\n* `:account_name` is the (case-sensitive) name associated with your account, as displayed at console.gnip.com\n* `:label` is the (case-sensitive) label associated with your search endpoint, as displayed at console.gnip.com  \nFor example, if the TwitterDev account has the 30-Day search product with a label of 'prod' (short for production), the search endpoints would be:  \n* Data endpoint: [https://gnip-api.twitter.com/search/30day/accounts/TwitterDev/prod.json](https://gnip-api.twitter.com/search/30day/accounts/TwitterDev/prod.json)\n* Counts endpoint: [https://gnip-api.twitter.com/search/30day/accounts/TwitterDev/prod/counts.json](https://gnip-api.twitter.com/search/30day/accounts/TwitterDev/prod/counts.json)  \nYour complete enterprise search API endpoint is displayed at [https://console.gnip.com](https://console.gnip.com/).  \nBelow there are several example requests using a simple HTTP utility called curl. These examples use URLs with `:product`, `:account_name`, and `:label`. To use these examples, be sure to update the URLs with your details.\n",
        "line_start": 832,
        "line_end": 847
    },
    "35": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tAuthentication\u00a0[\u00b6](#authentication- \"Permalink to this headline\")\n\nContent: \n## Authentication\u00a0[\u00b6](#authentication- \"Permalink to this headline\")  \nAll requests to the enterprise search APIs must use HTTP _Basic Authentication_, constructed from a valid email address and password combination used to log into your account at [https://console.gnip.com](https://console.gnip.com/). Credentials must be passed as the _Authorization_ header for each request.\n",
        "line_start": 856,
        "line_end": 858
    },
    "36": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tRequest/response behavior\u00a0[\u00b6](#request-response-behavior- \"Permalink to this headline\")\n\nContent: \n## Request/response behavior\u00a0[\u00b6](#request-response-behavior- \"Permalink to this headline\")  \nUsing the `fromDate` and `toDate` parameters, you can request any time period that the API supports. The 30-Day search API provides Tweets from the most recent 31 days (even though referred to as the '30-Day' API, it makes 31 days available to enable users to make complete-month requests). The Full-Archive search API provides Tweets back to the very first tweet (March 21, 2006). However, a single response will be limited to the lesser of your specified 'maxResults' or 31 days. If matching data or your time range exceeds your specified maxResults or 31 days, you will receive a 'next' token which you should use to paginate through the remainder of your specified time range.  \nFor example, say you are using Full-Archive search and want all Tweets matching your query from January 1, 2017 to June 30, 2017. You will specify that full six-month time period in your request using the `fromDate` and `toDate` parameters. The search API will respond with the first 'page' of Tweets, with the number of Tweets matching your `maxResults` parameter (which defaults to 100). Assuming there are more Tweets (and there most likely will be more), the API will also provide a 'next' token that enables you to make a request for the next 'page' of data. This process is repeated until the API does not return a 'next' token. See the next section for more details.\n",
        "line_start": 860,
        "line_end": 863
    },
    "37": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tPagination\u00a0[\u00b6](#pagination- \"Permalink to this headline\")\n\nContent: \n## Pagination\u00a0[\u00b6](#pagination- \"Permalink to this headline\")  \nWhen making both data and count requests it is likely that there is more data than can be returned in a single response. When that is the case the response will include a \u2018next\u2019 token. The \u2018next\u2019 token is provided as a root-level JSON attribute. Whenever a \u2018next\u2019 token is provided, there is additional data to retrieve so you will need to keep making API requests.  \n**Note:** The \u2018next\u2019 token behavior differs slightly for data and counts requests, and both are described below with example responses provided in the API Reference section.\n",
        "line_start": 866,
        "line_end": 869
    },
    "38": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tPagination\u00a0[\u00b6](#pagination- \"Permalink to this headline\")\n\tData pagination[\u00b6](#data-pagination \"Permalink to this headline\")\n\nContent: \n### Data pagination[\u00b6](#data-pagination \"Permalink to this headline\")  \nRequests for data will likely generate more data than can be returned in a single response. Each data request includes a parameter that sets the maximum number of Tweets to return per request. This `maxResults` parameter defaults to 100 and can be set to a range of 10-500. If your query matches more Tweets than the 'maxResults' parameter used in the request, the response will include a 'next' token (as a root-level JSON attribute). This 'next' token is used in the subsequent request to retrieve the next portion of the matching Tweets for that query (i.e. the next 'page\u201d). Next tokens will continue to be provided until you have reached the last 'page' of results for that query when no 'next' token is provided.  \nTo request the next 'page' of data, you must make the exact same query as the original, including `query`, `toDate`, and `fromDate` parameters, if used, and also include a 'next' request parameter set to the value from the previous response. This can be utilized with either a GET or POST request. However, the 'next' parameter must be URL encoded in the case of a GET request.  \nYou can continue to pass in the 'next' element from your previous query until you have received all Tweets from the time period covered by your query. When you receive a response that does not include a 'next' element, it means that you have reached the last page and no additional data is available for the specified query and time range.\n",
        "line_start": 872,
        "line_end": 876
    },
    "39": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tPagination\u00a0[\u00b6](#pagination- \"Permalink to this headline\")\n\tCounts pagination[\u00b6](#counts-pagination \"Permalink to this headline\")\n\nContent: \n### Counts pagination[\u00b6](#counts-pagination \"Permalink to this headline\")  \nThe 'counts' endpoint provides Tweet volumes associated with a query on either a daily, hourly, or per-minute basis. The 'counts' API endpoint will return a timestamped array of counts for a maximum of a 31-day payload of counts. If you request more than 31 days of counts you will be provided a 'next' token. As with the data 'next' tokens, you must make the exact same query as the original and also include a 'next' request parameter set to the value from the previous response.  \nBeyond requesting more than 31 days of counts, there is another scenario when a 'next' token is provided. For higher volume queries, there is the potential that the generation of counts will take long enough to trigger a response timeout. When this occurs you will receive less than 31 days of counts but will be provided a 'next' token in order to continue making requests for the entire payload of counts. **_Important:_** Timeouts will only issue full \"buckets\" - so 2.5 days would result in 2 full day \"buckets\".\n",
        "line_start": 880,
        "line_end": 883
    },
    "40": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tPagination\u00a0[\u00b6](#pagination- \"Permalink to this headline\")\n\tAdditional notes[\u00b6](#additional-notes \"Permalink to this headline\")\n\nContent: \n### Additional notes[\u00b6](#additional-notes \"Permalink to this headline\")  \n* When using a fromDate or toDate in a search request, you will only get results from within your time range. When you reach the last group of results within your time range, you will not receive a 'next' token.\n* The 'next' element can be used with any maxResults value between 10-500 (with a default value of 100). The maxResults determines how many Tweets are returned in each response, but does not prevent you from eventually getting all results.\n* The 'next' element does not expire. Multiple requests using the same 'next' query will receive the same results, regardless of when the request is made.\n* When paging through results using the 'next' parameter, you may encounter duplicates at the edges of the query. Your application should be tolerant of these.\n",
        "line_start": 886,
        "line_end": 891
    },
    "41": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tData endpoint \u00a0[\u00b6](#data-endpoint- \"Permalink to this headline\")\n\tPOST /search/:product/:label[\u00b6](#post-search-product-label \"Permalink to this headline\")\n\nContent: \n## Data endpoint \u00a0[\u00b6](#data-endpoint- \"Permalink to this headline\")  \n### POST /search/:product/:label[\u00b6](#post-search-product-label \"Permalink to this headline\")  \n#### Endpoint pattern:  \nThis endpoint returns data for the specified query and time period. If a time period is not specified the time parameters will default to the last 30 days. Note: This functionality can also be accomplished using a GET request, instead of a POST, by encoding the parameters described below into the URL.\n",
        "line_start": 893,
        "line_end": 897
    },
    "42": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tData endpoint \u00a0[\u00b6](#data-endpoint- \"Permalink to this headline\")\n\tData request parameters\u00a0[\u00b6](#data-request-parameters- \"Permalink to this headline\")\n\nContent: \n### Data request parameters\u00a0[\u00b6](#data-request-parameters- \"Permalink to this headline\")  \n| Parameters | Description | Required | Sample Value |\n| --- | --- | --- | --- |\n| query | The equivalent of one PowerTrack rule, with up to 2,048 characters (and no limits on the number of positive and negative clauses).  <br>  <br>This parameter should include ALL portions of the PowerTrack rule, including all operators, and portions of the rule should not be separated into other parameters of the query.  <br>  <br>**Note:** Not all PowerTrack operators are supported. Supported Operators are listed [HERE](https://developer.twitter.com/en/docs/tweets/search/overview/enterprise#AvailableOperators). | Yes | (snow OR cold OR blizzard) weather |\n| tag | Tags can be used to segregate rules and their matching data into different logical groups. If a rule tag is provided the rule tag is included in the 'matching\\_rules' attribute.  <br>  <br>It is recommended to assign rule-specific UUIDs to rule tags and maintain desired mappings on the client side. | No  | 8HYG54ZGTU |\n| fromDate | The oldest UTC timestamp (back to 3/21/2006 with Full-Archive search) from which the Tweets will be provided. Timestamp is in minute granularity and is inclusive (i.e. 12:00 includes the 00 minute).  <br>  <br>_Specified:_ Using only the fromDate with no toDate parameter will deliver results for the query going back in time from now( ) until the fromDate.  <br>  <br>_Not Specified:_ If a fromDate is not specified, the API will deliver all of the results for 30 days prior to now( ) or the toDate (if specified).  <br>  <br>If neither the fromDate or toDate parameter is used, the API will deliver all results for the most recent 30 days, starting at the time of the request, going backwards. | No  | 201207220000 |\n| toDate | The latest, most recent UTC timestamp to which the Tweets will be provided. Timestamp is in minute granularity and is not inclusive (i.e. 11:59 does not include the 59th minute of the hour).  <br>  <br>_Specified:_ Using only the toDate with no fromDate parameter will deliver the most recent 30 days of data prior to the toDate.  <br>  <br>_Not Specified:_ If a toDate is not specified, the API will deliver all of the results from now( ) for the query going back in time to the fromDate.  <br>  <br>If neither the fromDate or toDate parameter is used, the API will deliver all results for the entire 30-day index, starting at the time of the request, going backwards. | No  | 201208220000 |\n| maxResults | The maximum number of search results to be returned by a request. A number between 10 and the system limit (currently 500). By default, a request response will return 100 results. | No  | 500 |\n| next | This parameter is used to get the next 'page' of results as described [HERE](#Pagination). The value used with the parameter is pulled directly from the response provided by the API, and should not be modified. | No  | NTcxODIyMDMyODMwMjU1MTA0 |  \n#### Additional details  \n|     |     |\n| --- | --- |\n| **Available Timeframe** | 30-Day: last 31 days  <br>Full-Archive: March 21, 2006 - Present |\n| **Query Format** | The equivalent of one PowerTrack rule, with up to 2,048 characters (and no limits on the number of positive and negative clauses).  <br>  <br>**Note:** Not all PowerTrack operators are supported. Refer to [Available operators](https://developer.twitter.com/en/docs/tweets/search/overview/enterprise#AvailableOperators) for a list of supported operators. |\n| **Rate Limit** | Partners will be rate limited at both minute and second granularity. The per minute rate limit will vary by partner as specified in your contract. However, these per-minute rate limits are not intended to be used in a single burst. Regardless of your per minute rate limit, all partners will be limited to a maximum of 20 requests per second, aggregated across all requests for data and/or counts. |\n| **Compliance** | All data delivered via the Full-Archive Search API is compliant at the time of delivery. |\n| **Realtime Availability** | Data is available in the index within 30 seconds of generation on the Twitter Platform |\n",
        "line_start": 901,
        "line_end": 918
    },
    "43": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tData endpoint \u00a0[\u00b6](#data-endpoint- \"Permalink to this headline\")\n\tExample data requests and responses\u00a0[\u00b6](#example-data-requests-and-responses- \"Permalink to this headline\")\n\nContent: \n### Example data requests and responses\u00a0[\u00b6](#example-data-requests-and-responses- \"Permalink to this headline\")  \n#### Example POST request  \n* Request parameters in a POST request are sent via a JSON-formatted body, as shown below.\n* All portions of the PowerTrack rule being queried for (e.g. keywords, other operators like bounding\\_box:) should be placed in the 'query' parameter.\n* Do not split portions of the rule out as separate parameters in the query URL.  \nHere is an example POST (using cURL) command for making an initial data request:  \ncurl -X POST -u<username> \"https://gnip-api.twitter.com/search/:product/accounts/:account_name/:label.json\" -d '{\"query\":\"from:twitterDev\",\"maxResults\":500,\"fromDate\":\"yyyymmddhhmm\",\"toDate\":\"yyyymmddhhmm\"}'  \nIf the API data response includes a 'next' token, below is a subsequent request that consists of the original request, with the 'next' parameter set to the provided token:  \ncurl -X POST -u<username> \"https://gnip-api.twitter.com/search/:product/accounts/:account_name/:label.json\" -d '{\"query\":\"from:twitterDev\",\"maxResults\":500,\"fromDate\":\"yyyymmddhhmm\",\"toDate\":\"yyyymmddhhmm\",\n\"next\":\"NTcxODIyMDMyODMwMjU1MTA0\"}'  \n#### Example GET request  \n* Request parameters in a GET request are encoded into the URL, using standard URL encoding.\n* All portions of the PowerTrack rule being queried for (e.g. keywords, other operators like bounding\\_box:) should be placed in the 'query' parameter.\n* Do not split portions of the rule out as separate parameters in the query URL.  \nHere is an example GET (using cURL) command for making an initial data request:  \ncurl -u<username> \"http://gnip-api.twitter.com/search/:product/accounts/:account_name/:label.json?query=from%3Atwitterdev&maxResults=500&fromDate=yyyymmddhhmm&toDate=yyyymmddhhmm\"  \n#### Example data responses  \nNote that for Tweets created starting September 29, 2022, Tweet objects will include Tweet edit metadata that describes its edit history. See the [\"Edit Tweets\"](https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets) fundamentals page for more details.  \nBelow is an example response to a data query. This example assumes that there were more than \u2018maxResults\u2019 Tweets available so a 'next' token is provided for subsequent requests. If 'maxResults' or fewer Tweets are associated with your query, no 'next' token would be included in the response.\nThe value of the 'next' element will change with each query and should be treated as an opaque string. The 'next' element will look like the following in the response body:  \n{\n\"results\":\n[\n{--Tweet 1--},\n{--Tweet 2--},\n...\n{--Tweet 500--}\n],\n\"next\":\"NTcxODIyMDMyODMwMjU1MTA0\",\n\"requestParameters\":\n{\n\"maxResults\":500,\n\"fromDate\":\"201101010000\",\n\"toDate\":\"201201010000\"\n}\n}  \nThe response to a subsequent request might look like the following (note the new Tweets and different 'next' value):  \n{\n\"results\":\n[\n{--Tweet 501--},\n{--Tweet 502--},\n...\n{--Tweet 1000--}\n],\n\"next\":\"R2hCDbpBFR6eLXGwiRF1cQ\",\n\"requestParameters\":\n{\n\"maxResults\":500,\n\"fromDate\":\"201101010000\",\n\"toDate\":\"201201010000\"\n}\n}  \nYou can continue to pass in the 'next' element from your previous query until you have received all Tweets from the time period covered by your query. When you receive a response that does not include a 'next' element, it means that you have reached the last page and no additional data is available in your time range.  \n* * *\n",
        "line_start": 924,
        "line_end": 979
    },
    "44": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tCounts endpoint \u00a0[\u00b6](#counts-endpoint- \"Permalink to this headline\")\n\t/search/:stream/counts[\u00b6](#-search-stream-counts \"Permalink to this headline\")\n\nContent: \n## Counts endpoint \u00a0[\u00b6](#counts-endpoint- \"Permalink to this headline\")  \n### /search/:stream/counts[\u00b6](#-search-stream-counts \"Permalink to this headline\")  \n#### Endpoint pattern:  \n`/search/fullarchive/accounts/:account_name/:label/counts.json`  \nThis endpoint returns counts (data volumes) data for the specified query. If a time period is not specified the time parameters will default to the last 30 days. Data volumes are returned as a timestamped array on either daily, hourly (default), or by the minute.  \n**Note:** This functionality can also be accomplished using a GET request, instead of a POST, by encoding the parameters described below into the URL.\n",
        "line_start": 998,
        "line_end": 1004
    },
    "45": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tCounts endpoint \u00a0[\u00b6](#counts-endpoint- \"Permalink to this headline\")\n\tCounts request parameters\u00a0[\u00b6](#counts-request-parameters- \"Permalink to this headline\")\n\nContent: \n### Counts request parameters\u00a0[\u00b6](#counts-request-parameters- \"Permalink to this headline\")  \n| Parameters | Description | Required | Sample Value |\n| --- | --- | --- | --- |\n| query | The equivalent of one PowerTrack rule, with up to 2,048 characters (and no limits on the number of positive and negative clauses).  <br>  <br>This parameter should include ALL portions of the PowerTrack rule, including all operators, and portions of the rule should not be separated into other parameters of the query.  <br>  <br>**Note:** Not all PowerTrack operators are supported. Refer to [Available operators](https://developer.twitter.com/en/docs/tweets/search/overview/enterprise#AvailableOperators) for a list of supported operators. | Yes | (snow OR cold OR blizzard) weather |\n| fromDate | The oldest UTC timestamp (back to 3/21/2006) from which the Tweets will be provided. Timestamp is in minute granularity and is inclusive (i.e. 12:00 includes the 00 minute).  <br>  <br>_Specified:_ Using only the fromDate with no toDate parameter, the API will deliver counts (data volumes) data for the query going back in time from now until the fromDate. If the fromDate is older than 31 days from now( ), you will receive a next token to page through your request.  <br>  <br>_Not Specified:_ If a fromDate is not specified, the API will deliver counts (data volumes) for 30 days prior to now( ) or the toDate (if specified).  <br>  <br>If neither the fromDate or toDate parameter is used, the API will deliver counts (data volumes) for the most recent 30 days, starting at the time of the request, going backwards. | No  | 201207220000 |\n| toDate | The latest, most recent UTC timestamp to which the Tweets will be provided. Timestamp is in minute granularity and is not inclusive (i.e. 11:59 does not include the 59th minute of the hour).  <br>  <br>_Specified:_ Using only the toDate with no fromDate parameter will deliver the most recent counts (data volumes) for 30 days prior to the toDate.  <br>  <br>_Not Specified:_ If a toDate is not specified, the API will deliver counts (data volumes) for the query going back in time to the fromDate. If the fromDate is more than 31 days from now( ), you will receive a next token to page through your request.  <br>  <br>If neither the fromDate or toDate parameter is used, the API will deliver counts (data volumes) for the most recent 30 days, starting at the time of the request, going backwards. | No  | 201208220000 |\n| bucket | The unit of time for which count data will be provided. Count data can be returned for every day, hour or minute in the requested timeframe. By default, hourly counts will be provided. Options: 'day', 'hour', 'minute' | No  | minute |\n| next | This parameter is used to get the next 'page' of results as described [HERE](#Pagination). The value used with the parameter is pulled directly from the response provided by the API, and should not be modified. | No  | NTcxODIyMDMyODMwMjU1MTA0 |  \n#### Additional details  \n|     |     |\n| --- | --- |\n| **Available Timeframe** | 30-Day: last 31 days  <br>Full-Archive: March 21, 2006 - Present |\n| **Query Format** | The equivalent of one PowerTrack rule, with up to 2,048 characters.  <br>  <br>**Note:** Not all PowerTrack operators are supported. Refer to [Available operators](https://developer.twitter.com/en/docs/tweets/search/overview/enterprise#AvailableOperators) for a list of supported operators. |\n| **Rate Limit** | Partners will be rate limited at both minute and second granularity. The per minute rate limit will vary by partner as specified in your contract. However, these per-minute rate limits are not intended to be used in a single burst. Regardless of your per minute rate limit, all partners will be limited to a maximum of 20 requests per second, aggregated across all requests for data and/or counts. |\n| **Count Precision** | The counts delivered through this endpoint reflect the number of Tweets that occurred and do not reflect any later compliance events (deletions, scrub geos). Some Tweets counted may not be available via data endpoint due to user compliance actions. |\n",
        "line_start": 1010,
        "line_end": 1025
    },
    "46": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tCounts endpoint \u00a0[\u00b6](#counts-endpoint- \"Permalink to this headline\")\n\tExample counts requests and responses\u00a0[\u00b6](#example-counts-requests-and-responses- \"Permalink to this headline\")\n\nContent: \n### Example counts requests and responses\u00a0[\u00b6](#example-counts-requests-and-responses- \"Permalink to this headline\")  \n#### Example POST request  \n* Request parameters in a POST request are sent via a JSON-formatted body, as shown below.\n* All portions of the PowerTrack rule being queried for (e.g. keywords, other operators like bounding\\_box:) should be placed in the 'query' parameter.\n* Do not split portions of the rule out as separate parameters in the query URL.  \nHere is an example POST (using cURL) command for making an initial counts request:  \ncurl -X POST -u<username> \"https://gnip-api.twitter.com/search/:product/accounts/:account_name/:label/counts.json\" -d '{\"query\":\"TwitterDev\",\"fromDate\":\"yyyymmddhhmm\",\"toDate\":\"yyyymmddhhmm\",\"bucket\":\"day\"}'  \nIf the API counts response includes a 'next' token, below is a subsequent request that consists of the original request, with the 'next' parameter set to the provided token:  \ncurl -X POST -u<username> \"https://gnip-api.twitter.com/search/:product/accounts/:account_name/:label/counts.json\" -d '{\"query\":\"TwitterDev\",\"fromDate\":\"yyyymmddhhmm\",\"toDate\":\"yyyymmddhhmm\",\"bucket\":\"day\",\n\"next\":\"YUcxO87yMDMyODMwMjU1MTA0\"}'  \n#### Example GET request  \n* Request parameters in a GET request are encoded into the URL, using standard URL encoding\n* All portions of the PowerTrack rule being queried for (e.g. keywords, other operators like bounding\\_box:) should be placed in the 'query' parameter\n* Do not split portions of the rule out as separate parameters in the query URL  \nHere is an example GET (using cURL) command for making an initial counts request:  \ncurl -u<username> \"http://gnip-api.twitter.com/search/fullarchive/accounts/:account_name/:label/counts.json?query=TwitterDev&bucket=day&fromDate=yyyymmddhhmm&toDate=yyyymmddhhmm\"  \n#### Example counts responses  \nBelow is an example response to a counts (data volume) query. This example response includes a 'next' token, meaning the counts request was for more than 31 days, or that the submitted query had a large enough volume associated with it to trigger a partial response.  \nThe value of the 'next' element will change with each query and should be treated as an opaque string. The 'next' element will look like the following in the response body:  \n{\n\"results\": [\n{ \"timePeriod\": \"201101010000\", \"count\": 32 },\n{ \"timePeriod\": \"201101020000\", \"count\": 45 },\n{ \"timePeriod\": \"201101030000\", \"count\": 57 },\n{ \"timePeriod\": \"201101040000\", \"count\": 123 },\n{ \"timePeriod\": \"201101050000\", \"count\": 134 },\n{ \"timePeriod\": \"201101060000\", \"count\": 120 },\n{ \"timePeriod\": \"201101070000\", \"count\": 43 },\n{ \"timePeriod\": \"201101080000\", \"count\": 65 },\n{ \"timePeriod\": \"201101090000\", \"count\": 85 },\n{ \"timePeriod\": \"201101100000\", \"count\": 32 },\n{ \"timePeriod\": \"201101110000\", \"count\": 23 },\n{ \"timePeriod\": \"201101120000\", \"count\": 85 },\n{ \"timePeriod\": \"201101130000\", \"count\": 32 },\n{ \"timePeriod\": \"201101140000\", \"count\": 95 },\n{ \"timePeriod\": \"201101150000\", \"count\": 109 },\n{ \"timePeriod\": \"201101160000\", \"count\": 34 },\n{ \"timePeriod\": \"201101170000\", \"count\": 74 },\n{ \"timePeriod\": \"201101180000\", \"count\": 24 },\n{ \"timePeriod\": \"201101190000\", \"count\": 90 },\n{ \"timePeriod\": \"201101200000\", \"count\": 85 },\n{ \"timePeriod\": \"201101210000\", \"count\": 93 },\n{ \"timePeriod\": \"201101220000\", \"count\": 48 },\n{ \"timePeriod\": \"201101230000\", \"count\": 37 },\n{ \"timePeriod\": \"201101240000\", \"count\": 54 },\n{ \"timePeriod\": \"201101250000\", \"count\": 52 },\n{ \"timePeriod\": \"201101260000\", \"count\": 84 },\n{ \"timePeriod\": \"201101270000\", \"count\": 120 },\n{ \"timePeriod\": \"201101280000\", \"count\": 34 },\n{ \"timePeriod\": \"201101290000\", \"count\": 83 },\n{ \"timePeriod\": \"201101300000\", \"count\": 23 },\n{ \"timePeriod\": \"201101310000\", \"count\": 12 }\n],\n\"totalCount\":2027,\n\"next\":\"NTcxODIyMDMyODMwMjU1MTA0\",\n\"requestParameters\":\n{\n\"bucket\":\"day\",\n\"fromDate\":\"201101010000\",\n\"toDate\":\"201201010000\"\n}\n}  \nThe response to a subsequent request might look like the following (note the new counts timeline and different 'next' value):  \n{\n\"results\": [\n{ \"timePeriod\": \"201102010000\", \"count\": 45 },\n{ \"timePeriod\": \"201102020000\", \"count\": 76 },\n....\n{ \"timePeriod\": \"201103030000\", \"count\": 13 }\n],\n\"totalCount\":3288,\n\"next\":\"WE79fnakFanyMDMyODMwMjU1MTA0\",\n\"requestParameters\":\n{\n\"bucket\":\"day\",\n\"fromDate\":\"201101010000\",\n\"toDate\":\"201201010000\"\n}\n}  \nYou can continue to pass in the 'next' element from your previous query until you have received all counts from the query time period. When you receive a response that does not include a 'next' element, it means that you have reached the last page and no additional counts are available in your time range.\n",
        "line_start": 1029,
        "line_end": 1109
    },
    "47": {
        "content": "Source document: ../data/platform-docs-versions/X_Twitter-API-Enterprise/Search API.md\nParagraph location: \n\tEnterprise search APIs\n\tHTTP response codes\u00a0[\u00b6](#http-response-codes- \"Permalink to this headline\")\n\nContent: \n## HTTP response codes\u00a0[\u00b6](#http-response-codes- \"Permalink to this headline\")  \n| Status | Text | Description |\n| --- | --- | --- |\n| 200 | OK  | The request was successful. The JSON response will be similar to the following: |\n| 400 | Bad Request | Generally, this response occurs due to the presence of invalid JSON in the request, or where the request failed to send any JSON payload. |\n| 401 | Unauthorized | HTTP authentication failed due to invalid credentials. Log in to console.gnip.com with your credentials to ensure you are using them correctly with your request. |\n| 404 | Not Found | The resource was not found at the URL to which the request was sent, likely because an incorrect URL was used. |\n| 422 | Unprocessable Entity | This is returned due to invalid parameters in the query -- e.g. invalid PowerTrack rules. |\n| 429 | Unknown Code | Your app has exceeded the limit on connection requests. The corresponding JSON message will look similar to the following: |\n| 500 | Internal Server Error | There was an error on the server side. Retry your request using an exponential backoff pattern. |\n| 502 | Proxy Error | There was an error on server side. Retry your request using an exponential backoff pattern. |\n| 503 | Service Unavailable | There was an error on server side. Retry your request using an exponential backoff pattern. |\n",
        "line_start": 1128,
        "line_end": 1140
    }
}