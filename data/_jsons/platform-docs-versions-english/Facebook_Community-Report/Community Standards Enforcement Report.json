{
    "0": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\nContent: \n[Home](https://transparency.fb.com/)  \n[Data](https://transparency.fb.com/reports/)  \n[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)\n",
        "line_start": 0,
        "line_end": 3,
        "url": "https://transparency.fb.com/)"
    },
    "1": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tCommunity Standards Enforcement Report\n\nContent: \n# Community Standards Enforcement Report  \nWe want Facebook and Instagram to be places where people have a voice. To create conditions where everyone feels comfortable expressing themselves, we must also protect their safety, privacy, dignity and authenticity. This is why we have the [Facebook Community Standards](https://transparency.fb.com/policies/community-standards/) and [Instagram Community Guidelines](https://www.facebook.com/help/instagram/477434105621119), which define what is and is not allowed in our community.  \nFacebook  \nFacebook  \nInstagram  \n[Download (CSV)](https://transparency.fb.com/sr/community-standards/)\n",
        "line_start": 6,
        "line_end": 12,
        "url": "https://transparency.fb.com/)"
    },
    "2": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tCommunity Standards Enforcement Report\n\tQ3 2023 report\n\nContent: \n## Q3 2023 report  \nWe publish the Community Standards Enforcement Report on a quarterly basis to more effectively track our progress and demonstrate our continued commitment to making Facebook and Instagram safe and inclusive.  \n#### What's new  \nIn this November 2023 quarterly report, we share updated metrics for the reporting period from July to September 2023, detailing our progress on content that violates our policies.\n",
        "line_start": 18,
        "line_end": 22,
        "url": "https://transparency.fb.com/)"
    },
    "3": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tCommunity Standards Enforcement Report\n\tQ2 2023 report\n\nContent: \n## Q2 2023 report  \nWe publish the Community Standards Enforcement Report on a quarterly basis to more effectively track our progress and demonstrate our continued commitment to making Facebook and Instagram safe and inclusive.  \n#### What's new  \nIn this August 2023 quarterly report, we share updated metrics for the reporting period from April to June 2023, detailing our progress on content that violates our policies.  \n#### Facebook and Instagram policies  \nFacebook and Instagram share content policies. Content that is considered violating on Facebook is also considered violating on Instagram. Throughout this report, we link to our Community Standards, which include the most comprehensive descriptions of these policies.  \nAs we improve our methodologies, measure violations in more languages or across new parts of Facebook and Instagram and update our policies, the way we define and measure enforcement may change. As a result, historical comparisons may be imperfect.  \n#### Learn more  \n* [**Review EY\u2019s independent, third-party assessment of our Community Standards Enforcement Report from the fourth quarter of 2021.**](https://about.fb.com/news/2022/05/community-standards-enforcement-report-assessment-results/)  \n* [**Review a report from independent academic experts on their findings and recommendations on our data transparency efforts**](https://law.yale.edu/yls-today/news/facebook-data-transparency-advisory-group-releases-final-report?fbclid=IwAR2xMZr5GdD1GaNpjsXR3_yeeIR4H9iFASfrni5HKcJVAO5oWA52bvwcZxU).  \n[14  \nPolicies on Facebook](https://transparency.fb.com/data/community-standards-enforcement/adult-nudity-and-sexual-activity/facebook)  \n[12  \nPolicies on Instagram](https://transparency.fb.com/data/community-standards-enforcement/adult-nudity-and-sexual-activity/instagram)  \n[Read our post about this report  \n---------------------------------](https://transparency.fb.com/integrity-reports-q3-2023)\n",
        "line_start": 26,
        "line_end": 42,
        "url": "https://transparency.fb.com/)"
    },
    "4": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tCommunity Standards Enforcement Report\n\tQ3 2023\n\nContent: \n## Q3 2023  \n35.1 million  \n--------------  \nContent Actioned on Adult Nudity and Sexual Activity  \n------------------------------------------------------  \nContent actioned decreased from 51.2 million in Q2 2023 to 35.1 million in Q3 2023, returning to pre-Q2 levels after an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/adult-nudity-and-sexual-activity/facebook/#content-actioned)  \n## Q3 2023  \n92.4%  \n-------  \nProactive Rate on Adult Nudity and Sexual Activity  \n----------------------------------------------------  \nProactive rate decreased from 93.8% in Q2 2023 to 92.4% in Q3 2023, due to a bug in our proactive detection technology.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/adult-nudity-and-sexual-activity/facebook/#proactive-rate)  \n## Q3 2023  \n1.6 million  \n-------------  \nAppealed Content on Adult Nudity and Sexual Activity  \n------------------------------------------------------  \nAppealed content increased from 1.0 million in Q2 2023 to 1.6 million in Q3 2023, as we increased our appeals period to adhere to the Digital Services Act.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/adult-nudity-and-sexual-activity/instagram/#appealed-content)  \n## Q3 2023  \n87.8%  \n-------  \nProactive Rate on Bullying and Harassment  \n-------------------------------------------  \nProactive rate increased from 65.8% in Q2 2023 to 87.8% in Q3 2023, due to an update in our calculation to the proactive rate.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/bullying-and-harassment/facebook/#proactive-rate)  \n## Q3 2023  \n1.6 million  \n-------------  \nAppealed Content on Bullying and Harassment  \n---------------------------------------------  \nAppealed content increased from 847K in Q2 2023 to 1.6 million in Q3 2023, as we increased our appeals period to adhere to the Digital Services Act.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/bullying-and-harassment/instagram/#appealed-content)  \n## Q3 2023  \n16.9 million  \n--------------  \nContent Actioned on Child Endangerment: Sexual Exploitation  \n-------------------------------------------------------------  \nContent actioned increased from 7.2 million in Q2 2023 to 16.9 million in Q3 2023, due to a large takedown of coordinated behavior violating our policies.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#content-actioned)  \n## Q3 2023  \n99%  \n-----  \nProactive Rate on Child Endangerment: Sexual Exploitation  \n-----------------------------------------------------------  \nProactive rate increased from 96.9% in Q2 2023 to 99% in Q3 2023, due to an increase in proactive detection technology mentioned in content actioned.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#proactive-rate)  \n## Q3 2023  \n267K  \n------  \nAppealed Content on Child Endangerment: Sexual Exploitation  \n-------------------------------------------------------------  \nAppealed content increased from 147K in Q2 2023 to 267K in Q3 2023, due to an increase in proactive detection technology taking down content violating our policies.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#appealed-content)  \n## Q3 2023  \n204K  \n------  \nRestored Content on Child Endangerment: Sexual Exploitation  \n-------------------------------------------------------------  \nRestored content increased from 80K in Q2 2023 to 204K in Q3 2023, due to adjustments in our proactive detection technology.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#restored-content)  \n## Q3 2023  \n750K  \n------  \nContent Actioned on Dangerous Organizations and Individuals: Organized Hate  \n-----------------------------------------------------------------------------  \nContent actioned decreased from 1.1 million in Q2 2023 to 750K in Q3 2023, returning to Q2 levels after a spike in reported viral links in April.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/facebook/#content-actioned)  \n## Q3 2023  \n129K  \n------  \nContent Actioned on Dangerous Organizations and Individuals: Organized Hate  \n-----------------------------------------------------------------------------  \nContent actioned decreased from 215K in Q2 2023 to 129K in Q3 2023, returning to pre-Q3 levels after a spike in reported viral links in April.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/instagram/#content-actioned)  \n## Q3 2023  \n77.2%  \n-------  \nProactive Rate on Dangerous Organizations and Individuals: Organized Hate  \n---------------------------------------------------------------------------  \nProactive rate decreased from 84.5% in Q2 2023 to 77.2% in Q3 2023, due to a decrease in proactive actions taken by our media-matching technology.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/instagram/#proactive-rate)  \n## Q3 2023  \n8.2 million  \n-------------  \nContent Actioned on Dangerous Organizations and Individuals: Terrorism  \n------------------------------------------------------------------------  \nContent actioned decreased from 13.6 million in Q2 2023 to 8.2 million in Q3 2023, due to a decrease in content that violated our policies.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/facebook/#content-actioned)  \n## Q3 2023  \n99K  \n-----  \nRestored Content on Dangerous Organizations and Individuals: Terrorism  \n------------------------------------------------------------------------  \nRestored content decreased from 952K in Q2 2023 to 99K in Q3 2023, returning to pre-Q2 levels after an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored in Q2.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/facebook/#restored-content)  \n## Q3 2023  \n831K  \n------  \nContent Actioned on Dangerous Organizations and Individuals: Terrorism  \n------------------------------------------------------------------------  \nContent actioned decreased from 2 million in Q2 2023 to 831K in Q3 2023, due to a decline in content that violated our policies.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/instagram/#content-actioned)  \n## Q3 2023  \n23.7K  \n-------  \nRestored Content on Dangerous Organizations and Individuals: Terrorism  \n------------------------------------------------------------------------  \nRestored content decreased from 643K in Q2 2023 to 23.7K in Q3 2023, returning to pre-Q2 levels after an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored in Q2.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/instagram/#restored-content)  \n## Q3 2023  \n827 million  \n-------------  \nAccounts Actioned on Fake Accounts  \n------------------------------------  \nAccounts actioned increased from 676 million in Q2 2023 to 827 million in Q3 2023. Fluctuations in enforcement metrics for fake accounts are expected due to the highly adversarial nature of this space.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/fake-accounts/facebook/#content-actioned)  \n## Q3 2023  \n9.6 million  \n-------------  \nContent Actioned on Hate Speech  \n---------------------------------  \nContent actioned decreased from 18 million in Q2 2023 to 9.6 million in Q3 2023, returning to pre-Q2 levels following an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored. This impacted both platforms in Q2.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/facebook/#content-actioned)  \n## Q3 2023  \n94.8%  \n-------  \nProactive Rate on Hate Speech  \n-------------------------------  \nProactive rate increased from 88.8% in Q2 2023 to 94.8% in Q3 2023, due to an update in our calculation to the proactive rate.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/facebook/#proactive-rate)  \n## Q3 2023  \n313K  \n------  \nRestored Content on Hate Speech  \n---------------------------------  \nRestored content decreased from 6.92 million in Q2 2023 to 313K in Q3 2023, returning to pre-Q2 levels following an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored. This impacted both platforms in Q2.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/facebook/#restored-content)  \n## Q3 2023  \n7 million  \n-----------  \nContent Actioned on Hate Speech  \n---------------------------------  \nContent actioned decreased from 9.8 million in Q2 2023 to 7.0 million in Q3 2023, returning to pre-Q2 levels following an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored. This impacted both platforms in Q2.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/instagram/#content-actioned)  \n## Q3 2023  \n977K  \n------  \nAppealed Content on Hate Speech  \n---------------------------------  \nAppealed content increased from 625K in Q2 2023 to 977K in Q3 2023, as we increased our appeals period to adhere to Digital Services Act.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/instagram/#appealed-content)  \n## Q3 2023  \n87.7K  \n-------  \nRestored Content on Hate Speech  \n---------------------------------  \nRestored content decreased from 3.92 million in Q2 2023 to 87.7K in Q3 2023, returning to pre-Q2 levels following an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored. This impacted both platforms in Q2.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/instagram/#restored-content)  \n## Q3 2023  \n290K  \n------  \nAppealed Content on Restricted Goods and Services: Drugs  \n----------------------------------------------------------  \nAppealed content increased from 213K in Q2 2023 to 290K in Q3 2023, as we increased our appeals period to adhere to the Digital Services Act.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/regulated-goods/instagram/#appealed-content)  \n## Q3 2023  \n413 million  \n-------------  \nContent Actioned on Spam  \n--------------------------  \nContent actioned decreased from 1.1 billion in Q2 2023 to 413 million in Q3 2023, due to a decrease in enforcement due to a bug in our proactive detection technology that was later fixed in August. Fluctuations in enforcement metrics for spam are expected due to the highly adversarial nature of this space.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/spam/facebook/#content-actioned)  \n## Q3 2023  \n98.2%  \n-------  \nProactive Rate on Spam  \n------------------------  \nProactive rate increased from 95.3% in Q2 2023 to 98.2% in Q3 2023, due to an update in our calculation to the proactive rate.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/spam/facebook/#proactive-rate)  \n## Q3 2023  \n16.5 million  \n--------------  \nRestored Content on Spam  \n--------------------------  \nRestored content decreased from 129 million in Q2 2023 to 16.5 million in Q3 2023, due to updates to our proactive detection technology to improve accuracy.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/spam/facebook/#restored-content)  \n## Q3 2023  \n401K  \n------  \nAppealed Content on Suicide and Self-Injury  \n---------------------------------------------  \nAppealed content increased from 236K in Q2 2023 to 401K in Q3 2023, as we increased our appeals period to adhere to the Digital Services Act.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/suicide-and-self-injury/instagram/#appealed-content)  \n## Q3 2023  \n9 million  \n-----------  \nContent Actioned on Violent and Graphic Content  \n-------------------------------------------------  \nContent actioned decreased from 13.8 million in Q2 2023 to 9.0 million in Q3 2023, due to changes made to our enforcement systems.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/graphic-violence/facebook/#content-actioned)  \n## Q3 2023  \n98.2%  \n-------  \nProactive Rate on Violent and Graphic Content  \n-----------------------------------------------  \nProactive rate increased from 97.5% in Q2 2023 to 98.2% in Q3 2023, due to an update in our calculation to the proactive rate.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/graphic-violence/facebook/#proactive-rate)  \n## Q3 2023  \n4.1 million  \n-------------  \nContent Actioned on Violent and Graphic Content  \n-------------------------------------------------  \nContent actioned decreased from 6.2 million in Q2 2023 to 4.1 million in Q3 2023, due to changes made to our enforcement systems.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/graphic-violence/instagram/#content-actioned)  \n## Q3 2023  \n8.6 million  \n-------------  \nContent Actioned on Violence and Incitement  \n---------------------------------------------  \nContent actioned decreased from 10.6 million in Q2 2023 to 8.6 million in Q3 2023, due to a decrease in content that violated our policies.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/violence-incitement/facebook/#content-actioned)  \n## Q3 2023  \n97.3%  \n-------  \nProactive Rate on Violence and Incitement  \n-------------------------------------------  \nProactive rate increased from 85.1% in Q2 2023 to 97.3% in Q3 2023, due to an update in our calculation to the proactive rate.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/violence-incitement/facebook/#proactive-rate)  \n## Q3 2023  \n1.2 million  \n-------------  \nAppealed Content on Violence and Incitement  \n---------------------------------------------  \nAppealed content increased from 663K in Q2 2023 to 1.2 million in Q3 2023, as we increased our appeals period to adhere to the Digital Services Act.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/violence-incitement/instagram/#appealed-content)\n",
        "line_start": 62,
        "line_end": 300,
        "url": "https://transparency.fb.com/)"
    },
    "5": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tCommunity Standards Enforcement Report\n\tVIOLENCE AND CRIMINAL BEHAVIOR\n\nContent: \n## VIOLENCE AND CRIMINAL BEHAVIOR  \n[Dangerous Organizations: Terrorism and Organized Hate](https://transparency.fb.com/data/community-standards-enforcement/dangerous-organizations/)  \n[Restricted Goods and Services: Drugs and Firearms](https://transparency.fb.com/data/community-standards-enforcement/regulated-goods/)  \n[Violence and Incitement](https://transparency.fb.com/data/community-standards-enforcement/violence-incitement/)\n",
        "line_start": 608,
        "line_end": 612,
        "url": "https://transparency.fb.com/)"
    },
    "6": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tCommunity Standards Enforcement Report\n\tSAFETY\n\nContent: \n## SAFETY  \n[Suicide and Self-Injury](https://transparency.fb.com/data/community-standards-enforcement/suicide-and-self-injury/)  \n[Child Endangerment: Nudity and Physical Abuse and Sexual Exploitation](https://transparency.fb.com/data/community-standards-enforcement/child-nudity-and-sexual-exploitation/)  \n[Bullying and Harassment](https://transparency.fb.com/data/community-standards-enforcement/bullying-and-harassment/)\n",
        "line_start": 616,
        "line_end": 620,
        "url": "https://transparency.fb.com/)"
    },
    "7": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tCommunity Standards Enforcement Report\n\tOBJECTIONABLE CONTENT\n\nContent: \n## OBJECTIONABLE CONTENT  \n[Hate Speech](https://transparency.fb.com/data/community-standards-enforcement/hate-speech/)  \n[Violent and Graphic Content](https://transparency.fb.com/data/community-standards-enforcement/graphic-violence/)  \n[Adult Nudity and Sexual Activity](https://transparency.fb.com/data/community-standards-enforcement/adult-nudity-and-sexual-activity/)\n",
        "line_start": 624,
        "line_end": 628,
        "url": "https://transparency.fb.com/)"
    },
    "8": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tCommunity Standards Enforcement Report\n\tINTEGRITY AND AUTHENTICITY\n\nContent: \n## INTEGRITY AND AUTHENTICITY  \n[Fake Accounts](https://transparency.fb.com/data/community-standards-enforcement/fake-accounts/)  \n[Spam](https://transparency.fb.com/data/community-standards-enforcement/spam/)\n",
        "line_start": 632,
        "line_end": 635,
        "url": "https://transparency.fb.com/)"
    },
    "9": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tCommunity Standards Enforcement Report\n\tDEEP DIVE\n\nContent: \n## DEEP DIVE  \n[Prevalence](https://transparency.fb.com/policies/improving/prevalence-metric/)  \n[Content actioned](https://transparency.fb.com/policies/improving/content-actioned-metric/)  \n[Proactive rate](https://transparency.fb.com/policies/improving/proactive-rate-metric/)  \n[Appealed content](https://transparency.fb.com/policies/improving/appealed-content-metric/)  \n[Restored content](https://transparency.fb.com/policies/improving/restored-content-metric/)  \n[Getting better at measurement](https://transparency.fb.com/policies/improving/getting-better-at-measurement/)  \n[Corrections and adjustments](https://transparency.fb.com/policies/improving/corrections-adjustments/)  \n[Home](https://transparency.fb.com/)  \n[Data](https://transparency.fb.com/reports/)  \n[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)\n",
        "line_start": 640,
        "line_end": 651,
        "url": "https://transparency.fb.com/)"
    },
    "10": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tAdult Nudity and Sexual Activity\n\nContent: \n# Adult Nudity and Sexual Activity  \nWe restrict the display of adult nudity and sexual activity on Facebook and Instagram. We make some exceptions when it is clear the content is being shared in the context of a protest, for educational or medical reasons or a similar reason. On the other hand, we default to removing sexual imagery to prevent non-consensual or underage content from being shared.  \nThis report does not include metrics related to our separate policy on the [promotion of sexual assault, violence or exploitation](https://transparency.fb.com/policies/community-standards/sexual-exploitation-adults/).  \n[Read the policy details](https://transparency.fb.com/policies/community-standards/adult-nudity-sexual-activity)  \nFacebook  \nFacebook  \nInstagram  \n[Download (CSV)](https://transparency.fb.com/sr/community-standards/)\n",
        "line_start": 662,
        "line_end": 670,
        "url": "https://transparency.fb.com/)"
    },
    "11": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tAdult Nudity and Sexual Activity\n\tQ3 2023\n\nContent: \n## Q3 2023  \n35.1 million  \n--------------  \nContent Actioned on Adult Nudity and Sexual Activity  \n------------------------------------------------------  \nContent actioned decreased from 51.2 million in Q2 2023 to 35.1 million in Q3 2023, returning to pre-Q2 levels after an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/adult-nudity-and-sexual-activity/facebook/#content-actioned)  \n## Q3 2023  \n92.4%  \n-------  \nProactive Rate on Adult Nudity and Sexual Activity  \n----------------------------------------------------  \nProactive rate decreased from 93.8% in Q2 2023 to 92.4% in Q3 2023, due to a bug in our proactive detection technology.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/adult-nudity-and-sexual-activity/facebook/#proactive-rate)\n",
        "line_start": 62,
        "line_end": 76,
        "url": "https://transparency.fb.com/)"
    },
    "12": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tAdult Nudity and Sexual Activity\n\tprevalence\n\nContent: \n## prevalence  \nHow prevalent were adult nudity and sexual activity violations?  \nHow we calculate it  \nPrevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.  \n[Read about this data](https://transparency.fb.com/policies/improving/prevalence-metric/)\n",
        "line_start": 712,
        "line_end": 717,
        "url": "https://transparency.fb.com/)"
    },
    "13": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tAdult Nudity and Sexual Activity\n\tcontent actioned\n\nContent: \n## content actioned  \nHow much adult nudity and sexual activity content did we take action on?  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for adult nudity and sexual activity. It includes both content we actioned after someone reported it, and content that we found proactively.  \n[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)\n",
        "line_start": 722,
        "line_end": 727,
        "url": "https://transparency.fb.com/)"
    },
    "14": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tAdult Nudity and Sexual Activity\n\tproactive rate\n\nContent: \n## proactive rate  \nOf the violating content we actioned for adult nudity and sexual activity, how much did we find and action before people reported it?  \nFound and actioned by us  \nReported by users  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \n[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)  \nCorrecting mistakes  \nPeople can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.\n",
        "line_start": 732,
        "line_end": 741,
        "url": "https://transparency.fb.com/)"
    },
    "15": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tAdult Nudity and Sexual Activity\n\tappealed content\n\nContent: \n## appealed content  \nHow much of the content we actioned for adult nudity and sexual activity did people appeal?  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \n[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)\n",
        "line_start": 750,
        "line_end": 755,
        "url": "https://transparency.fb.com/)"
    },
    "16": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tAdult Nudity and Sexual Activity\n\trestored content\n\nContent: \n## restored content  \nHow much actioned content for adult nudity and sexual activity was later restored?  \nRestored without appeal  \nRestored after appeal  \nTotal  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)  \nNOTE:  \nDue to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.  \nHow we calculate it  \nPrevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for adult nudity and sexual activity. It includes both content we actioned after someone reported it, and content that we found proactively.  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Home](https://transparency.fb.com/)  \n[Data](https://transparency.fb.com/reports/)  \n[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)\n",
        "line_start": 760,
        "line_end": 783,
        "url": "https://transparency.fb.com/)"
    },
    "17": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tBullying and Harassment\n\nContent: \n# Bullying and Harassment  \nWe do not tolerate bullying and harassment on Facebook and Instagram. Because we recognize bullying can be especially harmful for minors, our policies provide heightened protections for them. We want to allow for open and vital discussion of people who are in the news or who have a large public audience, so we do permit more open or critical discourse towards public figures than private individuals.  \nBecause bullying and harassment is highly personal by nature, using technology to proactively detect these behaviors can be more challenging than other types of violations. That's why we also rely on people to report this behavior to us so we can identify and remove it. When measuring prevalence in this area, the metric captures only bullying and harassment where a deeper understanding of context or meaning is not necessary to determine if it violates our policy. We continue to invest in our proactive detection technology to ensure we are tackling the problem and protecting our community.  \n[Read the policy details](https://transparency.fb.com/policies/community-standards/bullying-harassment)  \nFacebook  \nFacebook  \nInstagram  \n[Download (CSV)](https://transparency.fb.com/sr/community-standards/)\n",
        "line_start": 806,
        "line_end": 814,
        "url": "https://transparency.fb.com/)"
    },
    "18": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tBullying and Harassment\n\tQ3 2023\n\nContent: \n## Q3 2023  \n87.8%  \n-------  \nProactive Rate on Bullying and Harassment  \n-------------------------------------------  \nProactive rate increased from 65.8% in Q2 2023 to 87.8% in Q3 2023, due to an update in our calculation to the proactive rate.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/bullying-and-harassment/facebook/#proactive-rate)\n",
        "line_start": 62,
        "line_end": 69,
        "url": "https://transparency.fb.com/)"
    },
    "19": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tBullying and Harassment\n\tprevalence\n\nContent: \n## prevalence  \nHow prevalent were bullying and harassment violations?  \nHow we calculate it  \nPrevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.  \n[Read about this data](https://transparency.fb.com/policies/improving/prevalence-metric/)\n",
        "line_start": 712,
        "line_end": 717,
        "url": "https://transparency.fb.com/)"
    },
    "20": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tBullying and Harassment\n\tcontent actioned\n\nContent: \n## content actioned  \nHow much bullying and harassment content did we take action on?  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for bullying and harassment. It includes both content we actioned after someone reported it, and content that we found proactively.  \n[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)\n",
        "line_start": 722,
        "line_end": 727,
        "url": "https://transparency.fb.com/)"
    },
    "21": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tBullying and Harassment\n\tproactive rate\n\nContent: \n## proactive rate  \nOf the violating content we actioned for bullying and harassment, how much did we find and action before people reported it?  \nFound and actioned by us  \nReported by users  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \n[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)  \nCorrecting mistakes  \nPeople can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.\n",
        "line_start": 732,
        "line_end": 741,
        "url": "https://transparency.fb.com/)"
    },
    "22": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tBullying and Harassment\n\tappealed content\n\nContent: \n## appealed content  \nHow much of the content we actioned for bullying and harassment did people appeal?  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \n[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)\n",
        "line_start": 750,
        "line_end": 755,
        "url": "https://transparency.fb.com/)"
    },
    "23": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tBullying and Harassment\n\trestored content\n\nContent: \n## restored content  \nHow much actioned content for bullying and harassment was later restored?  \nRestored without appeal  \nRestored after appeal  \nTotal  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)  \nNOTE:  \nDue to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.  \nHow we calculate it  \nPrevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for bullying and harassment. It includes both content we actioned after someone reported it, and content that we found proactively.  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Home](https://transparency.fb.com/)  \n[Data](https://transparency.fb.com/reports/)  \n[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)\n",
        "line_start": 760,
        "line_end": 783,
        "url": "https://transparency.fb.com/)"
    },
    "24": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tChild Endangerment: Nudity and Physical Abuse and Sexual Exploitation\n\nContent: \n# Child Endangerment: Nudity and Physical Abuse and Sexual Exploitation  \nWe do not allow content that endangers children, such as content that contains nudity or physical abuse or content that sexually exploits children on Facebook and Instagram. When we find this type of violating content, we remove it, regardless of the context or the person's motivation for sharing it. We may also disable the account of the person who shared it, unless it appears the intent was not malicious (for example, to spread awareness of child exploitation).  \nWe report apparent child exploitation to the [National Center for Missing and Exploited Children (NCMEC)](https://www.missingkids.org/home), a nonprofit that refers cases to law enforcement globally, in compliance with US law. We choose to remove content depicting non-sexualized child nudity to reduce the potential for abuse of the content by others.  \n[Read the policy details](https://transparency.fb.com/policies/community-standards/child-sexual-exploitation-abuse-nudity)  \nFacebook  \nFacebook  \nInstagram  \n[Download (CSV)](https://transparency.fb.com/sr/community-standards/)\n",
        "line_start": 934,
        "line_end": 942,
        "url": "https://transparency.fb.com/)"
    },
    "25": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tChild Endangerment: Nudity and Physical Abuse and Sexual Exploitation\n\tQ3 2023\n\nContent: \n## Q3 2023  \n16.9 million  \n--------------  \nContent Actioned on Child Endangerment: Sexual Exploitation  \n-------------------------------------------------------------  \nContent actioned increased from 7.2 million in Q2 2023 to 16.9 million in Q3 2023, due to a large takedown of coordinated behavior violating our policies.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#content-actioned)  \n## Q3 2023  \n99%  \n-----  \nProactive Rate on Child Endangerment: Sexual Exploitation  \n-----------------------------------------------------------  \nProactive rate increased from 96.9% in Q2 2023 to 99% in Q3 2023, due to an increase in proactive detection technology mentioned in content actioned.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#proactive-rate)  \n## Q3 2023  \n267K  \n------  \nAppealed Content on Child Endangerment: Sexual Exploitation  \n-------------------------------------------------------------  \nAppealed content increased from 147K in Q2 2023 to 267K in Q3 2023, due to an increase in proactive detection technology taking down content violating our policies.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#appealed-content)  \n## Q3 2023  \n204K  \n------  \nRestored Content on Child Endangerment: Sexual Exploitation  \n-------------------------------------------------------------  \nRestored content increased from 80K in Q2 2023 to 204K in Q3 2023, due to adjustments in our proactive detection technology.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#restored-content)\n",
        "line_start": 62,
        "line_end": 90,
        "url": "https://transparency.fb.com/)"
    },
    "26": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tChild Endangerment: Nudity and Physical Abuse and Sexual Exploitation\n\tprevalence\n\nContent: \n## prevalence  \nHow prevalent were child endangerment violations?  \nWe cannot estimate prevalence for child endangerment right now. We will continue to expand prevalence measurement to more areas as we confirm accuracy and meaningful data.\n",
        "line_start": 712,
        "line_end": 715,
        "url": "https://transparency.fb.com/)"
    },
    "27": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tChild Endangerment: Nudity and Physical Abuse and Sexual Exploitation\n\tcontent actioned\n\nContent: \n## content actioned  \nHow much child endangerment content did we take action on?  \nChild Nudity and Sexual Exploitation  \nChild Nudity and Physical Abuse  \nChild Sexual Exploitation  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for child nudity and physical abuse, child sexual exploitation and child nudity and sexual exploitation. It includes both content we actioned after someone reported it, and content that we found proactively.  \n[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)\n",
        "line_start": 722,
        "line_end": 730,
        "url": "https://transparency.fb.com/)"
    },
    "28": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tChild Endangerment: Nudity and Physical Abuse and Sexual Exploitation\n\tproactive rate\n\nContent: \n## proactive rate  \nOf the violating content we actioned for child endangerment, how much did we find and action before people reported it?  \nChild Nudity and Physical Abuse  \nChild Nudity and Physical Abuse  \nChild Sexual Exploitation  \nChild Nudity and Sexual Exploitation  \nFound and actioned by us  \nReported by users  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \n[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)  \nCorrecting mistakes  \nPeople can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.\n",
        "line_start": 732,
        "line_end": 745,
        "url": "https://transparency.fb.com/)"
    },
    "29": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tChild Endangerment: Nudity and Physical Abuse and Sexual Exploitation\n\tappealed content\n\nContent: \n## appealed content  \nHow much of the content we actioned for child endangerment did people appeal?  \nChild Nudity and Sexual Exploitation  \nChild Nudity and Physical Abuse  \nChild Sexual Exploitation  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \n[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)\n",
        "line_start": 750,
        "line_end": 758,
        "url": "https://transparency.fb.com/)"
    },
    "30": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tChild Endangerment: Nudity and Physical Abuse and Sexual Exploitation\n\trestored content\n\nContent: \n## restored content  \nHow much actioned content for child endangerment was later restored?  \nChild Nudity and Physical Abuse  \nChild Nudity and Physical Abuse  \nChild Sexual Exploitation  \nChild Nudity and Sexual Exploitation  \nRestored without appeal  \nRestored after appeal  \nTotal  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)  \nNOTE:  \nDue to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for child nudity and physical abuse, child sexual exploitation and child nudity and sexual exploitation. It includes both content we actioned after someone reported it, and content that we found proactively.  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Home](https://transparency.fb.com/)  \n[Data](https://transparency.fb.com/reports/)  \n[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)\n",
        "line_start": 760,
        "line_end": 785,
        "url": "https://transparency.fb.com/)"
    },
    "31": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tDangerous Organizations: Terrorism and Organized Hate\n\nContent: \n# Dangerous Organizations: Terrorism and Organized Hate  \nWe do not allow organizations or individuals that proclaim a violent mission, or are engaging in violence, to have a presence on Facebook and Instagram. We do not allow content that praises, supports or represents individuals or groups engaging in terrorist activity or organized hate.  \nThis report does not include data on other dangerous organizations prohibited from having a presence on Facebook and Instagram, including those engaging in mass or multiple murder, human trafficking or organized criminal activity. [Learn more about our latest efforts enforcing our dangerous organizations policy.](https://about.fb.com/news/2020/05/combating-hate-and-dangerous-organizations)  \n[Read the policy details](https://transparency.fb.com/policies/community-standards/dangerous-individuals-organizations)  \nFacebook  \nFacebook  \nInstagram  \n[Download (CSV)](https://transparency.fb.com/sr/community-standards/)\n",
        "line_start": 1130,
        "line_end": 1138,
        "url": "https://transparency.fb.com/)"
    },
    "32": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tDangerous Organizations: Terrorism and Organized Hate\n\tQ3 2023\n\nContent: \n## Q3 2023  \n750K  \n------  \nContent Actioned on Dangerous Organizations and Individuals: Organized Hate  \n-----------------------------------------------------------------------------  \nContent actioned decreased from 1.1 million in Q2 2023 to 750K in Q3 2023, returning to Q2 levels after a spike in reported viral links in April.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/facebook/#content-actioned)  \n## Q3 2023  \n8.2 million  \n-------------  \nContent Actioned on Dangerous Organizations and Individuals: Terrorism  \n------------------------------------------------------------------------  \nContent actioned decreased from 13.6 million in Q2 2023 to 8.2 million in Q3 2023, due to a decrease in content that violated our policies.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/facebook/#content-actioned)  \n## Q3 2023  \n99K  \n-----  \nRestored Content on Dangerous Organizations and Individuals: Terrorism  \n------------------------------------------------------------------------  \nRestored content decreased from 952K in Q2 2023 to 99K in Q3 2023, returning to pre-Q2 levels after an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored in Q2.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/facebook/#restored-content)\n",
        "line_start": 62,
        "line_end": 83,
        "url": "https://transparency.fb.com/)"
    },
    "33": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tDangerous Organizations: Terrorism and Organized Hate\n\tprevalence\n\nContent: \n## prevalence  \nHow prevalent were dangerous organizations violations?\n",
        "line_start": 712,
        "line_end": 714,
        "url": "https://transparency.fb.com/)"
    },
    "34": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tDangerous Organizations: Terrorism and Organized Hate\n\tTerrorism\n\nContent: \n## Terrorism  \nViews of violating content that contains terrorism are very infrequent, and we remove much of this content before people see it. As a result, many times we do not find enough violating samples to precisely estimate prevalence.  \nIn Q3 2023, this was true for violations of our policies on terrorism, suicide and self-injury and restricted goods and services on Facebook and Instagram. In these cases, we can estimate an upper limit of how often someone would see content that violates these policies.  \nIn Q3 2023, the upper limit was 0.05% for violations of our policy for terrorism on Facebook. This means that out of every 10,000 views of content on Facebook, we estimate no more than 5 of those views contained content that violated the policy.\n",
        "line_start": 1200,
        "line_end": 1204,
        "url": "https://transparency.fb.com/)"
    },
    "35": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tDangerous Organizations: Terrorism and Organized Hate\n\tOrganized Hate\n\nContent: \n## Organized Hate  \nWe cannot estimate prevalence for organized hate right now. We will continue to expand prevalence measurement to more areas as we confirm accuracy and meaningful data.\n",
        "line_start": 1208,
        "line_end": 1210,
        "url": "https://transparency.fb.com/)"
    },
    "36": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tDangerous Organizations: Terrorism and Organized Hate\n\tcontent actioned\n\nContent: \n## content actioned  \nHow much dangerous organizations content did we take action on?  \nTerrorism  \nOrganized Hate  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for terrorism and organized hate. It includes both content we actioned after someone reported it, and content that we found proactively.  \n[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)\n",
        "line_start": 722,
        "line_end": 729,
        "url": "https://transparency.fb.com/)"
    },
    "37": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tDangerous Organizations: Terrorism and Organized Hate\n\tproactive rate\n\nContent: \n## proactive rate  \nOf the violating content we actioned for dangerous organizations, how much did we find and action before people reported it?  \nTerrorism  \nTerrorism  \nOrganized Hate  \nFound and actioned by us  \nReported by users  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \n[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)  \nCorrecting mistakes  \nPeople can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.\n",
        "line_start": 732,
        "line_end": 744,
        "url": "https://transparency.fb.com/)"
    },
    "38": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tDangerous Organizations: Terrorism and Organized Hate\n\tappealed content\n\nContent: \n## appealed content  \nHow much of the content we actioned for dangerous organizations did people appeal?  \nTerrorism  \nOrganized Hate  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \n[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)\n",
        "line_start": 750,
        "line_end": 757,
        "url": "https://transparency.fb.com/)"
    },
    "39": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tDangerous Organizations: Terrorism and Organized Hate\n\trestored content\n\nContent: \n## restored content  \nHow much actioned content for dangerous organizations was later restored?  \nTerrorism  \nTerrorism  \nOrganized Hate  \nRestored without appeal  \nRestored after appeal  \nTotal  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)  \nNOTE:  \nDue to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for terrorism and organized hate. It includes both content we actioned after someone reported it, and content that we found proactively.  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Home](https://transparency.fb.com/)  \n[Data](https://transparency.fb.com/reports/)  \n[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)\n",
        "line_start": 760,
        "line_end": 784,
        "url": "https://transparency.fb.com/)"
    },
    "40": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tFake Accounts\n\nContent: \n# Fake Accounts  \nOur goal is to remove as many fake accounts on Facebook as we can. These include accounts created with malicious intent to violate our policies and personal profiles created to represent a business, organization or non-human entity, such as a pet.  \nWe prioritize enforcement against fake accounts that seek to cause harm. Many of these accounts are used in spam campaigns and are financially motivated.  \nWe expect the number of accounts we action to vary over time due to the unpredictable nature of adversarial account creation. Our detection technology helps us block millions of attempts to create fake accounts every day and detect millions more, often within minutes after creation. We do not include blocked attempts in the metrics we report here.  \n[Read the policy details](https://transparency.fb.com/policies/community-standards/account-integrity-and-authentic-identity/)  \nFacebook  \nFacebook  \nInstagram  \n[Download (CSV)](https://transparency.fb.com/sr/community-standards/)\n",
        "line_start": 1312,
        "line_end": 1321,
        "url": "https://transparency.fb.com/)"
    },
    "41": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tFake Accounts\n\tQ3 2023\n\nContent: \n## Q3 2023  \n827 million  \n-------------  \nAccounts Actioned on Fake Accounts  \n------------------------------------  \nAccounts actioned increased from 676 million in Q2 2023 to 827 million in Q3 2023. Fluctuations in enforcement metrics for fake accounts are expected due to the highly adversarial nature of this space.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/fake-accounts/facebook/#content-actioned)\n",
        "line_start": 62,
        "line_end": 69,
        "url": "https://transparency.fb.com/)"
    },
    "42": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tFake Accounts\n\tprevalence\n\nContent: \n## prevalence  \nHow prevalent were fake account violations?  \nWe estimate that fake accounts represented approximately 4-5% of our worldwide monthly active users (MAU) on Facebook during Q3 2023.\n",
        "line_start": 712,
        "line_end": 715,
        "url": "https://transparency.fb.com/)"
    },
    "43": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tFake Accounts\n\taccounts actioned\n\nContent: \n## accounts actioned  \nHow many fake accounts did we take action on?  \nHow we calculate it  \nAccounts actioned is the total number of accounts that Facebook took action on for fake accounts. It includes both accounts we actioned after someone reported them, and accounts that we found proactively.  \n[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)\n",
        "line_start": 1354,
        "line_end": 1359,
        "url": "https://transparency.fb.com/)"
    },
    "44": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tFake Accounts\n\tproactive rate\n\nContent: \n## proactive rate  \nOf the violating accounts we actioned, how many did we find and action before people reported them?  \nFound and actioned by us  \nReported by users  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \n[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)  \nHow we calculate it  \nAccounts actioned is the total number of accounts that Facebook took action on for fake accounts. It includes both accounts we actioned after someone reported them, and accounts that we found proactively.  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \n[Home](https://transparency.fb.com/)  \n[Data](https://transparency.fb.com/reports/)  \n[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)\n",
        "line_start": 732,
        "line_end": 746,
        "url": "https://transparency.fb.com/)"
    },
    "45": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tHate Speech\n\nContent: \n# Hate Speech  \nWe do not allow hate speech on Facebook and Instagram. We define hate speech as violent or dehumanizing speech, statements of inferiority, calls for exclusion or segregation based on protected characteristics or slurs. These characteristics include race, ethnicity, national origin, religious affiliation, sexual orientation, caste, sex, gender, gender identity and serious disability or disease.  \nWhen the intent is clear, we may allow people to share someone else's hate speech content to raise awareness or discuss whether the speech is appropriate to use, to use slurs self-referentially in an effort to reclaim the term or for other similar reasons.  \n[Read the policy details](https://transparency.fb.com/policies/community-standards/hate-speech/)  \nFacebook  \nFacebook  \nInstagram  \n[Download (CSV)](https://transparency.fb.com/sr/community-standards/)\n",
        "line_start": 1392,
        "line_end": 1400,
        "url": "https://transparency.fb.com/)"
    },
    "46": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tHate Speech\n\tQ3 2023\n\nContent: \n## Q3 2023  \n9.6 million  \n-------------  \nContent Actioned on Hate Speech  \n---------------------------------  \nContent actioned decreased from 18 million in Q2 2023 to 9.6 million in Q3 2023, returning to pre-Q2 levels following an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored. This impacted both platforms in Q2.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/facebook/#content-actioned)  \n## Q3 2023  \n94.8%  \n-------  \nProactive Rate on Hate Speech  \n-------------------------------  \nProactive rate increased from 88.8% in Q2 2023 to 94.8% in Q3 2023, due to an update in our calculation to the proactive rate.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/facebook/#proactive-rate)  \n## Q3 2023  \n313K  \n------  \nRestored Content on Hate Speech  \n---------------------------------  \nRestored content decreased from 6.92 million in Q2 2023 to 313K in Q3 2023, returning to pre-Q2 levels following an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored. This impacted both platforms in Q2.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/facebook/#restored-content)\n",
        "line_start": 62,
        "line_end": 83,
        "url": "https://transparency.fb.com/)"
    },
    "47": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tHate Speech\n\tprevalence\n\nContent: \n## prevalence  \nHow prevalent were hate speech violations?  \nHow we calculate it  \nPrevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.  \n[Read about this data](https://transparency.fb.com/policies/improving/prevalence-metric/)\n",
        "line_start": 712,
        "line_end": 717,
        "url": "https://transparency.fb.com/)"
    },
    "48": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tHate Speech\n\tcontent actioned\n\nContent: \n## content actioned  \nHow much hate speech content did we take action on?  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for hate speech. It includes both content we actioned after someone reported it, and content that we found proactively.  \n[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)\n",
        "line_start": 722,
        "line_end": 727,
        "url": "https://transparency.fb.com/)"
    },
    "49": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tHate Speech\n\tproactive rate\n\nContent: \n## proactive rate  \nOf the violating content we actioned for hate speech, how much did we find and action before people reported it?  \nFound and actioned by us  \nReported by users  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \n[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)  \nCorrecting mistakes  \nPeople can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.\n",
        "line_start": 732,
        "line_end": 741,
        "url": "https://transparency.fb.com/)"
    },
    "50": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tHate Speech\n\tappealed content\n\nContent: \n## appealed content  \nHow much of the content we actioned for hate speech did people appeal?  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \n[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)\n",
        "line_start": 750,
        "line_end": 755,
        "url": "https://transparency.fb.com/)"
    },
    "51": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tHate Speech\n\trestored content\n\nContent: \n## restored content  \nHow much actioned content for hate speech was later restored?  \nRestored without appeal  \nRestored after appeal  \nTotal  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)  \nNOTE:  \nDue to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.  \nHow we calculate it  \nPrevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for hate speech. It includes both content we actioned after someone reported it, and content that we found proactively.  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Home](https://transparency.fb.com/)  \n[Data](https://transparency.fb.com/reports/)  \n[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)\n",
        "line_start": 760,
        "line_end": 783,
        "url": "https://transparency.fb.com/)"
    },
    "52": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tRestricted Goods and Services: Drugs and Firearms\n\nContent: \n# Restricted Goods and Services: Drugs and Firearms  \nWe do not allow private individuals, manufacturers or retailers to buy, sell or trade non-medical drugs, pharmaceutical drugs and marijuana on Facebook and Instagram. We also do not allow private individuals to buy, sell, give, exchange or transfer firearms, including firearm parts or ammunition. While drugs and firearms are regulated by different legal restrictions around the world, we enforce these standards consistently across Instagram due to the borderless nature of our community.  \nThis report does not include data on other goods prohibited from being sold on Facebook or Instagram, including human organs, animals and their parts, or on our enforcement of our separate [Commerce Policies](https://www.facebook.com/policies_center/commerce) or [Advertising Policies](https://business.facebook.com/policies/ads).  \n[Read the policy details](https://transparency.fb.com/policies/community-standards/regulated-goods/)  \nFacebook  \nFacebook  \nInstagram  \n[Download (CSV)](https://transparency.fb.com/sr/community-standards/)\n",
        "line_start": 1552,
        "line_end": 1560,
        "url": "https://transparency.fb.com/)"
    },
    "53": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tRestricted Goods and Services: Drugs and Firearms\n\tprevalence\n\nContent: \n## prevalence  \nHow prevalent were restricted goods and services violations?  \nViews of violating content that contains restricted goods and services are very infrequent, and we remove much of this content before people see it. As a result, many times we do not find enough violating samples to precisely estimate prevalence.  \nIn Q3 2023, this was true for violations of our policies on restricted goods and services, suicide and self-injury and terrorism on Facebook and Instagram. In these cases, we can estimate an upper limit of how often someone would see content that violates these policies.  \nIn Q3 2023, the upper limit was 0.05% for violations of our policy for restricted goods and services on Facebook. This means that out of every 10,000 views of content on Facebook, we estimate no more than 5 of those views contained content that violated the policy.\n",
        "line_start": 712,
        "line_end": 717,
        "url": "https://transparency.fb.com/)"
    },
    "54": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tRestricted Goods and Services: Drugs and Firearms\n\tcontent actioned\n\nContent: \n## content actioned  \nHow much restricted goods and services content did we take action on?  \nDrugs  \nFirearms  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for drugs and firearms. It includes both content we actioned after someone reported it, and content that we found proactively.  \n[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)\n",
        "line_start": 722,
        "line_end": 729,
        "url": "https://transparency.fb.com/)"
    },
    "55": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tRestricted Goods and Services: Drugs and Firearms\n\tproactive rate\n\nContent: \n## proactive rate  \nOf the violating content we actioned for restricted goods and services, how much did we find and action before people reported it?  \nDrugs  \nDrugs  \nFirearms  \nFound and actioned by us  \nReported by users  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \n[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)  \nCorrecting mistakes  \nPeople can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.\n",
        "line_start": 732,
        "line_end": 744,
        "url": "https://transparency.fb.com/)"
    },
    "56": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tRestricted Goods and Services: Drugs and Firearms\n\tappealed content\n\nContent: \n## appealed content  \nHow much of the content we actioned for restricted goods and services did people appeal?  \nDrugs  \nFirearms  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \n[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)\n",
        "line_start": 750,
        "line_end": 757,
        "url": "https://transparency.fb.com/)"
    },
    "57": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tRestricted Goods and Services: Drugs and Firearms\n\trestored content\n\nContent: \n## restored content  \nHow much actioned content for restricted goods and services were later restored?  \nDrugs  \nDrugs  \nFirearms  \nRestored without appeal  \nRestored after appeal  \nTotal  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)  \nNOTE:  \nDue to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for drugs and firearms. It includes both content we actioned after someone reported it, and content that we found proactively.  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Home](https://transparency.fb.com/)  \n[Data](https://transparency.fb.com/reports/)  \n[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)\n",
        "line_start": 760,
        "line_end": 784,
        "url": "https://transparency.fb.com/)"
    },
    "58": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tSpam\n\nContent: \n# Spam  \nWe do not allow spam on Facebook. Spam is a broad term used to describe content that is designed to be shared in deceptive and annoying ways or attempts to mislead users to drive engagement. Spam spreads in a number of ways: It can be automated (published by bots or scripts) or coordinated (when an actor uses multiple accounts to spread deceptive content).  \nSpammers aim to build audiences to inflate their content's distribution and reach, typically for financial gain. The tactics spammers use, and our ability to detect them, drive the amount of content we take action on as well as our proactive rate.  \n[Read the policy details](https://transparency.fb.com/policies/community-standards/spam/)  \nFacebook  \nFacebook  \nInstagram  \n[Download (CSV)](https://transparency.fb.com/sr/community-standards/)\n",
        "line_start": 1678,
        "line_end": 1686,
        "url": "https://transparency.fb.com/)"
    },
    "59": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tSpam\n\tQ3 2023\n\nContent: \n## Q3 2023  \n413 million  \n-------------  \nContent Actioned on Spam  \n--------------------------  \nContent actioned decreased from 1.1 billion in Q2 2023 to 413 million in Q3 2023, due to a decrease in enforcement due to a bug in our proactive detection technology that was later fixed in August. Fluctuations in enforcement metrics for spam are expected due to the highly adversarial nature of this space.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/spam/facebook/#content-actioned)  \n## Q3 2023  \n98.2%  \n-------  \nProactive Rate on Spam  \n------------------------  \nProactive rate increased from 95.3% in Q2 2023 to 98.2% in Q3 2023, due to an update in our calculation to the proactive rate.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/spam/facebook/#proactive-rate)  \n## Q3 2023  \n16.5 million  \n--------------  \nRestored Content on Spam  \n--------------------------  \nRestored content decreased from 129 million in Q2 2023 to 16.5 million in Q3 2023, due to updates to our proactive detection technology to improve accuracy.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/spam/facebook/#restored-content)\n",
        "line_start": 62,
        "line_end": 83,
        "url": "https://transparency.fb.com/)"
    },
    "60": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tSpam\n\tprevalence\n\nContent: \n## prevalence  \nHow prevalent were spam violations?  \nWe cannot estimate this metric right now. We are working on new methods to measure the prevalence of spam on Facebook. Our existing methods for measuring prevalence, which rely on people to manually review samples of content, do not fully capture this type of highly adversarial violation, which includes deceptive behavior as well as content. Spammy behavior cannot always be detected by reviewing the content alone. We are working on ways to review and classify spammers' behavior to build a comprehensive picture.\n",
        "line_start": 712,
        "line_end": 715,
        "url": "https://transparency.fb.com/)"
    },
    "61": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tSpam\n\tcontent actioned\n\nContent: \n## content actioned  \nHow much spam content did we take action on?  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for spam. It includes both content we actioned after someone reported it, and content that we found proactively.  \n[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)\n",
        "line_start": 722,
        "line_end": 727,
        "url": "https://transparency.fb.com/)"
    },
    "62": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tSpam\n\tproactive rate\n\nContent: \n## proactive rate  \nOf the violating content we actioned for spam, how much did we find and action before people reported it?  \nFound and actioned by us  \nReported by users  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \n[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)  \nCorrecting mistakes  \nPeople can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.\n",
        "line_start": 732,
        "line_end": 741,
        "url": "https://transparency.fb.com/)"
    },
    "63": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tSpam\n\tappealed content\n\nContent: \n## appealed content  \nHow much of the content we actioned for spam did people appeal?  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \n[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)\n",
        "line_start": 750,
        "line_end": 755,
        "url": "https://transparency.fb.com/)"
    },
    "64": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tSpam\n\trestored content\n\nContent: \n## restored content  \nHow much actioned content for spam was later restored?  \nRestored without appeal  \nRestored after appeal  \nTotal  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)  \nNOTE:  \nDue to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for spam. It includes both content we actioned after someone reported it, and content that we found proactively.  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Home](https://transparency.fb.com/)  \n[Data](https://transparency.fb.com/reports/)  \n[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)\n",
        "line_start": 760,
        "line_end": 781,
        "url": "https://transparency.fb.com/)"
    },
    "65": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tSuicide and Self-Injury\n\nContent: \n# Suicide and Self-Injury  \nWe remove content that encourages suicide or self-injury on Facebook and Instagram. Self-injury is defined as the intentional and direct injuring of the body, including self-mutilation and eating disorders. We also remove content that identifies and negatively targets victims or survivors of self-injury or suicide.  \nWe do allow people to discuss suicide and self-injury because we want Facebook and Instagram to be spaces where people can raise awareness about these issues and seek support.  \n[Read the policy details](https://transparency.fb.com/policies/community-standards/suicide-self-injury/)  \nFacebook  \nFacebook  \nInstagram  \n[Download (CSV)](https://transparency.fb.com/sr/community-standards/)\n",
        "line_start": 1830,
        "line_end": 1838,
        "url": "https://transparency.fb.com/)"
    },
    "66": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tSuicide and Self-Injury\n\tprevalence\n\nContent: \n## prevalence  \nHow prevalent were suicide and self-injury violations?  \nViews of violating content that contains suicide and self-injury are very infrequent, and we remove much of this content before people see it. As a result, many times we do not find enough violating samples to precisely estimate prevalence.  \nIn Q3 2023, this was true for violations of our policies on suicide and self-injury, terrorism and restricted goods and services on Facebook and Instagram. In these cases, we can estimate an upper limit of how often someone would see content that violates these policies.  \nIn Q3 2023, the upper limit was 0.05% for violations of our policy for suicide and self-injury on Facebook. This means that out of every 10,000 views of content on Facebook, we estimate no more than 5 of those views contained content that violated the policy.\n",
        "line_start": 712,
        "line_end": 717,
        "url": "https://transparency.fb.com/)"
    },
    "67": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tSuicide and Self-Injury\n\tcontent actioned\n\nContent: \n## content actioned  \nHow much suicide and self-injury content did we take action on?  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for suicide and self injury. It includes both content we actioned after someone reported it, and content that we found proactively.  \n[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)\n",
        "line_start": 722,
        "line_end": 727,
        "url": "https://transparency.fb.com/)"
    },
    "68": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tSuicide and Self-Injury\n\tproactive rate\n\nContent: \n## proactive rate  \nOf the violating content we actioned for suicide and self-injury, how much did we find and action before people reported it?  \nFound and actioned by us  \nReported by users  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \n[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)  \nCorrecting mistakes  \nPeople can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.\n",
        "line_start": 732,
        "line_end": 741,
        "url": "https://transparency.fb.com/)"
    },
    "69": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tSuicide and Self-Injury\n\tappealed content\n\nContent: \n## appealed content  \nHow much of the content we actioned for suicide and self-injury did people appeal?  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \n[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)\n",
        "line_start": 750,
        "line_end": 755,
        "url": "https://transparency.fb.com/)"
    },
    "70": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tSuicide and Self-Injury\n\trestored content\n\nContent: \n## restored content  \nHow much actioned content for suicide and self-injury was later restored?  \nRestored without appeal  \nRestored after appeal  \nTotal  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)  \nNOTE:  \nDue to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for suicide and self injury. It includes both content we actioned after someone reported it, and content that we found proactively.  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Home](https://transparency.fb.com/)  \n[Data](https://transparency.fb.com/reports/)  \n[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)\n",
        "line_start": 760,
        "line_end": 781,
        "url": "https://transparency.fb.com/)"
    },
    "71": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolence and Incitement\n\nContent: \n# Violence and Incitement  \nWe aim to prevent potential offline harm that may be related to content on Facebook. While we understand that people commonly edddxpress disdain or disagreement by threatening or calling for violence in non-serious ways, we remove language that incites or facilitates serious violence. We remove content, disable accounts and work with law enforcement when we believe there is a genuine risk of physical harm or direct threats to public safety. We also try to consider the language and context in order to distinguish casual statements from content that constitutes a credible threat to public or personal safety.  \n[Read the policy details](https://transparency.fb.com/policies/community-standards/violence-incitement/)  \nFacebook  \nFacebook  \nInstagram  \n[Download (CSV)](https://transparency.fb.com/sr/community-standards/)\n",
        "line_start": 1936,
        "line_end": 1943,
        "url": "https://transparency.fb.com/)"
    },
    "72": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolence and Incitement\n\tQ3 2023\n\nContent: \n## Q3 2023  \n8.6 million  \n-------------  \nContent Actioned on Violence and Incitement  \n---------------------------------------------  \nContent actioned decreased from 10.6 million in Q2 2023 to 8.6 million in Q3 2023, due to a decrease in content that violated our policies.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/violence-incitement/facebook/#content-actioned)  \n## Q3 2023  \n97.3%  \n-------  \nProactive Rate on Violence and Incitement  \n-------------------------------------------  \nProactive rate increased from 85.1% in Q2 2023 to 97.3% in Q3 2023, due to an update in our calculation to the proactive rate.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/violence-incitement/facebook/#proactive-rate)\n",
        "line_start": 62,
        "line_end": 76,
        "url": "https://transparency.fb.com/)"
    },
    "73": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolence and Incitement\n\tPrevalence\n\nContent: \n## Prevalence  \nHow prevalent were violence and incitement violations?  \nHow we calculate it  \nPrevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.  \n[Read about this data](https://transparency.fb.com/policies/improving/prevalence-metric/)\n",
        "line_start": 1984,
        "line_end": 1989,
        "url": "https://transparency.fb.com/)"
    },
    "74": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolence and Incitement\n\tContent Actioned\n\nContent: \n## Content Actioned  \nHow much violence and incitement content did we take action on?  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for violence and incitement. It includes both content we actioned after someone reported it, and content that we found proactively.  \n[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)\n",
        "line_start": 1994,
        "line_end": 1999,
        "url": "https://transparency.fb.com/)"
    },
    "75": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolence and Incitement\n\tProactive Rate\n\nContent: \n## Proactive Rate  \nOf the violating content we actioned for violence and incitement content, how much did we find and action before people reported it?  \nFound and actioned by us  \nReported by users  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \n[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)  \nCorrecting mistakes  \nPeople can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.\n",
        "line_start": 2004,
        "line_end": 2013,
        "url": "https://transparency.fb.com/)"
    },
    "76": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolence and Incitement\n\tAppealed Content\n\nContent: \n## Appealed Content  \nHow much of the content we actioned for violence and incitement content did people appeal?  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \n[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)\n",
        "line_start": 2022,
        "line_end": 2027,
        "url": "https://transparency.fb.com/)"
    },
    "77": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolence and Incitement\n\tRestored Content\n\nContent: \n## Restored Content  \nHow much actioned content for violence and incitement content was later restored?  \nRestored without appeal  \nRestored after appeal  \nTotal  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)  \nNOTE:  \nDue to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.  \nHow we calculate it  \nPrevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for violence and incitement. It includes both content we actioned after someone reported it, and content that we found proactively.  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Home](https://transparency.fb.com/)  \n[Data](https://transparency.fb.com/reports/)  \n[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)\n",
        "line_start": 2032,
        "line_end": 2055,
        "url": "https://transparency.fb.com/)"
    },
    "78": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolent and Graphic Content\n\nContent: \n# Violent and Graphic Content  \nWe remove content that glorifies violence or celebrates the suffering or humiliation of others on Facebook and Instagram. We do allow people to share some graphic content to raise awareness about current events and issues. In these cases, we may hide the content from people under 18 and cover it with a warning for those over 18, so people are aware it is graphic or violent before they choose to view it.  \n[Read the policy details](https://transparency.fb.com/policies/community-standards/violent-graphic-content/)  \nFacebook  \nFacebook  \nInstagram  \n[Download (CSV)](https://transparency.fb.com/sr/community-standards/)\n",
        "line_start": 2078,
        "line_end": 2085,
        "url": "https://transparency.fb.com/)"
    },
    "79": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolent and Graphic Content\n\tQ3 2023\n\nContent: \n## Q3 2023  \n9 million  \n-----------  \nContent Actioned on Violent and Graphic Content  \n-------------------------------------------------  \nContent actioned decreased from 13.8 million in Q2 2023 to 9.0 million in Q3 2023, due to changes made to our enforcement systems.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/graphic-violence/facebook/#content-actioned)  \n## Q3 2023  \n98.2%  \n-------  \nProactive Rate on Violent and Graphic Content  \n-----------------------------------------------  \nProactive rate increased from 97.5% in Q2 2023 to 98.2% in Q3 2023, due to an update in our calculation to the proactive rate.  \n[](https://transparency.fb.com/reports/community-standards-enforcement/graphic-violence/facebook/#proactive-rate)\n",
        "line_start": 62,
        "line_end": 76,
        "url": "https://transparency.fb.com/)"
    },
    "80": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolent and Graphic Content\n\tprevalence\n\nContent: \n## prevalence  \nHow prevalent were violent and graphic content violations?  \nHow we calculate it  \nPrevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.  \n[Read about this data](https://transparency.fb.com/policies/improving/prevalence-metric/)\n",
        "line_start": 712,
        "line_end": 717,
        "url": "https://transparency.fb.com/)"
    },
    "81": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolent and Graphic Content\n\tcontent actioned\n\nContent: \n## content actioned  \nHow much violent and graphic content did we take action on?  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for graphic violence. It includes both content we actioned after someone reported it, and content that we found proactively.  \n[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)\n",
        "line_start": 722,
        "line_end": 727,
        "url": "https://transparency.fb.com/)"
    },
    "82": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolent and Graphic Content\n\tproactive rate\n\nContent: \n## proactive rate  \nOf the violating content we actioned for violent and graphic content, how much did we find and action before people reported it?  \nFound and actioned by us  \nReported by users  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \n[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)  \nCorrecting mistakes  \nPeople can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.\n",
        "line_start": 732,
        "line_end": 741,
        "url": "https://transparency.fb.com/)"
    },
    "83": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolent and Graphic Content\n\tappealed content\n\nContent: \n## appealed content  \nHow much of the content we actioned for violent and graphic content did people appeal?  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \n[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)\n",
        "line_start": 750,
        "line_end": 755,
        "url": "https://transparency.fb.com/)"
    },
    "84": {
        "content": "Source document: data/platform-docs-versions-english/Facebook_Community-Report/Community Standards Enforcement Report.md\nParagraph location: \n\tViolent and Graphic Content\n\trestored content\n\nContent: \n## restored content  \nHow much actioned content for violent and graphic content was later restored?  \nRestored without appeal  \nRestored after appeal  \nTotal  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.  \n[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)  \nNOTE:  \nDue to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.  \nHow we calculate it  \nPrevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.  \nHow we calculate it  \nContent actioned is the total number of pieces of content that Facebook took action on for graphic violence. It includes both content we actioned after someone reported it, and content that we found proactively.  \nHow we calculate it  \nProactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.  \nHow we calculate it  \nAppealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.  \nHow we calculate it  \nRestored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.\n",
        "line_start": 760,
        "line_end": 780,
        "url": "https://transparency.fb.com/)"
    }
}