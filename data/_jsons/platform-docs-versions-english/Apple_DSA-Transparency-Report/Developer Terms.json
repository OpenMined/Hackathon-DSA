{
    "0": {
        "content": "Source document: data/platform-docs-versions-english/Apple_DSA-Transparency-Report/Developer Terms.md\nParagraph location: \n\tDSA Transparency Report\n\tOctober 2023\n\nContent: \n## October 2023  \nIn accordance with Articles 15, 24 and 42 of the EU\u2019s Digital Services Act (DSA), this transparency report provides information on orders and notices of illegal content received by the App Store and content moderation that the App Store has undertaken on its own initiative.[1](#one) This first report covers the reporting period between 27 August 2023 and 27 September 2023. Subsequent reports will cover successive six-month periods.\n",
        "line_start": 4,
        "line_end": 6
    },
    "1": {
        "content": "Source document: data/platform-docs-versions-english/Apple_DSA-Transparency-Report/Developer Terms.md\nParagraph location: \n\tDSA Transparency Report\n\tSection 1: Orders Received from EU Member States[2](#two)\n\nContent: \n## Section 1: Orders Received from EU Member States[2](#two)  \nThis section covers orders issued by EU Member States\u2019 judicial or administrative authorities to act against illegal content in accordance with Article 9 of the DSA. These orders can be submitted through Content Reports ([ContentReports.apple.com](http://contentreports.apple.com/)) \u2014 the App Store notice and action mechanism developed in compliance with Article 16 \u2014 as well as through existing communication channels.[3](#three) The section also covers orders issued by EU Member States\u2019 judicial or administrative authorities to provide information as defined by Article 10 of the DSA.  \n**Total number of EU Member State orders to act against illegal content: 1**  \n**Table 1.1:** EU Member State orders to act against illegal content categorised by the EU Member State issuing the order  \n|     | **Count of EU Member State orders** |\n| --- | --- |\n| Hungary | 1   |  \n**Table 1.2:** EU Member State orders to act against illegal content categorised by type of illegal content concerned  \n|     | **Count of EU Member State orders** |\n| --- | --- |\n| Provides or facilitates an illegal service | 1   |  \nEU Member State orders to act against illegal content \u2014 median time to confirm receipt: 0 days[4](#four)  \nEU Member State orders to act against illegal content \u2014 median time to give effect to the order: 5 days  \n**Total number of EU Member State orders to provide information: 8**  \n**Table 1.3:** EU Member State orders to provide information categorised by the EU Member State issuing the order  \n|     | **Count of EU Member State orders** |\n| --- | --- |\n| France | 3   |\n| Germany | 1   |\n| Hungary | 1   |\n| Italy | 1   |\n| Netherlands | 1   |\n| Sweden | 1   |  \nEU Member State orders to provide information \u2014 median time to confirm receipt: 0 days  \nEU Member State orders to provide information \u2014 median time to give effect to the order: 3 days\n",
        "line_start": 8,
        "line_end": 33
    },
    "2": {
        "content": "Source document: data/platform-docs-versions-english/Apple_DSA-Transparency-Report/Developer Terms.md\nParagraph location: \n\tDSA Transparency Report\n\tSection 2: Notices Received Through Notice and Action Mechanism\n\nContent: \n## Section 2: Notices Received Through Notice and Action Mechanism  \nThe App Store notice and action mechanism in accordance with Article 16 is available at [ContentReports.apple.com](http://contentreports.apple.com/) or through the [Report a Problem tool](http://reportaproblem.apple.com/) and can be accessed by any individual or entity with an EU IP address.  \n**Total number of notices: 615**  \n**Table 2.1:** Notices categorised by type of alleged illegal content concerned[5](#five)  \n|     | **Count of notices** |\n| --- | --- |\n| Violates intellectual property rights[6](#six) | 547 |\n| Violates consumer protection or privacy law | 19  |\n| Provides or facilitates an illegal service | 17  |\n| Child sexual abuse material | 8   |\n| Violates advertising law | 4   |\n| Illegal hate speech | 3   |\n| Incites terrorism or violence | 0   |\n| Other | 17  |  \nNotices submitted by trusted flaggers: 0[7](#seven)  \nNotices processed using automated means: 0  \n**Total number of notices on which the App Store took an action: 14[8](#eight)**  \n* Action taken on the basis of the law: 0\n* Action taken on the basis of terms and conditions: 14[9](#nine)  \nMedian time to take action: 8 days\n",
        "line_start": 47,
        "line_end": 67
    },
    "3": {
        "content": "Source document: data/platform-docs-versions-english/Apple_DSA-Transparency-Report/Developer Terms.md\nParagraph location: \n\tDSA Transparency Report\n\tSection 3: App Store\u2013Initiated Content Moderation\n\nContent: \n## Section 3: App Store\u2013Initiated Content Moderation  \nThe App Store moderates three types of content for compliance with applicable law and terms and conditions: live apps that are published on the App Store, ads that are live on the App Store,[10](#ten) and user ratings and reviews and public developer responses (both before and after publication).  \n**Content moderation relating to published apps**  \nBefore they\u2019re published on the App Store \u2014 that is, before becoming subject to any content moderation decisions \u2014 all apps and app updates are subject to two levels of ex ante review by the App Review team (App Review): automated review and human review. After apps are published, the App Store continues to monitor them and can and does take action, including app takedowns, if it identifies apps that do not comply with applicable law, with the [App Store Review Guidelines](https://developer.apple.com/app-store/review/guidelines/) or with other applicable terms and conditions \u2014 namely the [Apple Developer Agreement](https://developer.apple.com/support/downloads/terms/apple-developer-agreement/Apple-Developer-Agreement-20230605-English.pdf) or the [Apple Developer Program License Agreement](https://developer.apple.com/support/terms/apple-developer-program-license-agreement/) (DPLA). The App Store may also take action if alerted to concerns about an app by third parties, including via Report a Problem or Content Reports.  \nAutomated tools are used to assist App Review specialists in their ongoing monitoring of apps published on the App Store. This includes automated tools that detect malware or bait-and-switch apps that change their functionality after approval by App Review. It also includes automated tools that scan user reviews of published apps to identify concerns raised by consumers that may indicate that apps contain content incompatible with applicable law or terms and conditions. These tools are continually trained and enhanced to address new and emerging threats and to factor in learning from human-based decision-making. Any apps flagged as potentially problematic by these automated tools are escalated to human App Review specialists. These specialists then determine whether the apps violate App Store terms and conditions and, if so, what action to take \u2014 for example, app removal. No such actions are taken solely on the basis of automated tools.  \nApp Review supports all official EU Member State languages ([see Table 3.1](#table3)). Each specialist receives language- and region-specific training that covers cultural and sensitivity issues as they relate to enforcing the App Store Review Guidelines. Specialists also participate in regular discussions on new issues or trends that arise in their particular regions.  \nAll App Review specialists charged with the continuing review of apps published on the App Store receive comprehensive training when they join the App Review team. This training is supplemented by ongoing training to ensure that specialists remain informed of new and emerging threats and issues. They have access to senior App Review specialists for guidance and can escalate issues internally, including to the App Review Board.  \n**Content moderation relating to published ads**  \nBefore they\u2019re published on the App Store, ads are reviewed to ensure that they comply with [Apple Search Ads Advertising Policies](https://searchads.apple.com/policies). The App Store will also moderate ads after they\u2019re published if it becomes aware that they\u2019re in breach of the Apple Search Ads Advertising Policies.  \nSome automated tools are used to assist with moderating ads, but final decisions regarding content moderation are taken by humans.  \nPersonnel charged with moderating published Apple Search Ads content receive comprehensive training when they join the team. This training is supplemented by ongoing training to ensure that personnel remain informed of new and emerging threats and issues.  \n**Content moderation relating to user ratings and reviews as well as developer responses**  \nCustomers provide ratings and reviews on the App Store to give feedback on their experience with an app and to help others decide which apps they\u2019d like to try. App developers can respond to user reviews regarding their apps. Some submitted ratings and reviews aren\u2019t published on the App Store because automated tools are applied before they\u2019re published to prevent reviews or responses that contain certain types of content \u2014 such as spam, fake reviews or profanity \u2014 from ever being published on the App Store. Nonetheless, we include these ratings and reviews in the relevant tables that follow.  \nAll user ratings and reviews must comply with the Submissions Guidelines in the [Apple Media Services (AMS) Terms and Conditions](https://www.apple.com/legal/internet-services/itunes/). Ratings and reviews that do not comply with these terms and conditions can be removed from the App Store. All developer responses must comply with the Developer Code of Conduct in the App Store Review Guidelines, as well as with the DPLA. Responses that do not comply can also be removed from the App Store.  \nWe use a combination of automated and human review to moderate this content. Any reviews that may violate the law or App Store terms and conditions are evaluated by human moderators. Automated tools are used to flag reviews with potential concerns for human moderators to consider; but because decisions are taken by human reviewers rather than by automated means, considerations of the accuracy or error rate of such automated tools do not apply. Human reviewers sometimes detect or are alerted by developers and customers to published reviews that contain new patterns of illegal content or content that doesn\u2019t comply with the AMS Terms and Conditions. In these circumstances, human reviewers may run automated queries to detect other published reviews that contain such content.  \nThe personnel responsible for moderating user ratings and reviews and developer responses both before and after publication on the App Store receive comprehensive training at onboarding. This training is supplemented by ongoing training to ensure that personnel remain informed of new and emerging threats and issues.  \n**Total number of human resources dedicated to content moderation: 607**  \n**Table 3.1: Human resources dedicated to content moderation categorised by supported language[11](#eleven)**  \nIn accordance with Article 42(2)(a) of the DSA, the App Store must specify the human resources that it dedicates to content moderation, broken down by each official language of the EU Member States. The App Store does not maintain separate content moderation teams per EU Member State language, so it has detailed the number of content moderation human resources broken down by proficiency in EU Member State languages.  \n|     | **Count of dedicated human resources** |\n| --- | --- |\n| English | 607 |\n| Spanish | 42  |\n| Portuguese | 34  |\n| German | 32  |\n| French | 29  |\n| Italian | 22  |\n| Swedish | 14  |\n| Danish | 13  |\n| Polish | 10  |\n| Slovak | 10  |\n| Dutch | 9   |\n| Bulgarian | 8   |\n| Czech | 8   |\n| Greek | 8   |\n| Croatian | 7   |\n| Hungarian | 6   |\n| Romanian | 6   |\n| Estonian | 5   |\n| Finnish | 5   |\n| Slovenian | 5   |\n| Maltese | 4   |\n| Latvian | 3   |\n| Lithuanian | 3   |\n| Irish | 2   |  \n**Total number of content moderation measures taken:** **1,000,804**  \nNumber of content moderation measures taken detected solely using automated means: 221,255[12](#twelve)  \n**Table 3.2:** Content moderation measures taken categorised by type of restriction applied  \n|     | **Count of content moderation measures taken** |\n| --- | --- |\n| Accounts terminated[13](#thirteen) | 512,914 |\n| Ratings or reviews removed[14](#fourteen) | 480,719 |\n| Apps removed[15](#fifteen) | 7,129 |\n| Apps restricted[16](#sixteen) | 27  |\n| Ads removed | 10  |\n| Accounts restricted[17](#seventeen) | 5   |  \n**Table 3.3:** Content moderation measures taken categorised by type of illegal content or violation of terms and conditions  \n|     | **Count of content moderation measures taken** |\n| --- | --- |\n| AMS Terms Section K \u2014 Prohibited Use of Service | 993,429 |\n| App Store Review Guideline 4.0 \u2014 Design[18](#eighteen) | 5,456 |\n| Apple DPLA Section 3.2(f) \u2014 Fraud | 1,756 |\n| App Store Review Guideline 4.3 \u2014 Spam | 38  |\n| App Store Review Guideline 5.6.3 \u2014 Discovery Fraud | 27  |\n| App Store Review Guideline 3 \u2014 Business | 21  |\n| App Store Review Guideline 4.1 \u2014 Copycats | 14  |\n| App Store Review Guideline 2.3.1 \u2014 Accurate Metadata | 9   |\n| App Store Review Guideline 5.6 \u2014 Developer Code of Conduct | 9   |\n| App Store Review Guideline 2.1 \u2014 App Completeness | 5   |\n| App Store Review Guideline 1.1 \u2014 Objectionable Content | 5   |\n| Advertising Policies 3.4 \u2014 Adult Content | 4   |\n| App Store Review Guideline 3.1.2 \u2014 Subscriptions | 4   |\n| App Store Review Guideline 3.1.1 \u2014 In-App Purchases | 3   |\n| App Store Review Guideline 5 \u2014 Legal | 3   |\n| App Store Review Guideline 5.2.3 \u2014 Intellectual Property \u2014 Audio/Video Downloading | 3   |\n| Advertising Policies 4.2 \u2014 Sensitive Content or Imagery | 2   |\n| App Store Review Guideline 2.3 \u2014 Accurate Metadata | 2   |\n| App Store Review Guideline 4.2 \u2014 Minimum Functionality | 2   |\n| App Store Review Guideline 4.8 \u2014 Sign in with Apple | 2   |\n| Advertising Policies 1 \u2014 Advertiser Responsibilities | 1   |\n| Advertising Policies 3.5 \u2014 Controlled Substances | 1   |\n| Advertising Policies 4.4 \u2014 Real Money Gambling | 1   |\n| Advertising Policies 4.6 \u2014 Dating Services/Match Making | 1   |\n| App Store Review Guideline 2.3.7 \u2014 Accurate Metadata | 1   |\n| App Store Review Guideline 2.5.18 \u2014 Software Requirements | 1   |\n| App Store Review Guideline 3.2.2 \u2014 Unacceptable Business Model | 1   |\n| App Store Review Guideline 5.1.1 \u2014 Data Collection and Storage | 1   |\n| App Store Review Guideline 5.2.1 \u2014 Intellectual Property \u2014 Generally | 1   |\n| App Store Review Guideline 5.2.2 \u2014 Intellectual Property \u2014 Third-Party Sites/Services | 1   |\n",
        "line_start": 77,
        "line_end": 166
    },
    "4": {
        "content": "Source document: data/platform-docs-versions-english/Apple_DSA-Transparency-Report/Developer Terms.md\nParagraph location: \n\tDSA Transparency Report\n\tSection 4: Complaints[19](#nineteen)\n\nContent: \n## Section 4: Complaints[19](#nineteen)  \n**Total complaints received: 147**  \nMedian time to take decisions: 11 days  \n**Table 4.1:** Complaints received categorised by the basis for the complaint[20](#twenty)  \n|     | **Count of complaints received** |\n| --- | --- |\n| Procedural complaints | 0   |\n| Substantive complaints on the illegality or incompatibility | 147 |\n| Restriction imposed is not diligent, objective, or proportionate | 0   |  \n**Table 4.2:** Complaints received categorised by decision taken  \n|     | **Count of complaints received** |\n| --- | --- |\n| Decision upheld | 53  |\n| Decision reversed | 34  |\n| Decision pending | 60  |  \n**Section 5: Out-of-Court Disputes**  \nNumber of disputes submitted to out-of-court dispute settlement bodies referred to in Article 21: 0[21](#twentyone)  \n**Section 6: Suspensions for Misuse of the Service**  \nDSA Article 23(1) provides for the suspension of users who \u201cfrequently provide manifestly illegal content.\u201d DSA Article 23(2) provides for the suspension of users who \u201cfrequently submit notices or complaints that are manifestly unfounded.\u201d  \nUnder its existing content moderation practices, and in accordance with its terms and conditions, the App Store will terminate \u2014 rather than merely suspend \u2014 the accounts of any user or developer who frequently provides manifestly illegal content in the form of apps, user reviews of published apps or other forms of illegal content. The App Store may suspend or terminate users who frequently submit Content Reports notices or related complaints that are manifestly unfounded.  \n**Total number of suspensions for provision of manifestly illegal content: 0**  \n**Total number of suspensions for submission of manifestly unfounded notices: 0**  \n**Total number of suspensions for submission of manifestly unfounded complaints: 0**\n",
        "line_start": 192,
        "line_end": 215
    },
    "5": {
        "content": "Source document: data/platform-docs-versions-english/Apple_DSA-Transparency-Report/Developer Terms.md\nParagraph location: \n\tDSA Transparency Report\n\tSection 7: App Store Recipients of the Service\n\nContent: \n## Section 7: App Store Recipients of the Service  \n**Table 7.1:** Average monthly recipients of the App Store categorised by EU Member State  \n|     | **Count of monthly recipients of the App Store** |\n| --- | --- | --- |\n| Austria | 3 million |\n| Belgium | 4 million |\n| Bulgaria | Under 1 million |\n| Croatia | Under 1 million |\n| Cyprus | Under 1 million |\n| Czechia | 2 million |\n| Denmark | 4 million |\n| Estonia | Under 1 million |\n| Finland | 2 million |\n| France | 24 million |\n| Germany | 28 million |\n| Greece | 2 million |\n| Hungary | 2 million |     |\n| Ireland | 2 million |\n| Italy | 14 million |\n| Latvia | Under 1 million |\n| Lithuania | Under 1 million |\n| Luxembourg | Under 1 million |\n| Malta | Under 1 million |\n| Netherlands | 8 million |\n| Poland | 5 million |\n| Portugal | 2 million |\n| Romania | 2 million |\n| Slovakia | Under 1 million |\n| Slovenia | Under 1 million |\n| Spain | 11 million |\n| Sweden | 6 million |  \n1. Data in the report comes from EU Member State storefronts only.\n2. For the purposes of this report, an \u201corder\u201d is a valid request from a Member State judicial or administrative authority in accordance with specific mandatory powers under the laws of the Member State in question, seeking production of information relating to the use of App Store services by one or more specific recipients of the service, or requiring action to be taken in respect of specific items of illegal content, regardless of whether it constitutes an order legally binding on Apple Distribution International Limited. This reporting is without prejudice to the legal position of Apple Distribution International Limited with regard to the binding nature of any such order, under applicable law.\n3. For more information on accessing the Content Reports portal, please see Section 2.\n4. All lengths of time are listed in calendar days.\n5. This table displays the category of illegal content selected by the notifier. The selected category may not accurately reflect the content concerned.\n6. Intellectual property rights notices are generally settled by the rights\u2019 claimants themselves without requiring an action from the App Store.\n7. Under DSA Article 22(5), the European Commission will publish in a publicly available database information regarding entities awarded the status of trusted flaggers by the Digital Services Coordinators; these Digital Services Coordinators are designated by the EU Member States in accordance with DSA Article 22(2). To date, no such information has been published.\n8. For more information on the content moderation actions that the App Store takes, see Table 3.2. Some actions on reported notices may not be included in these figures because they were pending at the time that data was collected. Additionally, some notices are not related to the reporting of illegal content and are therefore not actionable.\n9. The App Store terms and conditions \u2014 including the App Store Review Guidelines, the Apple Developer Program License Agreement (DPLA) and Apple Media Services (AMS) Terms and Conditions \u2014 prohibit illegal content on the App Store, as well as the use of the App Store for illegal purposes. As such, this figure may include actions taken against content that might also be incompatible with applicable laws.\n10. Apple Search Ads is a separate business from the App Store, and it\u2019s included in this report because its business involves selling advertising media on the App Store.\n11. Table 3.1 lists human resources who are proficient in multiple languages under each applicable language.\n12. This category includes ratings and reviews detected and removed solely through automated means.\n13. This category includes terminations of App Store developers, AMS customers and Apple Search Ads advertisers.\n14. This category includes ratings and reviews removed before and after publication.\n15. This category includes apps that were live on the App Store when the developer account was terminated.\n16. This category includes apps that were suppressed on App Store charts and in App Store search. It also includes apps blocked from being transferred to other developers.\n17. This category includes user accounts that are restricted from leaving ratings or reviews on the App Store.\n18. This removal is the result of ongoing cleanup for outdated apps.\n19. The App Store has multiple complaint-handling systems from which data is included in this section. These systems cover complaints related to Content Reports notices, review removals, App Review Board (ARB) cases, platform-to-business (P2B) cases and advertisement restrictions. For more information on redress options, please see [apple.com/legal/dsa/en/redress-options.html](https://www.apple.com/legal/dsa/en/redress-options.html).\n20. The App Store will seek to provide users filing complaints with additional flexibility to select a basis for complaint for future reports.\n21. In accordance with Article 21(8) of the DSA, the European Commission will publish a list of certified out-of-court dispute settlement bodies certified by Digital Services Coordinators under DSA Article 21(3). To date, no such list has been published.\n",
        "line_start": 230,
        "line_end": 282
    }
}