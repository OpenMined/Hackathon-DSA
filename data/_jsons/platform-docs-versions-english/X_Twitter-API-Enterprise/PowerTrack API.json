{
    "0": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\nContent: \nOverview  \nThis endpoint has been updated to include Tweet edit metadata. Learn more about these metadata on the [\"Edit Tweets\" fundamentals page](https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets).\n",
        "line_start": 0,
        "line_end": 2,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "1": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tOverview\n\nContent: \n# Overview  \n[Enterprise](https://developer.twitter.com/en/products/twitter-api/enterprise)  \n_This is an enterprise API available within our managed access levels only. To use this API, you must first set up an account with our enterprise sales team.\u00a0[Learn more](https://developer.twitter.com/en/products/twitter-api/enterprise)_  \n_You can view all of the Twitter API filtered stream offerings\u00a0[HERE](https://developer.twitter.com/en/docs/twitter-api/filtered-stream-overview)._  \nThe PowerTrack API provides customers with the ability to filter the full Twitter firehose, and only receive the data that they or their customers are interested in. This is accomplished by applying the PowerTrack filtering language - see [Rules and filtering](https://developer.twitter.com/en/docs/twitter-api/enterprise/rules-and-filtering/overview.html) - to match Tweets based on a wide variety of attributes, including user attributes, geo-location, language, and many others. Using PowerTrack rules to filter Tweet ensures that customers receive all of the data, and\u00a0_only_\u00a0the data they need for your app.\n",
        "line_start": 4,
        "line_end": 9,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "2": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tOverview\n\tCore components\n\nContent: \n### Core components  \nThe PowerTrack API consists of two endpoints:  \n#### Rules endpoint  \nA separate endpoint managed independently by your application, the rules endpoint supports GET, POST,\u00a0POST \\_method=delete\u00a0and rule validation methods with basic authentication for managing your ruleset. It can support thousands of rules that allow you to filter the realtime stream of data for the topics and conversations that you care about. The rules endpoint can be accessed, managed, and will persist regardless of your connection status to the stream - you can also update (add/remove) rules while connected to the stream and the changes will take effect almost immediately.  \n#### Stream endpoint  \nConnecting to the streaming endpoint consists of a simple [GET](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/api-reference/powertrack-stream) request using basic authentication. Once a connection is established, data is delivered in JSON format (see sample payload below) through a persistent HTTP Streaming connection. You will only receive data matching your rules while connected to the stream.  \n#### Rule tags  \nA single PowerTrack stream can support thousands of rules, so being able to discern which rule(s) matched a given Tweet becomes important. This is easily solved by using rule tags. Upon rule creation, you can assign a tag value which will be returned in the matching\\_rules\u00a0object ([see here](https://developer.twitter.com/en/docs/twitter-api/enterprise/enrichments/overview/matching-rules.html))\u00a0of the response payload.  \nRule tags can represent an end customer use case, a topic or conversation, or another helpful identifier that you can use to route incoming Tweets accordingly.  \nIf, in addition to realtime data, your product also requires instant access to recent data, we recommend using our\u00a0[Search API](https://developer.twitter.com/en/docs/twitter-api/search-overview).\n",
        "line_start": 15,
        "line_end": 25,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "3": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tOverview\n\tAvailable operators\n\nContent: \n### Available operators  \nThe PowerTrack API currently supports the following operators:  \n* keyword\n* emoji\n* \"exact phrase match\"\n* \"keyword1 keyword2\"~N\n* contains:\n* from:\n* to:\n* url:\n* url\\_title:\n* url\\_description:\n* url\\_contains:\n* has:links\n* sample:\n* #\n* point\\_radius:\\[lon lat radius\\]\n* bounding\\_box:\\[west\\_long south\\_lat east\\_long north\\_lat\\]\n* @\n* $\n* bio:\n* bio\\_name:\n* retweets\\_of:\n* lang:\n* bio\\_location:\n* statuses\\_count:\n* followers\\_count:\n* friends\\_count:\n* listed\\_count:\n* is:verified\n* source:\n* place:\n* place\\_country:\n* has:geo\n* has:mentions\n* has:hashtags\n* has:images\n* has:videos\n* has:media\n* has:symbols\n* is:retweet\n* is:reply\n* is:quote\n* retweets\\_of\\_status\\_id:\n* in\\_reply\\_to\\_status\\_id:\n* has:profile\\_geo\n* profile\\_point\\_radius:\\[long lat radius\\]\n* profile\\_bounding\\_box:\\[west\\_long south\\_lat east\\_long north\\_lat\\]\n* profile\\_country:\n* profile\\_region:\n* profile\\_locality:\n* profile\\_subregion:  \nFor more details, please see the\u00a0[Getting started with enterprise rules](https://developer.twitter.com/en/docs/twitter-api/enterprise/rules-and-filtering/enterprise-operators)\u00a0guide.\n",
        "line_start": 36,
        "line_end": 89,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "4": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tOverview\n\tSample payload\n\nContent: \n### Sample payload  \nBelow is a sample payload from the PowerTrack API in Native Enriched format:  \n`{   \"created_at\": \"Wed Oct 10 20:19:24 +0000 2018\",   \"id\": 1050118621198921700,   \"id_str\": \"1050118621198921728\",   \"text\": \"To make room for more expression, we will now count all emojis as equal\u2014including those with gender\u200d\u200d\u200d \u200d\u200dand skin t\u2026 https://t.co/MkGjXf9aXm\",   \"source\": \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\",   \"truncated\": true,   \"in_reply_to_status_id\": null,   \"in_reply_to_status_id_str\": null,   \"in_reply_to_user_id\": null,   \"in_reply_to_user_id_str\": null,   \"in_reply_to_screen_name\": null,   \"user\": {     \"id\": 6253282,     \"id_str\": \"6253282\",     \"name\": \"Twitter API\",     \"screen_name\": \"TwitterAPI\",     \"location\": \"San Francisco, CA\",     \"url\": \"https://developer.twitter.com\",     \"description\": \"The Real Twitter API. Tweets about API changes, service issues and our Developer Platform. Don't get an answer? It's on my website.\",     \"translator_type\": \"null\",     \"derived\": {       \"locations\": [         {           \"country\": \"United States\",           \"country_code\": \"US\",           \"locality\": \"San Francisco\",           \"region\": \"California\",           \"sub_region\": \"San Francisco County\",           \"full_name\": \"San Francisco, California, United States\",           \"geo\": {             \"coordinates\": [               -122.41942,               37.77493             ],             \"type\": \"point\"           }         }       ]     },     \"protected\": false,     \"verified\": true,     \"followers_count\": 6172196,     \"friends_count\": 12,     \"listed_count\": 13003,     \"favourites_count\": 31,     \"statuses_count\": 3650,     \"created_at\": \"Wed May 23 06:01:13 +0000 2007\",     \"utc_offset\": null,     \"time_zone\": null,     \"geo_enabled\": false,     \"lang\": \"en\",     \"contributors_enabled\": false,     \"is_translator\": null,     \"profile_background_color\": \"null\",     \"profile_background_image_url\": \"null\",     \"profile_background_image_url_https\": \"null\",     \"profile_background_tile\": null,     \"profile_link_color\": \"null\",     \"profile_sidebar_border_color\": \"null\",     \"profile_sidebar_fill_color\": \"null\",     \"profile_text_color\": \"null\",     \"profile_use_background_image\": null,     \"profile_image_url\": \"null\",     \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/942858479592554497/BbazLO9L_normal.jpg\",     \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/6253282/1497491515\",     \"default_profile\": false,     \"default_profile_image\": false,     \"following\": null,     \"follow_request_sent\": null,     \"notifications\": null   },   \"geo\": null,   \"coordinates\": null,   \"place\": null,   \"contributors\": null,   \"is_quote_status\": false,   \"extended_tweet\": {     \"full_text\": \"To make room for more expression, we will now count all emojis as equal\u2014including those with gender\u200d\u200d\u200d \u200d\u200dand skin tone modifiers \ud83d\udc4d\ud83c\udffb\ud83d\udc4d\ud83c\udffd\ud83d\udc4d\ud83c\udfff. This is now reflected in Twitter-Text, our Open Source library. \\n\\nUsing Twitter-Text? See the forum post for detail: https://t.co/Nx1XZmRCXA\",     \"display_text_range\": [       0,       277     ],     \"entities\": {       \"hashtags\": [],       \"urls\": [         {           \"url\": \"https://t.co/Nx1XZmRCXA\",           \"expanded_url\": \"https://twittercommunity.com/t/new-update-to-the-twitter-text-library-emoji-character-count/114607\",           \"display_url\": \"twittercommunity.com/t/new-update-t\u2026\",           \"unwound\": {             \"url\": \"https://twittercommunity.com/t/new-update-to-the-twitter-text-library-emoji-character-count/114607\",             \"status\": 200,             \"title\": \"New update to the Twitter-Text library: Emoji character count\",             \"description\": \"Over the years, we have made several updates to the way that people can communicate on Twitter. One of the more notable changes made last year was to increase the number of characters per Tweet from 140 to 280 characters. Today, we continue to expand people\u2019s ability to express themselves by announcing a change to the way that we count emojis. Due to the differences in the way written text and emojis are encoded, many emojis (including emojis where you can apply gender and skin tone) have count...\"           },           \"indices\": [             254,             277           ]         }       ],       \"user_mentions\": [],       \"symbols\": []     }   },   \"quote_count\": 0,   \"reply_count\": 0,   \"retweet_count\": 0,   \"favorite_count\": 0,   \"entities\": {     \"hashtags\": [],     \"urls\": [       {         \"url\": \"https://t.co/MkGjXf9aXm\",         \"expanded_url\": \"https://twitter.com/i/web/status/1050118621198921728\",         \"display_url\": \"twitter.com/i/web/status/1\u2026\",         \"indices\": [           117,           140         ]       }     ],     \"user_mentions\": [],     \"symbols\": []   },   \"favorited\": false,   \"retweeted\": false,   \"possibly_sensitive\": false,   \"filter_level\": \"low\",   \"lang\": \"en\",   \"timestamp_ms\": \"1539202764211\",   \"matching_rules\": [     {       \"tag\": null,       \"id\": 1128017341835464700,       \"id_str\": \"1128017341835464704\"     }   ] } }`\n",
        "line_start": 94,
        "line_end": 97,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "5": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tOverview\n\tNext steps\n\nContent: \n## Next steps  \n[Continue to the realtime PowerTrack API reference](https://developer.twitter.com/en/docs/tweets/filter-realtime/api-reference/powertrack-stream)  \nSee code examples:  \n* [See simple scripts in several languages to help get started](https://github.com/gnip/support/tree/master/Premium%20Stream%20Connection)\n* [Build a trends dashboard with Twitter API Toolkit for Google Cloud](https://developer.twitter.com/en/docs/tutorials/developer-guide--twitter-api-toolkit-for-google-cloud11)\n* See an example Java client libraries: [Hosebird Client adapted for enterprise streams](https://github.com/jimmoffitt/hbc), [Gnip4J](https://github.com/zauberlabs/gnip4j)  \n* [See an example Python client library](https://github.com/tw-ddis/Gnip-Stream-Collector-Metrics)  \nIntegrating with PowerTrack\n",
        "line_start": 102,
        "line_end": 110,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "6": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tOverview\n\tIntegrating with PowerTrack\n\nContent: \n## Integrating with PowerTrack  \nTo integrate PowerTrack into your product, you will need to build an application that can do the following:  \n1. Establish a streaming connection to the PowerTrack stream API.\n2. Asynchronously send POST requests to the PowerTrack rules API to add and delete rules from the stream.\n3. Handle low data volumes \u2013 Maintain the streaming connection, and ensure buffers are flushed regularly.\n4. Handle high data volumes \u2013 de-couple stream ingestion from additional processing using asynchronous processes.\n5. Reconnect to the stream automatically when disconnected for any reason.  \nFor details on the types of requests needed for tasks 1 and 2, and important considerations in implementing them, see the\u00a0[API reference](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/api-reference).  \nFor information on consuming a realtime data stream, see\u00a0[here](https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data.html).  \nPowerTrack rules & filtering\n",
        "line_start": 116,
        "line_end": 126,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "7": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tOverview\n\tRules & Filtering\n\nContent: \n## Rules & Filtering  \nTake a deeper dive into building PowerTrack rules using our [learning path: How to detect signal from noise and build powerful filtering rules](https://developer.twitter.com/en/docs/tutorials/building-powerful-enterprise-filters)  \nPowerTrack enhances the ability to filter Twitter\u2019s full firehose, and only receive the data that they or their customers are interested in. This is accomplished by applying PowerTrack filtering language to match Tweets based on a wide variety of attributes, including user attributes, geo-location, language, and many others. Using PowerTrack rules to filter a data source ensures that customers receive all of the data, and\u00a0_only_\u00a0the data they need for your app.  \nAs described, customers add filtering rules to the PowerTrack stream to determine which activities will be sent through the connection. The PowerTrack stream can support thousands of these individual rules, and deliver the combined set of matching activities through the single stream connection.  \nThe set of PowerTrack rules used to filter a customer\u2019s stream is highly flexible. If a customer needs to add a new filtering rule to capture a different type of content, or remove an existing rule, their app can send a request to the PowerTrack API to make it happen. When that request is sent, the filtering rules are automatically modified and the changes simply take effect in the data stream with no need to reconnect. This allows customers to provide data for many customers at scale, while supporting distinct filtering requirements for each of those customers.  \n[See Complete List of Operators \u00bb](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/enterprise-operators.html)  \n#### Data  \nData is delivered to the customer\u2019s app through a constant stream as it is created. The realtime stream does not provide recent data \u2013 rather, it begins filtering for and delivering results based on the time a filtering rule is added to the stream. If, in addition to realtime data, your product also requires instant access to recent data, we recommend using the\u00a0[Search API](https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/overview.html).  \nData is in Gzip compressed JSON format.  \n#### Matching Rules  \nWhen an activity is delivered through the PowerTrack stream, adds metadata in the\u00a0[\u201cmatching rules\u201d](https://developer.twitter.com/en/docs/twitter-api/enterprise/enrichments/overview/matching-rules)\u00a0portion of that activity to indicate which rule or rules caused that specific activity to be delivered. If multiple rules match a single activity, the activity is delivered a single time with each of the matching rules included in this metadata. The matching rules provide an easy way to associate a specific activity with specific rules and customers in your product, even where you have many customers with lots of distinct rules. Since the data is delivered through a single stream in this manner, scaling up as your product gains additional customers is simple.  \n#### Rule Tags  \nAt the time they are created, each filtering rule may be created with a tag. Rule tags have no special meaning, they are simply treated as opaque strings carried along with the rule. They will be included in the \u201cmatching rules\u201d metadata in activities returned. Tags provide an easy way to create logical groupings of PowerTrack rules. For example, you may generate a unique ID for a specific rule as its tag, and allow your app to reference that ID within activities it processes to associate a result with specific customers, campaigns, categories, or other related groups.  \nNote that tags cannot be updated on an existing rule, but can only be included when a rule is created. In order to \u201cupdate\u201d a tag, you need to first remove the rule, then add it again with the updated tag. The best solution is to simply use a unique identifier as your tag, which your system can associate with various other data points within your own app, all without having to change anything in the rule set.  \nPowerTrack operators\n",
        "line_start": 132,
        "line_end": 147,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "8": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack operators\n\nContent: \n# PowerTrack operators  \nBelow is a list of all operators supported in Twitter's enterprise real-time and historical PowerTrack APIs.  \nOperatorDescriptionkeyword\nMatches a keyword within the body of a Tweet. This is a tokenized match, meaning that your keyword string will be matched against the tokenized text of the Tweet body \u2013 tokenization is based on punctuation, symbol, and separator Unicode basic plane characters. For example, a Tweet with the text \u201cI like coca-cola\u201d would be split into the following tokens: I, like, coca, cola. These tokens would then be compared to the keyword string used in your rule. To match strings containing punctuation (for example, coca-cola), symbol, or separator characters, you must use a quoted exact match as described below.  \n**Note:**\u00a0This operator will match on both URLs and unwound URLs within a Tweet.emoji\nMatches an emoji within the body of a Tweet. Emojis are a tokenized match, meaning that your emoji will be matched against the tokenized text of the Tweet body \u2013 tokenization is based on punctuation, symbol/emoji, and separator Unicode basic plane characters. For example, a Tweet with the text \u201cI like \ud83c\udf55\u201d would be split into the following tokens: I, like, \ud83c\udf55. These tokens would then be compared to the emoji used in your rule. Note that if an emoji has a variant, you must use \u201cquotations\u201d to add to a rule.\n\"exact phrase match\"  \nMatches an exact phrase within the body of a Tweet.  \n**Note:**\u00a0In 30 Day Search and Full Archive Search, punctuation is not tokenized and is instead treated as whitespace.\nFor example,\u00a0quoted \u201c#hashtag\u201d will match \u201chashtag\u201d but not #hashtag (use the hashtag # operator without quotes to match on actual hashtags\nFor example, quoted \u201c$cashtag\u201d will match \u201ccashtag\u201d but not $cashtag (use the cashtag $ operator without quotes to match on actual cashtags  \n**Note:**\u00a0This operator will match on both URLs and unwound URLs within a Tweet.\n",
        "line_start": 162,
        "line_end": 174,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "9": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\t\n\nContent: \n#  \nMatches any Tweet with the given hashtag.  \nThis operator performs an exact match, NOT a tokenized match, meaning the rule \u201c2016\u201d will match posts with the exact hashtag \u201c2016\u201d, but not those with the hashtag \u201c2016election\u201d  \nNote: that the hashtag operator relies on Twitter\u2019s entity extraction to match hashtags, rather than extracting the hashtag from the body itself.\u00a0See\u00a0[HERE](https://developer.twitter.com/en/docs/twitter-api/enterprise/data-dictionary/native-enriched-objects/entities)\u00a0for more information on Twitter Entities JSON attributes.  \n@  \nMatches any Tweet that mentions the given username.  \nThe to: operator returns a subset match of the @mention operator.  \n\"keyword1 keyword2\"~N  \nCommonly referred to as a proximity operator, this matches a Tweet where the keywords are no more than N tokens from each other.  \nIf the keywords are in the opposite order, they can not be more than N-2 tokens from each other.  \nCan have any number of keywords in quotes.  \nN cannot be greater than 6.  \n**Example:**\u00a0********************\"snowy mountain resort\"~6********************  \ncontains:  \nSubstring match for Tweets that have the given substring in the body, regardless of tokenization. In other words, this does a pure substring match and does not consider word boundaries.  \nUse double quotes to match substrings that contain whitespace or punctuation.  \nfrom:  \nMatches any Tweet from a specific user.  \nThe value must be the user\u2019s Twitter numeric Account ID or username (excluding the @ character). See\u00a0HERE\u00a0or\u00a0[HERE](http://gettwitterid.com/)\u00a0for methods for looking up numeric Twitter Account IDs.  \nurl:\nPerforms a tokenized (keyword/phrase) match on the expanded URLs of a Tweet (similar to url\\_contains). Tokens and phrases containing punctuation or special characters should be double-quoted. For example, url:\"/developer\". While generally not recommended, if you want to match on a specific protocol, enclose in double-quotes: url:\"https://developer.twitter.com\".  \n**Note:** When using PowerTrack or Historical PowerTrack, this operator will match on URLs contained within the original Tweet of a Quote Tweet. For example, if your rule includes url:\"developer.twitter.com\", and a Tweet contains that URL, any Quote Tweets of that Tweet will be included in the results. This is not the case when using the Search API.url\\_title:  \n_Available alias_: url\\_title:  \nPerforms a keyword/phrase match on the (new) expanded URL HTML title metadata. See [HERE](https://developer.twitter.com/en/docs/twitter-api/enterprise/enrichments/overview/expanded-and-enhanced-urls) for more information on expanded URL enrichment.  \nurl\\_description:  \n_Available alias_: within\\_url\\_description:  \nPerforms a keyword/phrase match on the (new) expanded page description metadata. See\u00a0[HERE](https://developer.twitter.com/en/docs/twitter-api/enterprise/enrichments/overview/expanded-and-enhanced-urls)\u00a0for more information on expanded URL enrichment.  \nurl\\_contains:  \nMatches Tweets with URLs that literally contain the given phrase or keyword. To search for patterns with punctuation in them (i.e. google.com) enclose the search term in quotes.  \nNOTE: If you\u2019re using the [Expanded URL](https://developer.twitter.com/en/docs/twitter-api/enterprise/enrichments/overview/expanded-and-enhanced-urls) output format, we will match against the expanded URL as well.  \nbio:  \n_Available alias_: user\\_bio:  \nMatches a keyword or phrase within the user bio of a Tweet. This is a tokenized match within the contents of the 'description' field within the [User object](https://developer.twitter.com/en/docs/twitter-api/enterprise/data-dictionary/native-enriched-objects/user).  \nbio\\_name:\nMatches a keyword within the user bio name of a Tweet. This is a tokenized match within the contents of a user\u2019s \u201cname\u201d field within the\u00a0[User object](https://developer.twitter.com/en/docs/twitter-api/enterprise/data-dictionary/native-enriched-objects/user).\nbio\\_location:  \n_Available alias_: user\\_bio\\_location:  \nMatches tweets where the User object's location contains the specified keyword or phrase. This operator performs a tokenized match, similar to the normal keyword rules on the message body.  \nThis location is part of the\u00a0[User object](https://developer.twitter.com/en/docs/tweets/data-dictionary/native-enriched-objects/user), and is the account's 'home' location,\u00a0is a non-normalized, user-generated, free-form string, and is different from a Tweet's location (when available).  \nstatuses\\_count:  \n_Available alias_: tweets\\_count:  \nMatches Tweets when the author has posted a number of statuses that falls within the given range.  \nIf a single number is specified, any number equal to or higher will match.  \nAdditionally, a range can be specified to match any number in the given range \u00a0(for example, statuses\\_count:1000..10000).  \nfollowers\\_count:  \nMatches Tweets when the author has a followers count within the given range.  \nIf a single number is specified, any number equal to or higher will match.  \nAdditionally, a range can be specified to match any number in the given range (for example, followers\\_count:1000..10000).  \nfriends\\_count:  \n_Available alias_: following\\_count:  \nMatches Tweets when the author has a friends count (the number of users they follow) that falls within the given range.  \nIf a single number is specified, any number equal to or higher will match.  \nAdditionally, a range can be specified to match any number in the given range (for example, friends\\_count:1000..10000).  \nlisted\\_count:  \n_Available alias_: user\\_in\\_lists\\_count:  \nMatches Tweets when the author has been listed on Twitter a number of times falls within the given range.  \nIf a single number is specified, any number equal to or higher will match.  \nAdditionally, a range can be specified to match any number in the given range (for example, listed\\_count:10..100).  \n$  \nMatches any Tweet that contains the specified \u2018cashtag\u2019 (where the leading character of the token is the \u2018$\u2019 character).  \nNote that the cashtag operator relies on Twitter\u2019s \u2018symbols\u2019 entity extraction to match cashtags, rather than trying to extract the cashtag from the body itself.\u00a0See\u00a0[HERE](https://developer.twitter.com/en/docs/twitter-api/enterprise/data-dictionary/native-enriched-objects/entities)\u00a0for more information on Twitter Entities JSON attributes.  \nretweets\\_of:  \n_Available alias_: retweets\\_of\\_user:  \nMatches Tweets that are Retweets of a specified user. Accepts both usernames and numeric Twitter Account IDs (NOT tweet status IDs).\nSee\u00a0[HERE](https://developer.twitter.com/content/developer-twitter/en/docs/twitter-api/users/lookup)\u00a0for methods for looking up numeric Twitter Account IDs.  \nretweets\\_of\\_status\\_id:  \n_Available alias_: retweets\\_of\\_tweet\\_id:  \nDeliver only explicit Retweets of the specified Tweet.\u00a0Note that the status ID used should be the ID of an original Tweet and not a Retweet.  \nin\\_reply\\_to\\_status\\_id:  \n_Available alias_: in\\_reply\\_to\\_tweet\\_id:  \nDeliver only explicit replies to the specified Tweet.  \nsample:  \nReturns a random sample of Tweets that match a rule rather than the entire set of Tweets. Sample percent must be represented by an integer value between 1 and 100. This operator applies to the entire rule and requires any \u201cOR\u2019d\u201d terms be grouped.  \n**Important Note:**\u00a0The sample operator first reduces the scope of the firehose to X%, then the rule/filter is applied to that sampled subset. If you are using, for example, **sample:10**, each Tweet has a 10% chance of being in the sample.  \nAlso, the sampling is deterministic, and you will get the same data sample in realtime as you would if you pulled the data historically.  \nsource:Matches any Tweet generated by the given source application. The value must be either the name of the application or the application\u2019s URL. **Cannot be used alone.**\nlang:  \nMatches Tweets that have been classified by Twitter as being of a particular language (if, and only if, the tweet has been classified). It is important to note that each Tweet is currently only classified as being of one language, so AND\u2019ing together multiple languages will yield no results.  \n**Note:**\u00a0if no language classification can be made the provided result is \u2018und\u2019 (for undefined).  \nThe list below represents the currently supported languages and their corresponding BCP 47 language identifier:  \n|     |     |     |     |\n| --- | --- | --- | --- |\n| Amharic: am | German: de | Malayalam: ml | Slovak: sk |\n| Arabic: ar | Greek: el | Maldivian: dv | Slovenian: sl |\n| Armenian: hy | Gujarati: gu | Marathi: mr | Sorani Kurdish: ckb |\n| Basque: eu | Haitian Creole: ht | Nepali: ne | Spanish: es |\n| Bengali: bn | Hebrew: iw | Norwegian: no | Swedish: sv |\n| Bosnian: bs | Hindi: hi | Oriya: or | Tagalog: tl |\n| Bulgarian: bg | Latinized Hindi: hi-Latn | Panjabi: pa | Tamil: ta |\n| Burmese: my | Hungarian: hu | Pashto: ps | Telugu: te |\n| Croatian: hr | Icelandic: is | Persian: fa | Thai: th |\n| Catalan: ca | Indonesian: in | Polish: pl | Tibetan: bo |\n| Czech: cs | Italian: it | Portuguese: pt | Traditional Chinese: zh-TW |\n| Danish: da | Japanese: ja | Romanian: ro | Turkish: tr |\n| Dutch: nl | Kannada: kn | Russian: ru | Ukrainian: uk |\n| English: en | Khmer: km | Serbian: sr | Urdu: ur |\n| Estonian: et | Korean: ko | Simplified Chinese: zh-CN | Uyghur: ug |\n| Finnish: fi | Lao: lo | Sindhi: sd | Vietnamese: vi |\n| French: fr | Latvian: lv | Sinhala: si | Welsh: cy |\n| Georgian: ka | Lithuanian: lt |     |  \nplace:  \nMatches Tweets tagged with the specified location\u00a0_or_\u00a0Twitter place ID (see examples). Multi-word place names (\u201cNew York City\u201d, \u201cPalo Alto\u201d) should be enclosed in quotes.  \n**Note:**\u00a0See the\u00a0[GET geo/search](https://developer.twitter.com/en/docs/geo/places-near-location/api-reference/get-geo-search)\u00a0public API endpoint for how to obtain Twitter place IDs.  \n**Note:** This operator will not match on Retweets, since Retweet's places are attached to the original Tweet. It will also not match on places attached to the original Tweet of a Quote Tweet.  \nplace\\_country:  \nMatches Tweets where the country code associated with a tagged\u00a0[place/location](https://developer.twitter.com/en/docs/twitter-api/enterprise/data-dictionary/native-enriched-objects/geo)\u00a0matches the given ISO alpha-2 character code.  \nValid ISO codes can be found here:\u00a0[http://en.wikipedia.org/wiki/ISO\\_3166-1\\_alpha-2](http://en.wikipedia.org/wiki/ISO_3166-1_alpha-2)  \n**Note:** This operator will not match on Retweets, since Retweet's places are attached to the original Tweet. It will also not match on places attached to the original Tweet of a Quote Tweet.  \npoint\\_radius:\\[lon lat radius\\]  \nMatches against the Exact Location (x,y) of the Tweet when present, and in Twitter, against a \u201cPlace\u201d geo polygon, where the Place is fully contained within the defined region.  \n* Units of radius supported are miles (mi) and kilometers (km).\n* Radius must be less than 25mi.\n* Longitude is in the range of \u00b1180\n* Latitude is in the range of \u00b190\n* All coordinates are in decimal degrees.\n* Rule arguments are contained within brackets, space delimited.  \n**Note:** This operator will not match on Retweets, since Retweet's places are attached to the original Tweet. It will also not match on places attached to the original Tweet of a Quote Tweet.  \n**Example:** ********************point\\_radius:\\[2.355128 48.861118 16km\\]\u00a0OR point\\_radius:\\[-41.287336 174.761070 20mi\\]********************  \nbounding\\_box:\\[west\\_long south\\_lat east\\_long north\\_lat\\]  \n_Available alias_: geo\\_bounding\\_box:  \nMatches against the Exact Location (long, lat) of the Tweet when present, and in Twitter, against a \u201cPlace\u201d geo polygon, where the Place is fully contained within the defined region.  \n* west\\_long south\\_lat represent the southwest corner of the bounding box where west-long is the longitude of that point, and south\\_lat is the latitude.\n* east\\_long and north\\_lat represent the northeast corner of the bounding box, where east\\_long is the longitude of that point, and north\\_lat is the latitude.\n* Width and height of the bounding box must be less than 25mi\n* Longitude is in the range of \u00b1180\n* Latitude is in the range of \u00b190\n* All coordinates are in decimal degrees.\n* Rule arguments are contained within brackets, space delimited.  \n**Note:** This operator will not match on Retweets, since Retweet's places are attached to the original Tweet. It will also not match on places attached to the original Tweet of a Quote Tweet.  \n**Example:** ********************bounding\\_box:\\[-105.301758 39.964069 -105.178505 40.09455\\]********************  \nprofile\\_country:  \nExact match on the \u201ccountryCode\u201d field from the \u201caddress\u201d object in the Profile Geo enrichment.  \nUses a normalized set of two-letter country codes, based on ISO-3166-1-alpha-2 specification. This operator is provided in lieu of an operator for \u201ccountry\u201d field from the \u201caddress\u201d object to be concise.  \nprofile\\_region:  \nMatches on the \u201cregion\u201d field from the \u201caddress\u201d object in the Profile Geo enrichment.  \nThis is an exact full string match. It is not necessary to escape characters with a backslash. For example, if matching something with a slash, use \u201cone/two\u201d, not \u201cone\\\\/two\u201d. Use double quotes to match substrings that contain whitespace or punctuation.  \nprofile\\_locality:  \nMatches on the \u201clocality\u201d field from the \u201caddress\u201d object in the Profile Geo enrichment.  \nThis is an exact full string match. It is not necessary to escape characters with a backslash. For example, if matching something with a slash, use \u201cone/two\u201d, not \u201cone\\\\/two\u201d. Use double quotes to match substrings that contain whitespace or punctuation.  \nprofile\\_subregion:  \nMatches on the \u201csubRegion\u201d field from the \u201caddress\u201d object in the [Profile Geo](https://developer.twitter.com/en/docs/twitter-api/enterprise/enrichments/overview/profile-geo) enrichment. In addition to targeting specific counties, these operators can be helpful to filter on a metro area without defining filters for every city and town within the region.  \nThis is an exact full string match. It is not necessary to escape characters with a backslash. For example, if matching something with a slash, use \u201cone/two\u201d, not \u201cone\\\\/two\u201d. Use double quotes to match substrings that contain whitespace or punctuation.  \nhas:geo  \nMatches Tweets that have Tweet-specific geolocation data provided from Twitter. This can be either \u201cgeo\u201d lat-long coordinate, or a \u201clocation\u201d in the form of a Twitter\u00a0[\u201cPlace\u201d](https://dev.twitter.com/overview/api/places), with the corresponding display name, geo polygon, and other fields.  \n**Note:**\u00a0Operators matching on\u00a0place\u00a0(Tweet geo) will only include matches from original tweets. Retweets do not contain any place data.  \nhas:profile\\_geo  \n_Available alias_: has:derived\\_user\\_geo  \nMatches Tweets that have any\u00a0[Profile Geo](https://developer.twitter.com/en/docs/twitter-api/enterprise/enrichments/overview/profile-geo)\u00a0metadata, regardless of the actual value.  \nhas:links  \nThis operator matches Tweets which contain links in the message body.is:retweet  \nDeliver only explicit retweets that match a rule. Can also be negated to exclude retweets that match a rule from delivery and only original content is delivered.  \nThis operator looks only for true Retweets, which use Twitter\u2019s Retweet functionality. Quoted Tweets and Modified Tweets which do not use Twitter\u2019s Retweet functionality will not be matched by this operator.  \nCan also be negated to match only on original Tweets.  \nis:quoteDelivers only Quote Tweets, or Tweets that reference another Tweet, as identified by the \"is\\_quote\\_status\":true in Tweet payloads. Can also be negated to exclude Quote Tweets.\nis:verified\nDeliver only Tweets where the author is \u201cverified\u201d by Twitter. Can also be negated to exclude Tweets where the author is verified.\nis:replyDeliver only replies that match a rule.\u00a0It can also be negated to exclude delivery of replies that match the specified rule.\u00a0This operator matches on replies in original Tweets, as well as replies in quoted Tweets and Retweets. You can use is:reply in conjunction with is:retweet and is:quote to only deliver replies to original Tweets.\n\\-is:nullcast  \nNegation only. Negates Tweets that are nullcasted (for example, contains the ********************\"scopes\": {\"followers\": false}\"********************\u00a0object). For more info on Nullcasted Tweets,\u00a0[see here](https://developer.twitter.com/en/docs/tweets/post-and-engage/guides/tweet-availability).  \nNote: Must be used at highest level of rule\u00a0when used with the Search API.\nExample: (gold AND silver) -is:nullcast  \nhas:mentions\nMatches Tweets that mention another Twitter user.\nhas:hashtags\nMatches Tweets that contain a hashtag.\nhas:media  \n_Available alias_: has:media\\_link  \nMatches Tweets that contain a media URL classified by Twitter. For example, pic.twitter.com.  \nhas:images\nMatches Tweets that contain a media URL classified by Twitter. For example, pic.twitter.com.\nhas:videos  \n_Available alias_: has:video\\_link  \nMatches Tweets that contain native Twitter videos, uploaded directly to Twitter. This will not match on videos created with Vine, Periscope, or Tweets with links to other video hosting sites.  \nhas:symbols\nMatches Tweets that contain a\u00a0cashtag\u00a0symbol (with a leading \u2018$\u2019 character. For example, $tag).  \nConnecting to a streaming endpoint\n",
        "line_start": 181,
        "line_end": 357,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "10": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\nContent: \n# Connecting to a streaming endpoint  \nEstablishing a connection to the streaming APIs means making a very long lived HTTP request, and parsing the response incrementally. Conceptually, you can think of it as downloading an infinitely long file over HTTP.\n",
        "line_start": 486,
        "line_end": 488,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "11": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tAuthentication\n\nContent: \n## Authentication  \nThe following authentication methods are supported by the Streaming APIs:  \n|     |     |     |\n| --- | --- | --- |\n| Auth Type | Supported APIs | Description |\n| [OAuth](https://developer.twitter.com/en/docs/basics/authentication/overview) | * Track API Stream | Requests must be authorized\u00a0[according to the OAuth specification](https://developer.twitter.com/content/developer-twitter/en/docs/authentication)\u00a0. |\n| [Basic auth](https://developer.twitter.com/en/docs/basics/authentication/overview/basic-auth.html) | * PowerTrack API<br>* Decahose stream | Requests must use of HTTP Basic Authentication, constructed from a valid email address and password combination. |\n",
        "line_start": 490,
        "line_end": 497,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "12": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tConnecting\n\nContent: \n## Connecting  \nTo connect to the Streaming API, form a HTTP request and consume the resulting stream for as long as is practical. Our servers will hold the connection open indefinitely, barring server-side error, excessive client-side lag, network hiccups, routine server maintenance or duplicate logins.  \nThe method to form an HTTP request and parse the response will be different for every language or framework, so consult the documentation for the HTTP library you are using.  \nSome HTTP client libraries only return the response body after the connection has been closed by the server. These clients will not work for accessing the Streaming API. You must use an HTTP client that will return response data incrementally. Most robust HTTP client libraries will provide this functionality. The\u00a0[Apache HttpClient](http://hc.apache.org/httpcomponents-client-ga/)\u00a0will handle this use case, for example.\n",
        "line_start": 500,
        "line_end": 504,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "13": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tDisconnections\n\nContent: \n## Disconnections  \nTwitter will close a streaming connection for the following reasons:  \n* A client establishes too many connections with the same credentials. When this occurs, the oldest connection will be terminated. This means you have to be careful not to run two reconnecting clients in parallel with the same credentials, or else they will take turns disconnecting each other.\n* A client stops reading data suddenly. If the rate of Tweets being read off of the stream drops suddenly, the connection will be closed.\n* A client reads data too slowly. Every streaming connection is backed by a queue of messages to be sent to the client. If this queue grows too large over time, the connection will be closed.\n* A streaming server is restarted. This is usually related to a code deploy and is not very frequent.\n* Twitter\u2019s network configuration changes. These events are rare, and would represent load balancer restarts or network reconfigurations, for example.\n",
        "line_start": 508,
        "line_end": 515,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "14": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tStalls\n\nContent: \n## Stalls  \nSet a timer, either a 90 second TCP level socket timeout, or a 90 second application level timer on the receipt of new data. If 90 seconds pass with no data received, including newlines, disconnect and reconnect immediately according to the backoff strategies in the next section. The Streaming API will send a keep-alive newline every 30 seconds to prevent your application from timing out the connection. You should wait at least 3 cycles to prevent spurious reconnects in the event of network congestion, local CPU starvation, local GC pauses, etc.\n",
        "line_start": 518,
        "line_end": 520,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "15": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tReconnecting\n\nContent: \n## Reconnecting  \nOnce an\u00a0**established**\u00a0connection drops, attempt to reconnect immediately. If the reconnect fails, slow down your reconnect attempts according to the type of error experienced:  \n* Back off linearly for\u00a0**TCP/IP level network errors**. These problems are generally temporary and tend to clear quickly. Increase the delay in reconnects by 250ms each attempt, up to 16 seconds.\n* Back off exponentially for\u00a0**HTTP errors**\u00a0for which reconnecting would be appropriate. Start with a 5 second wait, doubling each attempt, up to 320 seconds.\n* Back off exponentially for\u00a0**HTTP 420 errors**. Start with a 1 minute wait and double each attempt. Note that every HTTP 420 received increases the time you must wait until rate limiting will no longer will be in effect for your account.\n",
        "line_start": 522,
        "line_end": 527,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "16": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tConnection churn\n\nContent: \n## Connection churn  \nRepeatedly opening and closing a connection (churn) wastes server resources. Keep your connections as stable and long-lived as possible.  \nAvoid mobile (cellular network) connections from mobile devices. WiFi is generally OK.  \nDelay opening a streaming connection in cases where the user may quit the application quickly.  \nIf your client works in an environment where the connection quality changes over time, attempt to detect flaky connections. When detected, fall back to REST polling until the connection quality improves.\n",
        "line_start": 530,
        "line_end": 535,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "17": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tRate limiting\n\nContent: \n## Rate limiting  \nClients which do not implement backoff and attempt to reconnect as often as possible will have their connections rate limited for a small number of minutes. Rate limited clients will receive HTTP 420 responses for all connection requests.  \nClients which break a connection and then reconnect frequently (to change query parameters, for example) run the risk of being rate limited.  \nTwitter does not make public the number of connection attempts which will cause a rate limiting to occur, but there is some tolerance for testing and development. A few dozen connection attempts from time to time will not trigger a limit. However, it is essential to stop further connection attempts for a few minutes if a HTTP 420 response is received. If your client is rate limited frequently, it is possible that your IP will be blocked from accessing Twitter for an indeterminate period of time.\n",
        "line_start": 540,
        "line_end": 544,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "18": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tBest practices\n\tTest backoff strategies\n\nContent: \n## Best practices  \n### Test backoff strategies  \nA good way to test a backoff implementation is to use invalid authorization credentials and examine the reconnect attempts. A good implementation will not get any 420 responses.\n",
        "line_start": 548,
        "line_end": 551,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "19": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tBest practices\n\tIssue alerts for multiple reconnects\n\nContent: \n### Issue alerts for multiple reconnects  \nIf a client reaches its upper threshold of its time between reconnects, it should send you notifications so you can triage the issues affecting your connection.\n",
        "line_start": 554,
        "line_end": 556,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "20": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tBest practices\n\tHandle DNS changes\n\nContent: \n### Handle DNS changes  \nTest that your client process honors the DNS Time To live (TTL). Some stacks will cache a resolved address for the duration of the process and will not pick up DNS changes within the proscribed TTL. Such aggressive caching will lead to service disruptions on your client as Twitter shifts load between IP addresses.\n",
        "line_start": 558,
        "line_end": 560,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "21": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tBest practices\n\tUser Agent\n\nContent: \n### User Agent  \nEnsure your\u00a0user-agent\u00a0HTTP header includes the client\u2019s version. This will be critical in diagnosing issues on Twitter\u2019s end. If your environment precludes setting the\u00a0user-agent\u00a0field, then set an\u00a0x-user-agent\u00a0header.\n",
        "line_start": 562,
        "line_end": 564,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "22": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tHTTP Error Codes\n\nContent: \n## HTTP Error Codes  \nMost error codes are returned with a string with additional details. For all codes greater than 200, clients should wait before attempting another connection. See the Connecting section, above.  \n|     |     |     |\n| --- | --- | --- |\n| Status | Text | Description |\n| **200** | **Success** | Self evident. |\n| **401** | **Unauthorized** | HTTP authentication failed due to either:<br><br>* Invalid basic auth credentials, or an invalid OAuth request.<br>* Out-of-sync timestamp in your OAuth request (the response body will indicate this).<br>* Too many incorrect passwords entered or other login rate limiting. |\n| **403** | **Forbidden** | The connecting account is not permitted to access this endpoint. |\n| **404** | **Unknown** | There is nothing at this URL, which means the resource does not exist. |\n| **406** | **Not Acceptable** | At least one request parameter is invalid. For example, the filter endpoint returns this status if:<br><br>* The track keyword is too long or too short.<br>* An invalid bounding box is specified.<br>* Neither the track nor follow parameter are specified.<br>* The follow user ID is not valid. |\n| **413** | **Too Long** | A parameter list is too long. For example, the filter endpoint returns this status if:<br><br>* More track values are sent than the user is allowed to use.<br>* More bounding boxes are sent than the user is allowed to use.<br>* More follow user IDs are sent than the user is allowed to follow. |\n| **416** | **Range Unacceptable** | For example, an endpoint returns this status if:<br><br>* A count parameter is specified but the user does not have access to use the count parameter.<br>* A count parameter is specified which is outside of the maximum/minimum allowable values. |\n| **420** | **Rate Limited** | The client has connected too frequently. For example, an endpoint returns this status if:<br><br>* A client makes too many login attempts in a short period of time.<br>* Too many copies of an application attempt to authenticate with the same credentials. |\n| **503** | **Service Unavailable** | A streaming server is temporarily overloaded. Attempt to make another connection, keeping in mind the connection attempt rate limiting and possible DNS caching in your client. |  \nRule limits\n",
        "line_start": 566,
        "line_end": 581,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "23": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tRule limits\n\nContent: \n## Rule limits  \nTwitter will now begin to enforce long-held contractual limits for the number of rules that a customer is able to add to their stream by enforcing rule limits on PowerTrack. While these limits have always been observed, we are now making it easier for customers to know where their limits stand and how close they are to their cap. Functionality has been added to our console that will allow you to observe your current rule count for each product and stream. This information can be found on the right hand side of a product page just under the activity counter (see below).  \nThis can also be found under the rules section of the usage tab (see below).\n",
        "line_start": 585,
        "line_end": 588,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "24": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tWhat If I Hit My Cap?\n\nContent: \n## What If I Hit My Cap?  \nIf you attempt to upload more rules to your stream that you are contractually allowed, you will receive the following message:  \n_\u201cRequest exceeds account\u2019s Rule Limit. Delete rules or contact your account manager to proceed.\u201d_  \nIf you encounter this error message while you have an open connection, your stream will not be disrupted. In order to add more rules once you hit your cap, you will either need to delete rules from your stream or reach out to your account manager to increase your contractual limit.  \nRecovery and redundancy features\n",
        "line_start": 596,
        "line_end": 601,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "25": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tIntroduction\n\nContent: \n## Introduction  \nWith streaming high volumes of realtime Tweets comes a set of best practices that promote both data reliability and data full-fidelity. When consuming realtime data, maximizing your connection time is a fundamental goal. When disconnects occur, it is important to automatically detect that and reconnect. After reconnecting it\u2019s important to assess if there are any periods to backfill data for. The component that manages these details and consumes realtime Tweets is only one part of a system with network, datastore, server, and storage concerns. Given the complexity of these systems, another best practice is to have different streaming environments, with at least separate streams for development/testing and production.  \nPowerTrack comes with a set of features that help with these efforts.  \nTo support multiple environments, we can deploy\u00a0[Additional Streams](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/powertrack_recovery_and_redundancy_features#additional_streams)\u00a0for your account. These streams are completely independent of each other, having unique URLs and separate rule sets.  \nTo help support maintaining a connection, each realtime PowerTrack stream supports\u00a0[Redundant Connections](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/powertrack_recovery_and_redundancy_features#redundant_connections). The most common architecture is for a stream to have two connections, and on the client-side there are two independent consumers, ideally on different networks. With this design, there can be redundancy across the client-side networks, servers, and datastore pathways. Note that a full-copy of the data is served on each connection (since there is a single \u2018source\u2019 server and no partitioning with filtered streams) and the client-side must be tolerant of and manage these duplicate data.  \nFor detecting disconnects, each stream has a \u2018heartbeat\u2019 signal that can used to detect when a stream has timed-out. These 10-second heartbeats provide connection confirmation even when there are time periods with no Tweets matching your rules and being delivered on your stream. For most Twitter stream consumers, the data volumes are high enough that even a smaller duration of no Tweets is a sign of a connection issue. So both a \u2018data silence\u2019 and lack of a heartbeat can be used to detect a disconnect.  \nSince disconnects will happen, PowerTrack has a dedicated\u00a0[Recovery](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/powertrack_recovery_and_redundancy_features#replay)\u00a0and a PowerTrack\u00a0[Backfill](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/powertrack_recovery_and_redundancy_features#backfill)\u00a0feature to help recover data that was missed due to disconnections and other operational issues. To learn more about disconnects see our support article\u00a0[HERE](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/disconnections-explained).\n",
        "line_start": 606,
        "line_end": 613,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "26": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tAdditional streams\n\nContent: \n## Additional streams  \nHaving additional PowerTrack streams is another way to help build reliability into your solution. So much so that it is considered a best practice. Any additional streams are completely independent, having their unique endpoint and independent rule set. Each stream is assigned its own \u2018label\u2019, and this label, along with your account name, are part of that stream\u2019s URL.  \nhttps://gnip-stream.twitter.com/stream/powertrack/accounts/{ACCOUNT\\_NAME}/publishers/twitter/{STREAM\\_LABEL}.json  \nThe most common convention is to have a realtime stream dedicated for your production system, and an additional stream available for development and testing. Having a test/development stream enables PowerTrack customers to have a stream to test client consumer updates. While any (unique) label can be assigned to a stream, one convention is to use \u2018prod\u2019 for production stream, and \u2018dev\u2019 or \u2018sandbox\u2019 for an additional development stream.  \nThe number of streams, and their unique labels, is configurable by your account representative.\n",
        "line_start": null,
        "line_end": null,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "27": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tRedundant connections\n\nContent: \n## Redundant connections  \nA redundant connection simply allows you to establish more than 1 simultaneous connections to the data stream. This provides redundancy by allowing you to connect to the same stream with two separate consumers, receiving the same data through both connections. Thus, your app has a hot failover for various situations, e.g. where one stream is disconnected or where your app\u2019s primary server fails.  \nThe number of connections allowed for any given stream is configurable by your account representative. To use a redundant stream, simply connect to the same URL used for your primary connection. The data for your stream will be sent through both connections, with both stream connections represented on the stream dashboard.  \nNote that for billing purposes, we deduplicate the activity counts you receive through multiple connections such that you are only billed for each unique activity once.\n",
        "line_start": null,
        "line_end": null,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "28": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tRecovery\n\nContent: \n## Recovery  \n#### Overview  \nRecovery is a data tool that provides streaming access to a rolling window of recent Twitter historical data. It should be utilized to recover data in scenarios where your consuming application misses data in the real time stream, whether due to disconnecting for a short period, or for any other scenario where you fail to ingest realtime data for a period of time.  \nThere are different varieties of Recovery streams, corresponding to different types of realtime streams that they complement. PowerTrack Recovery streams are provided to allow customers using realtime PowerTrack to recover data they miss, using the same rules as they use in realtime.  \n#### Using\u00a0Recovery  \nWith the Recovery stream, your app can make requests to it that operate in the same manner as requests to existing realtime streams. However, your app must specify parameters in the URL that indicate the time window you are requesting. In other words, a Recovery request asks for \u201cPosts from time A to time B.\u201d These Posts are then delivered through your streaming connection in a manner that mimics the realtime stream.  \nPosts are delivered beginning with the first minute of the specified time period, continuing until the final minute is delivered. At that point, a \u201cRecovery Request Completed\u201d message is sent through the connection, and the connection is then closed by Gnip. If your request begins at a time of day where little or no matching results occurred, there will likely be some period of time before the first results are delivered \u2013 data will be delivered when Recovery encounters matches in the portion of the archive being processed at that time. When no results are available to deliver, the stream will continue sending carriage-return \u201cheartbeats\u201d through the connection to prevent you from timing out.  \nRecovery is intended as a tool for easily recovering data missed due to short disconnects, not for very long time periods like entire days. If the need to recover data for long periods arises, we recommend breaking longer requests into shorter time windows (e.g. two hours) to reduce the possibility of being disconnected mid-request due to internet volatility or other reasons, and to provide more visibility into the progress of long requests.  \n#### Data availability  \nYou can use the Recovery feature to recover missed data within the last 24 hours if you are unable to reconnect with the 5 minute backfill window.  \nThe streaming recovery feature allows you to have an extended backfill window of 24 hours. Recovery enables you to \u2018recover\u2019 the time period of missed data. A recovery stream is started when you make a connection request using 'startTime' and 'endTime' request parameters. Once connected, Recovery will re-stream the time period indicated, then disconnect.  \nYou will be able to make 2 concurrent requests to recovery at the same time, i.e. \u201ctwo recovery jobs\u201d. Recovery works technically in the same way as backfill, except a start and end time is defined. A recovery period is for a single time range.  \n| Name | Type | Description |\n| --- | --- | --- |\n| startTime | date (ISO 8601) | YYYY-MM-DDTHH:mm:ssZ (ISO 8601/RFC 3339).<br><br>Date in UTC signifying the start time to recover from. |\n| endTime | date (ISO 8601) | YYYY-MM-DDTHH:mm:ssZ (ISO 8601/RFC 3339).<br><br>Date in UTC signifying the end time to recover to. |  \n[](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/api-reference/replay-stream)\n",
        "line_start": null,
        "line_end": null,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "29": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tBackfill\n\nContent: \n## Backfill  \nThe Backfill feature is used to request up to 5 minutes of stream data that is missed after a disconnect, and is available on PowerTrack and Volume streams as an\u00a0_optional_\u00a0feature.  \nTo request backfill, you need to add a \u2018backfillMinutes=number\u2019 parameter to your connection request, where \u2018number\u2019 is the number of minutes (1-5, whole numbers only) to backfill when the connection is made. For example, if you disconnect for 90 seconds, you should add \u2018backfillMinutes=2\u2019 to your connection request. Since this request will provide backfill for 2 minutes, including for the 30-second period before you disconnected, your\u00a0_consumer app must be tolerant of duplicate data_.  \nAn example PowerTrack connection request URL, requesting a 5 minute backfill, looks like:  \nhttps://gnip-stream.twitter.com/stream/powertrack/accounts/{ACCOUNT\\_NAME}/publishers/twitter/{STREAM\\_LABEL}.json?backfillMinutes=5  \n**NOTES:**  \n* You do have the option to always use \u2018backfillMinutes=5\u2019 when you connect, then handling any duplicate data that is provided.  \n* If you are disconnected for more than five minutes, you can recover data using the\u00a0Recovery.\n",
        "line_start": null,
        "line_end": null,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "30": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tRecovering from disconnect\n\nContent: \n## Recovering from disconnect  \nRestarting and recovering from a disconnect involves several steps:  \n* Determining length of disconnect time period.\n* 5 minutes or less?\n* If you have Backfill enabled for stream, prepare connection request with appropriate \u2018backfillMinutes\u2019 parameter.\n* More than 5 minutes?\n* Make a connection request using 'startTime' and 'endTime' request parameters in order to start a recovery stream. The streaming recovery feature allows you to have an extended backfill window of 24 hours. Recovery enables you to 'replay' the time period of missed data.\n* Request a new connection.  \nPlanning for high-volume social data events\n",
        "line_start": null,
        "line_end": null,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "31": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tPlanning for high-volume social data events\n\nContent: \n## Planning for high-volume social data events  \nMajor national and global events are often accompanied by dramatic spikes in user activity across social media platforms. Sometimes these events are known about in advance, like the Super Bowl, political elections, and New Year\u2019s celebrations around the world. Other times, the spikes in volume are due to unexpected happenings such as natural disasters, unplanned political events, or surprise pop culture moments like Ellen\u2019s famous selfie Tweet at the Oscars.  \nThese bursts of user activity can be short-lived (measured in seconds) or they may be sustained over several minutes\u2019 time. No matter their origin, it is important to consider the impact that they can have on applications consuming realtime data from Twitter.  \nHere are some best practices that will help your team prepare for high-volume social data events.  \n#### Review your current PowerTrack rules  \n* Certain keywords can skyrocket during high volume events, for instance brand mentions when a brand sponsors a major sporting event.\n* Be careful to avoid any unnecessary or overly generic PowerTrack rules that may generate unnecessary activity volumes.\n* Consider communicating with your clients prior to known high-volume events to help them plan appropriately.  \n#### Stress test your application  \nAnticipate that burst volumes may reach 5-10x average daily consumption levels. Depending on your PowerTrack rule set, the increase may be much higher.  \n#### Optimize to stay connected  \nWith realtime streams, staying connected is essential to avoid missing data. Your client application should be able to detect a disconnect and have logic to immediately retry its connection, using an\u00a0exponential backoff\u00a0if the reconnect attempt fails.  \n#### Add built-in buffering on your end  \nBuilding a multi-threaded application is a key strategy for handling high-volume streams. At a high-level, a best practice for managing data streams is to have a separate thread/process that establishes the streaming connection and then writes received JSON activities to a memory structure or a buffered stream reader. This \u2018light-weight\u2019 stream processing thread is responsible for handling incoming data, which can be buffered in memory, growing and shrinking as needed. Then a different thread consumes that hash and does the \u2018heavy lifting\u2019 of parsing the JSON, preparing database writes, or whatever else your application needs to do.  \n#### Optional streaming data recovery tools  \n* [PowerTrack Replay](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/powertrack_recovery_and_redundancy_features#replay)\u00a0is available to recover missed activities should you experience an extended disconnection.\n* [PowerTrack Backfill](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/powertrack_recovery_and_redundancy_features)\u00a0automates data recovery if you disconnect briefly. If you disconnect and reconnect within 5 minutes, your data will be buffered by Gnip and delivered automatically.\n* If you are unsure whether your Gnip package includes these recovery features, be sure to contact your Account Manager to learn more.  \n#### Global events = global time zones  \n* The events may occur after business hours or over the weekend, so be sure that your team is prepared for spikes to occur outside your normal business hours.  \n#### Don\u2019t Panic!  \n* As always, we recommend that you maintain your connections to Twitter real-time APIs and monitor for any changes in delivery latency.\n* Twitter\u2019s highly-scalable infrastructure ensures that none of your data will be lost or missed from any temporary increases in this latency.  \nDisconnections explained\n",
        "line_start": 703,
        "line_end": 727,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "32": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tDisconnections explained\n\nContent: \n## Disconnections explained  \nDisconnects from your PowerTrack stream can happen for a handful of reasons - whether they proactively planned or unplanned. Regardless of whether or not they were planned, any sort of disconnect can be surprising cause for data loss, but they don\u2019t have to be. A basic understanding of the types of disconnects that you might encounter and how to quickly reconnect can mean the difference between a major issue and something that can be incorporated into your application design by reconnecting, or using\u00a0Backfill\u00a0or\u00a0[Recovery](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/powertrack_recovery_and_redundancy_features#replay).\u00a0Please note that for any disconnect, forced or client-side, your\u00a0[console.gnip.com dashboard](https://console.gnip.com/)\u00a0will have a message that displays the kind of disconnect that you experienced and a timestamp for the disconnect.  \nThis article will go over the types of disconnects you might encounter, how to minimize their effects, and how to troubleshoot issues related to disconnects.\n",
        "line_start": 746,
        "line_end": 749,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "33": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tDisconnections explained\n\tForced disconnects\n\nContent: \n### Forced disconnects  \nAt the highest level, forced disconnects happen when Twitter actively closes your connection to the stream. These can happen for a variety of reasons, and when you are force disconnected from your stream then Twitter will send a zero byte chunk in accordance with\u00a0[HTTP chunked encoding practice](http://www.httpwatch.com/httpgallery/chunked/). In all cases of forced disconnects, you should be able to reconnect to the stream immediately and you should be sure to have\u00a0[reconnect logic](https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data#reconnecting)\u00a0written into your code to prevent further data loss.  \nThere are three types of forced disconnects that your app will need to be prepared for.  \n#### **Twitter maintenance**  \nTwitter deploys for ongoing maintenance several times a week. During these updates, sometimes customer streams will experience one or more disconnects. This will be accompanied by a \u201cTwitter is closing for operational reasons\u201d message. These should be expected disconnections, and your application should be able to reconnect immediately, so make sure that you have\u00a0[reconnect logic](https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data#reconnecting)\u00a0written into your application.  \n#### **Full buffer disconnect**  \nA full buffer disconnect generally indicates that your application\u2019s code isn\u2019t keeping up with the amount of data that we\u2019re streaming to you and there is a backup of cached data on the Twitter server side for your connection which needs to be flushed. This can happen after a major rule change, a\u00a0[big event](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/high-volume-social-data-events), or simply because your application is having trouble\u00a0[consuming the stream](https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data). Full buffer disconnects are triggered when your stream connection buffer hits a certain threshold of Tweets. If you are disconnected for a full buffer, reconnecting with [backfill](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/powertrack_recovery_and_redundancy_features.html#backfill) is not available and data will begin streaming from the time you reconnect. It's likely that you will need to run a [Recovery](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/powertrack_recovery_and_redundancy_features#replay)\u00a0to recover Tweets lost in the disconnection. If you find that full buffer disconnects are happening frequently, reach out to the support team to assist you in making sure that your application is properly configured.  \nHere are some\u00a0suggestions to prevent these kinds of disconnects from occurring in the future:  \n1. Ensure nothing is slowing down the process reading from the stream. Do not do any processing in the process/thread that is reading from the stream. Instead, have this process read the message then pass off any processing (such as parsing, date calculations, etc) of the message to a separate process or thread.\n2. Verify there are no network issues between your application and Twitter preventing messages from being sent.\n3. Make sure you have sufficient bandwidth for the volume of activities on your stream.\u00a0 Some streams can have high volumes requiring significant bandwidth (~10 Mbps is not unheard of). Keep in mind these streams require this bandwidth to be sustained 24 hours a day, including spikes that may cause 2-3 times the volume during significant world events. These spikes are often absorbed by Twitter's buffer, and are one of the reasons it is in place.  \n#### **Too many connections**  \nEach stream is configured to allow for a specified number of connections. This number is determined between you and your account manager, and is available in your account agreement. If you connect to your stream with more connections than are allowed, you will be force disconnected. Any extra connections are allowed for approximately one minute. If after one minute an extra connection exists, the most recent connection is forced disconnected. Allowing an extra connection for a minute enables the customer to, for example, spin up a new server and connect with it, then teardown a server that is being \u2018retired.\u2019\n",
        "line_start": 753,
        "line_end": 766,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "34": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tDisconnections explained\n\tClient disconnects\n\nContent: \n### Client disconnects  \nA client disconnect is essentially any disconnection that occurs which isn\u2019t initiated by our servers. There are many causes for this. Sometimes this could be caused by the code or the architecture of your application, but this often occurs when something in the internet or network layer cuts off the connection. This section provides a list of the most common causes for a client disconnects.  \n**Issues at the network layer**  \nRouting issues at the networking level can cause disconnects. For example, a Border Gateway Protocol (BGP) update can go awry, and clients can disconnect as routers fail to keep up with the sudden additional load put on them when a route fails. As network operators cooperate to reroute traffic, you may notice a pattern of disconnects for some time.  \n**Firewall configuration**  \nClients may have firewalls set up with session limits that cut off the connections after a certain amount of time, which they need to create exceptions for. From our side, our servers just see the connection close, so we don\u2019t have a way to see whether it was closed by the proactive actions of your app, or just something related to the internet connection between your client and the Twitter servers.  \n**Data burst and packet loss**  \nClients should be designed to handle spikes in the volume of Tweets received. If a client is slow to consume a stream, it will receive a [full buffer disconnect](#full_buffer_disconnect). However, there are situations where the client is not able to handle a sudden surge in volume (for example, after significant rule activity) which will cause the client to drop packets. When this happens, you may notice the client resetting a TCP/IP connection. In certain cases, the connection is terminated correctly and cleanly; however, there may be situations where the underlying networking layer doesn't close the socket properly, or does so after a set delay. In your dashboard, this event will be reported as a client disconnect. In such cases, clients must be sized to handle multiple times the average Tweet volume. It can be beneficial to examine the network traffic to detect any pattern that leads the client to drop packets.  \n**Failure to reconnect after a disconnection**  \nOccasionally, some customers have trouble reconnecting to their stream after they\u2019ve terminated a connection. Assuming there are no operational issues posted on our [Status Page](https://api.twitterstat.us/), one reason might be that something within your code is keeping the connection alive. In these scenarios, we see something in the layer outside of your app persisting, because the connection wasn\u2019t properly terminated. Generally we see similar behavior when the HTTP client portion of the code isn\u2019t getting proactively closed. It might also be that there is simply some network latency or delay set at the configuration level preventing the request from going through.  \nFAQ\n",
        "line_start": 781,
        "line_end": 792,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "35": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tFrequently asked questions\n\tRealtime PowerTrack API\n\nContent: \n### Realtime PowerTrack API  \n**I am interested in Twitter data and would like to find out approximate subscription costs.**  \nPlease fill out [this form](https://developer.twitter.com/en/enterprise-application) to get in touch with our Sales team.  \n**What are some of the features provided by realtime PowerTrack?**  \nBy connecting directly to our data services, you can take advantage of many enterprise-ready features that provide reliable connectivity and full-fidelity data. As an enterprise licensed-access offering, realtime PowerTrack includes tools for dynamic filtering, consistent connection, data recovery and data compliance management. This technology, paired with operational monitoring, guaranteed support and integration services allows businesses to start with a strong foundation to serve their own customers.  \nThese features include:  \n* Dynamic rule updates while connected to the stream. There is no need to disconnect your stream while you update your stream\u2019s ruleset.\n* Support for multiple connections to each stream.\n* Ability to automatically recover data that is missed during brief disconnects when you reconnect within 5 minutes with Backfill.\n* Availability of Recovery feature to recover missed data within the last 24 hours if you are unable to reconnect with the 5 minute backfill window.\n* Availability of additional streams for testing and development.\n* Status dashboard to communicate with customers about any operational issues.  \n**How do I consume streaming data?**  \nRealtime streams of data are initiated by sending a HTTP GET command to your custom `https://gnip-stream.twitter.com` URL. HTTP streaming connections are requested with HTTP headers that indicate a \u2018keep-alive\u2019 connection. More information on realtime streaming is available [here](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/overview).  \nGiven the potential of high volumes of Twitter data delivered in a stream, it is highly recommended that incoming data is processed in an asynchronous fashion. What this means is that your code that \u2018hosts\u2019 the client side of the stream simply inserts incoming Tweets into a (FIFO) queue, or similar memory structure, and then you have a separate process/thread that consumes Tweets from that queue and does more of the \u2018heavy lifting\u2019 of parsing and preparing the data for storage. With this design, you can implement a process that will bend but not break in case incoming data volumes change dramatically.  \n**How can multiple customers, projects, and campaigns be managed in a single stream?**  \nThe vast majority of realtime PowerTrack users manage multiple customers, projects, and campaigns within a single realtime stream by using [PowerTrack rule \u2018tags\u2019](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/overview). Rule tags have no special meaning, they are simply treated as opaque strings carried along with the rule. They will be included in the \u201cmatching rules\u201d metadata in activities returned.  \nTags provide an easy way to create logical groupings of PowerTrack rules. For example, you may generate a unique ID for a specific rule as its tag and allow your application to reference that ID within activities it processes to associate a result with specific customers, campaigns, categories, or other related groups.  \n**How many connections to a given PowerTrack stream can I have at one time?**  \nPowerTrack streams support multiple connections to a single endpoint. Having multiple connections enables customers to build redundant data consumer clients, ideally on different networks. While PowerTrack streams default to a single connection, many customers prefer to have two connections per PowerTrack stream to ensure continuous delivery. If multiple connections are made to a single endpoint, and/or multiple streams exist with common rules, a given Tweet will be received multiple times. Note that for accounting purposes, the Tweet will be counted once.  \nPlease talk to your Account Manager for more information.  \n**How 'realtime' are the results? Is there any delay/elaboration time between the publication of a Tweet on Twitter and their release on the PowerTrack stream?**  \nTweets that match your ruleset will be delivered to your stream within seconds of being published on the platform. There are variables, such as network connectivity and how your consuming application reads data off the stream; but all things being equal, you should receive Tweets within seconds of them being published.  \nPlease note that the URL enrichment does cause an increased latency, due to the unwinding of each URL in the Tweet.  \nGenerally speaking, you should expect Volume streams (e.g. Firehose and [Decahose](https://developer.twitter.com/en/docs/twitter-api/enterprise/decahose-api/overview)) to be faster than [PowerTrack](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/overview), and PowerTrack to be fast than [statuses/filter](https://developer.twitter.com/en/docs/tweets/filter-realtime/api-reference/post-statuses-filter).  \n**Is it possible to update several rules in one go?**  \nYes, you can add or delete several rules with one request.  \nHowever, note that the add and delete steps are separate and you will need two requests: one request to add one or several rule(s) and another request to delete one or several rule(s).  \nThe upper limit number of rules that can either be added or be deleted in one go is a JSON body that is 5MB or less in size. Depending on the length of your rule values and tags, the upper number will be in the lower thousands.  \n**Why isn't my rule appearing on the stream right away?**  \nMost rule additions take effect almost immediately. However, depending on factors such as network connectivity and rule size/complexity, it may take up to 5 minutes before you start receiving matching Tweets.  \n**What if some Tweets are missing: I was expecting them to be returned by the stream, but they weren't?**  \nYou can follow the next few steps to understand why some Tweets might not have been delivered:  \n1. Check your [rule](https://developer.twitter.com/en/docs/twitter-api/enterprise/rules-and-filtering/enterprise-operators) and ensure that you are using the correct operators.\n2. Were you connected to the stream when the Tweet was created? You can use the 'Connections' tab in the [console](https://console.gnip.com/) to check your connection history.\n3. Was your rule already in place when the Tweet was created?\n4. Note that if the account from which the Tweet was sent was private at the time the Tweet was created, the Tweet won't be returned - even if the account is public at the time of the request.  \n**If I lose the connection to the stream and then connect back, will I lose all Tweets from that duration?**  \nYes, if you lose the connection to the stream, you may be missing data for the period of time that you were disconnected from the stream. Whenever a disconnection occurs, your client app must restart the process by establishing a new connection.  \nAdditionally, to ensure that you do not miss any data, you may need to utilize a [Redundant Connection](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/powertrack_recovery_and_redundancy_features#redundant_connections), [Backfill](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/powertrack_recovery_and_redundancy_features#backfill), or a [Replay stream](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/api-reference/replay-stream) to mitigate or recover data from disconnections from the stream. Please see our answer to the next question for more information.  \n**What if I get disconnected from the stream? How can I collect any data that was missed while disconnected?**  \nWhen streaming data, the goal is to stay connected for as long as possible, recognizing that disconnects will occur. PowerTrack streams provide a 15-second heartbeat (in the form of a new-line character) that enable client applications to detect disconnects. When fresh data and the heartbeat stop arriving, reconnection logic should be triggered. In most software languages this can be easily implemented by setting a data read timeout.  \nAny time you disconnect from the stream, you are potentially missing data that would have been sent if connected. However, there are multiple ways to mitigate these disconnects and recover data when they occur.  \nThere is a range of tools available for retrieving historical tweets, including:  \n1. [Redundant Streams](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/powertrack_recovery_and_redundancy_features#redundant_connections) - With multiple connections, consume the stream from multiple servers to prevent missed data when one is disconnected.\n2. [Recovery](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/api-reference/replay-stream)\u00a0- Recover data within the last 24 hours.\n3. [Backfill](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/powertrack_recovery_and_redundancy_features#backfill) - Reconnect within 5 minutes and start from where you left off.\n4. [Full Archive Search](https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-full-archive) - Recover data from the entire Twitter archive.  \nPlease also refer to [our documentation on disconnects](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/disconnections-explained).  \n**How fast is the streaming speed of Recovery?**  \nRecovery will deliver up to 1000 posts per second. It is intended to deliver the posts for the period of time that a customer is disconnected.  \n**Do you have any realtime PowerTrack code examples I can use to get started with?**  \nYes, we have several realtime code examples available, including:  \n* [Sample Python scripts](https://github.com/twitterdev/python-enterprise-scripts/blob/master/python_stream_sample.py)\n* [Sample Ruby scripts](https://github.com/twitterdev/ruby-enterprise-scripts/tree/master/PowerTrack)  \nNote that these are only available to enterprise customers.  \n**How do Edit Tweets impact my usage and billing?**  \nOnly the original Tweet will count for billing purposes. Any subsequent edits will be ignored and not contribute to your overall activity count.\n",
        "line_start": 811,
        "line_end": 869,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "36": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tConnecting to a streaming endpoint\n\tFrequently asked questions\n\t\n\nContent: \n###\nError troubleshooting guide  \n**Code 429 - Rate Limited: Your app has exceeded the limit on requests to add, delete, or list rules for this stream**  \nYou may be receiving the 429 error code because you are adding or deleting rules too quickly. If you are adding or deleting rules individually, this could add up and exceed the rate limit.  \nA workaround could be to add or delete several rules at one time.  \nFor example, the below sample cURL command shows you how to delete several rules at once:  \ncurl -v -X POST -uexample@customer.com \"https://gnip-api.twitter.com/rules/powertrack/accounts/:account_name/publishers/twitter/:stream_label.json?_method=delete\" -d '{\"rule_ids\":[734938587381145604,734938587381174273]}\"  \nYou can learn more about adding or deleting rules and the relevant rate limits [here](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/api-reference/powertrack-rules).  \n**Code 400**  \nA 400 error code normally indicates that the server was unable to process the request sent by the client due to poorly formatted JSON.  \nThere are many reasons why this might be the case and you will need to double check the format of your JSON query.  \nFor example, you may need to escape the quotes around the exact phrase match(es) in your rule (as in the example below):  \n{\"rules\":\\[{\"tag\":\"test1\",\"value\":\"coffee OR \\\\\"I love coffee\\\\\"\"}\\]}  \n**\nFrequent Disconnects - I am experiencing frequent disconnections on the stream and one of the following messages is being returned. Why is this happening?**  \n`This stream has been disconnected because your client was unable to keep up with us.`  \n`This stream has been disconnected for operational reasons.`  \nThis kind of error occurs when your stream is not keeping up with the speed at which we are delivering data and your app isn't consuming the data from the stream fast enough.  \nWe allow delivery to get behind for a period of time, and we have a temporary staging buffer amount for each stream on our side; but if you don't catch up, we initiate a disconnect to allow you to reconnect at the current point in time. Please note that this may lead to data loss (for data that is within the buffer at the time of the full buffer disconnect).  \nThese can occur around large spikes in data. Generally, we recommend using a buffer process for consuming data quickly that is separate from the processing process.  \nYou can find out more about optimizing your app to prevent disconnects like this in our articles on\u00a0[connection](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/disconnections-explained) and on consuming streaming data [here](https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data) and [here](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/guides/high-volume-social-data-events).  \nPowerTrack API  \npowertrack-stream\n",
        "line_start": 927,
        "line_end": 950,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "37": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack API\n\nContent: \n# PowerTrack API  \nJump to on this page  \n[Methods](#Methods)  \n[Authentication](#Authentication)  \n[GET /track/:stream](#Stream)\n",
        "line_start": 973,
        "line_end": 978,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "38": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack API\n\tMethods\u00a0[\u00b6](#methods- \"Permalink to this headline\")\n\nContent: \n## Methods\u00a0[\u00b6](#methods- \"Permalink to this headline\")  \n| Method | Description |\n| --- | --- |\n| [GET /track/:stream](#Stream) | Connect to the data stream |\n",
        "line_start": 983,
        "line_end": 987,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "39": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack API\n\tAuthentication\u00a0[\u00b6](#authentication- \"Permalink to this headline\")\n\nContent: \n## Authentication\u00a0[\u00b6](#authentication- \"Permalink to this headline\")  \nAll requests to the PowerTrack API must use HTTP Basic Authentication, constructed from a valid email address and password combination used to log into your account at console.gnip.com. Credentials must be passed as the Authorization header for each request. Make sure your client is adding the \"Authentication: Basic\" HTTP header (with encoded credentials over HTTPS) to all API requests.\n",
        "line_start": 989,
        "line_end": 991,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "40": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack API\n\tGET /track/:stream\u00a0[\u00b6](#get-track-stream- \"Permalink to this headline\")\n\nContent: \n## GET /track/:stream\u00a0[\u00b6](#get-track-stream- \"Permalink to this headline\")  \nEstablishes a persistent connection to the PowerTrack data stream, through which the social data will be delivered.  \n**IMPORTANT:** After you establish the connection [see here](https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data) for details on consuming streaming data.  \n|     |     |\n| --- | --- |\n| **Request Method** | HTTP GET |\n| **Connection Type** | Keep-Alive  <br>  <br>This should be specified in the header of the request. |\n| **URL** | Found on the stream's API Help page of your console dashboard, and resembles the following structure:  <br>  <br><br>[https://gnip-stream.twitter.com/stream/powertrack/accounts/](https://gnip-stream.twitter.com/stream/powertrack/accounts/){gnip\\_account\\_name}/publishers/twitter/{stream\\_label}.json |\n| **Compression** | Gzip. To connect to the stream using Gzip compression, simply send an Accept-Encoding header in the connection request. The header should look like the following:  <br>  <br>Accept-Encoding: gzip |\n| **Character Encoding** | UTF-8 |\n| **Response Format** | JSON. The header of your request should specify JSON format for the response. |\n| **Rate Limit** | 60 requests per minute. |\n| **Read Timeout** | Set a read timeout on your client, and ensure that it is set to a value beyond 30 seconds. |\n| **Support for Tweet edits** | All Tweet objects will include Tweet edit metadata describing the Tweet's edit history. See the [\"Edit Tweets\" fundamentals page](https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets) for more details. |  \n#### Responses  \nThe following responses may be returned by the API for these requests. Most error codes are returned with a string with additional details in the body. For non-200 responses, clients should attempt to reconnect.  \n| Status | Text | Description |\n| --- | --- | --- |\n| 200 | Success | The connection was successfully opened, and new activities will be sent through as they arrive. |\n| 401 | Unauthorized | HTTP authentication failed due to invalid credentials. Log in to console.gnip.com with your credentials to ensure you are using them correctly with your request. |\n| 406 | Not Acceptable | Generally, this occurs where your client fails to properly include the headers to accept gzip encoding from the stream, but can occur in other circumstances as well.  <br>  <br>Will contain a JSON message similar to \"This connection requires compression. To enable compression, send an 'Accept-Encoding: gzip' header in your request and be ready to uncompress the stream as it is read on the client end.\" |\n| 429 | Rate Limited | Your app has exceeded the limit on connection requests. |\n| 503 | Service Unavailable | Twitter server issue. Reconnect using an exponential backoff pattern. If no notice about this issue has been posted on the [Twitter API Status Page](https://api.twitterstat.us/), contact support or emergency if unable to connect after 10 minutes. |  \n**Example curl Request**  \nThe following example request is accomplished using cURL on the command line. However, note that these requests may also be sent with the programming language of your choice.  \ncurl --compressed -v -uexample@customer.com \"https://gnip-stream.twitter.com/stream/powertrack/accounts/:account\\_name/publishers/twitter/:stream\\_label.json\"  \nPowerTrack Rules API  \npowertrack-rules\n",
        "line_start": 993,
        "line_end": 1021,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "41": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack Rules API\n\nContent: \n# PowerTrack Rules API  \nJump to on this page  \n[Methods](#Methods)  \n[Authentication](#Authentication)  \n[POST /rules](#AddRules)  \n[GET /rules](#ListRules)  \n[GET /rules/:rule\\_id](#GetRule)  \n[POST /rules \\_method=get](#GetRules)  \n[POST /rules \\_method=delete](#DeleteRules)  \n[POST /validation](#ValidateRules)\n",
        "line_start": 1037,
        "line_end": 1047,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "42": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack Rules API\n\tMethods\u00a0[\u00b6](#methods- \"Permalink to this headline\")\n\nContent: \n## Methods\u00a0[\u00b6](#methods- \"Permalink to this headline\")  \n| Method | Description |\n| --- | --- |\n| [POST /rules](#AddRules) | Add rules to the stream |\n| [GET /rules](#ListRules) | Retrieve all rules currently in place on the stream |\n| [GET /rules/:rule\\_id](#GetRule) | Retrieve an existing rule on the stream by rule ID |\n| [POST /rules \\_method=get](#GetRules) | Retrieve multiple rules on the stream by rule IDs |\n| [POST /rules \\_method=delete](#DeleteRules) | Delete rules from the stream |\n| [POST /validation](#ValidateRules) | Validate PowerTrack rule syntax |\n",
        "line_start": 983,
        "line_end": 992,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "43": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack Rules API\n\tAuthentication\u00a0[\u00b6](#authentication- \"Permalink to this headline\")\n\nContent: \n## Authentication\u00a0[\u00b6](#authentication- \"Permalink to this headline\")  \nAll requests to the PowerTrack rules API must use HTTP Basic Authentication, constructed from a valid email address and password combination used to log into your account at console.gnip.com. Credentials must be passed as the Authorization header for each request. Make sure your client is adding the \"Authentication: Basic\" HTTP header (with encoded credentials over HTTPS) to all API requests.\n",
        "line_start": 989,
        "line_end": 991,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "44": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack Rules API\n\tPOST /rules\u00a0[\u00b6](#post-rules- \"Permalink to this headline\")\n\nContent: \n## POST /rules\u00a0[\u00b6](#post-rules- \"Permalink to this headline\")  \nAdds one or many rules to your PowerTrack stream's ruleset.  \n#### Request Specifications  \n|     |     |\n| --- | --- |\n| **Request Method** | HTTP POST |\n| **Content Type** | \"application/json\". The request should specify this as the \"Content-type\". |\n| **URL** | Found on the [Console - Products API Help tab](https://developer.twitter.com/en/docs/twitter-api/enterprise/console/product), and uses the following structure:  <br>  <br>`https://data-api.twitter.com/rules/powertrack/accounts/{gnip_account_name}/publishers/twitter/{stream_label}.json` |\n| **Character Encoding** | UTF-8 |\n| **Request Body Format** | JSON |\n| **Request Body Size Limit** | 5 MB |\n| **Rate Limit** | 60 requests per minute, aggregated across all requests to /rules endpoint for the specific stream's API (POST and GET). Rule addition requests will be processed serially and will be rejected if you have more than one rule request happening at the same time. |  \n#### Request Body Content  \nYour request should provide rule data in the following format with the defined Content-type: \"application/json\":  \n{\n\"rules\":\n[\n{\"value\":\"rule1\",\"tag\":\"tag1\"},\n{\"value\":\"rule2\",\"tag\":\"tag2\"}\n]\n}  \n**Example curl Request**  \nThe following example requests demonstrate how to add rules using cURL on the command line, using JSON rules.  \ncurl -v -X POST -uexample@customer.com \"https://data-api.twitter.com/rules/powertrack/accounts/:account_name/publishers/twitter/:stream_label.json\" -d '{\"rules\":[{\"value\":\"rule1\",\"tag\":\"tag1\"},{\"value\":\"rule2\",\"tag\":\"tag2\"}]}'  \ncurl -v -X POST -uexample@customer.com \"https://data-api.twitter.com/rules/powertrack/accounts/:account_name/publishers/twitter/:stream_label.json\" -d @arrayofrulesfile_max5mb.json  \ncurl -v -X POST -uexample@customer.com \"https://data-api.twitter.com/rules/powertrack/accounts/companyname/publishers/twitter/prod.json\" -d '{\"rules\":[{\"value\":\"(#snow OR snowday OR \"snow day\" OR from:noaa) lang:en\",\"tag\":\"4581245\"},{\"value\":\"(skiing OR boarding OR \"hitting the slopes\" OR from:OnTheSnow) lang:en\",\"tag\":\"4581267\"}]}'  \n#### Responses  \nThe following responses may be returned by the API for these requests. Non-200 responses should be retried after making any necessary modifications in the rules.  \n| Status | Text | Description |\n| --- | --- | --- |\n| 201 | Created | The rule or rules were successfully added to your PowerTrack ruleset. |\n| 400 | Bad Request | Generally relates to poorly formatted JSON, and includes an \"Invalid JSON\" message in the response. |\n| 401 | Unauthorized | HTTP authentication failed due to invalid credentials. Log in to console.gnip.com with your credentials to ensure you are using them correctly with your request. |\n| 422 | Unprocessable Entity | Generally occurs due to an invalid rule, based on the PowerTrack rule restrictions. Requests fail or succeed as a batch. For these errors, each invalid rule and the reason for rejection is included in a JSON message in the response. Catch the associated exception to expose this message. |\n| 429 | Rate Limited | Your app has exceeded the limit on requests to add, delete, or list rules for this stream. |\n| 503 | Service Unavailable | Twitter server issue. Reconnect using an exponential backoff pattern. If no notice about this issue has been posted on the [Twitter API Status Page](https://api.twitterstat.us/) contact support or contact emergency if still unable to connect after 10 minutes. |  \n**Example Responses**  \nThis response indicates that all rules (two in this case) were successfully created.  \nHTTP/1.1 201 Created\n{\n\"summary\": {\n\"created\": 2,\n\"not_created\": 0\n},\n\"detail\": [{\n\"rule\": {\n\"value\": \"(#snow OR snowday OR \\\"snow day\\\" OR from:noaa) lang:en\",\n\"tag\": \"4581245\",\n\"id\": 734938587381145604\n},\n\"created\": true\n}, {\n\"rule\": {\n\"value\": \"(skiing OR boarding OR \\\"hitting the slopes\\\" OR from:OnTheSnow) lang:en\",\n\"tag\": \"4581267\",\n\"id\": 734938587381174273\n},\n\"created\": true\n}],\n\"sent\": \"2016-05-24T02:46:28.402Z\"\n}  \nThis response indicates that one rule was successfully created, and two were not created because they already exist. Rules are indexed by rule value (syntax). For rules not created there is a 'message' field explaining why the rule could not be created.  \nHTTP/1.1 201 Created\n{\n\"summary\": {\n\"created\": 1,\n\"not_created\": 2\n},\n\"detail\": [{\n\"rule\": {\n\"value\": \"robot OR \ud83e\udd16\",\n\"tag\": \"botrule123\",\n\"id\": 734861971116285952\n},\n\"created\": true\n}, {\n\"rule\": {\n\"value\": \"fish OR \ud83d\udc1f\",\n\"tag\": \"fishrule123\"\n},\n\"created\": false,\n\"message\": \"A rule with this value already exists\"\n}, {\n\"rule\": {\n\"value\": \"Pizza OR \ud83c\udf55\",\n\"tag\": \"pizzarule123\"\n},\n\"created\": false,\n\"message\": \"A rule with this value already exists\"\n}],\n\"sent\": \"2016-05-23T21:42:01.661Z\"\n}  \nThe following responses indicate that no rules were created. In each case there is a 'message' field explaining why the rule could not be created. Note that when one or more rules are invalid, no rules are added (even rules with valid syntax).  \nHTTP/1.1 422 Unprocessable Entity\n{\n\"summary\": {\n\"created\": 0,\n\"not_created\": 2\n},\n\"detail\": [{\n\"rule\": {\n\"value\": \"streaming gnip contains:$twtr\",\n\"tag\": null\n},\n\"created\": false,\n\"message\": \"no viable alternative at input '$twtr' (at position 25)\\n\"\n}, {\n\"rule\": {\n\"value\": \"streaming gnip contains:\\\"$twtr\\\"\",\n\"tag\": null\n},\n\"created\": false\n}],\n\"sent\": \"2016-06-01T15:41:27.451Z\"\n}  \nHTTP/1.1 422 Unprocessable Entity\n{\n\"summary\": {\n\"created\": 0,\n\"not_created\": 1\n},\n\"detail\": [{\n\"rule\": {\n\"value\": \"-follow\",\n\"tag\": null\n},\n\"created\": false,\n\"message\": \"Rules must contain a non-negation term (at position 1)\\nRules must contain at least one positive, non-stopword clause (at position 1)\\n\"\n}],\n\"sent\": \"2016-05-23T18:34:25.218Z\"\n}  \nHTTP/1.1 422 Unprocessable Entity\n{\n\"summary\": {\n\"created\": 0,\n\"not_created\": 1\n},\n\"detail\": [{\n\"rule\": {\n\"value\": \"streaming AND lang:en\",\n\"tag\": null\n},\n\"created\": false,\n\"message\": \"Ambiguous use of and as a keyword. Use a space to logically join two clauses, or \\\"and\\\" to find occurrences of and in text (at position 11)\\n\"\n}],\n\"sent\": \"2016-05-23T21:39:49.612Z\"\n}\n",
        "line_start": 1072,
        "line_end": 1219,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "45": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack Rules API\n\tGET /rules\u00a0[\u00b6](#get-rules- \"Permalink to this headline\")\n\nContent: \n## GET /rules\u00a0[\u00b6](#get-rules- \"Permalink to this headline\")  \nRetrieve all rules currently in place on the stream  \n#### Request Specifications  \n|     |     |\n| --- | --- |\n| **Request Method** | HTTP GET |\n| **URL** | Found on the [Console - Products API Help tab](https://developer.twitter.com/en/docs/twitter-api/enterprise/console/product), and uses the following structure:  <br>  <br>`https://data-api.twitter.com/rules/powertrack/accounts/:account_name/publishers/twitter/:stream_label.json` |\n| **Rate Limit** | 60 requests per minute, aggregated across all requests to /rules endpoint for the specific stream's API (POST and GET). |  \n**Example cURL Request**  \nThe following example request demonstrates how to retrieve rules using cURL on the command line.  \ncurl -v -uexample@customer.com \"https://data-api.twitter.com/rules/powertrack/accounts/:account_name/publishers/twitter/:stream_label.json\"  \n#### Response  \nThe following responses may be returned by the API for these requests. Non-200 responses should be retried, utilizing an exponential backoff for subsequent requests.  \n| Status | Text | Description |\n| --- | --- | --- |\n| 200 | OK  | The request was successful, and the current ruleset is returned in JSON format. |\n| 400 | Bad Request | Generally relates to poorly formatted JSON, and includes an \"Invalid JSON\" message in the response. |\n| 401 | Unauthorized | HTTP authentication failed due to invalid credentials. Log in to console.gnip.com with your credentials to ensure you are using them correctly with your request. |\n| 429 | Rate Limited | Your app has exceeded the limit on requests to add, delete, or list rules for this stream. |\n| 503 | Service Unavailable | Twitter server issue. Reconnect using an exponential backoff pattern. If no notice about this issue has been posted on the [Twitter API Status Page](https://api.twitterstat.us/) contact support. |  \n**Example Response**  \nHTTP/1.1 200 OK\n{\n\"rules\": [{\n\"value\": \"from:twitterdev\",\n\"tag\": \"tweetsfromtwitterdev123\",\n\"id\": 735163830813134848\n}, {\n\"value\": \"fish OR \ud83d\udc1f\",\n\"tag\": \"fishrule123\",\n\"id\": 738034522583769088\n}, {\n\"value\": \"Pizza OR \ud83c\udf55\",\n\"tag\": \"pizzarule123\",\n\"id\": 738034522579554304\n}, {\n\"value\": \"robot OR \ud83e\udd16\",\n\"tag\": \"botrule123\",\n\"id\": 738034522579570689\n}],\n\"sent\": \"2016-06-01T15:52:37.341Z\"\n}\n",
        "line_start": 1263,
        "line_end": 1305,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "46": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack Rules API\n\tGET /rules/:rule\\_id\u00a0[\u00b6](#get-rules-rule-id- \"Permalink to this headline\")\n\nContent: \n## GET /rules/:rule\\_id\u00a0[\u00b6](#get-rules-rule-id- \"Permalink to this headline\")  \nRetrieve an existing rule on the stream by rule ID. Note that all rules are assigned a unique ID by Twitter at the time of creation, rules that are deleted and recreated will receive a different unique rule ID.  \n#### Request Specifications  \n|     |     |\n| --- | --- |\n| **Request Method** | HTTP GET |\n| **URL** | Found on the [Console - Products API Help tab](https://developer.twitter.com/en/docs/twitter-api/enterprise/console/product), and uses the following structure:  <br>  <br>`https://data-api.twitter.com/rules/powertrack/accounts/:account_name/publishers/twitter/:stream_label/rules/:rule_id.json` |\n| **Rate Limit** | 60 requests per minute, aggregated across all requests to /rules endpoint for the specific stream's API (POST and GET). |  \n**Example cURL Request**  \nThe following example request demonstrates how to retrieve a rule by rule\\_id using cURL on the command line.  \ncurl -v -uexample@customer.com \"https://data-api.twitter.com/rules/powertrack/accounts/:account_name/publishers/twitter/:stream_label/rules/:rule_id.json\"  \ncurl -v -uexample@customer.com \"https://data-api.twitter.com/rules/powertrack/accounts/companyname/publishers/twitter/prod/rules/735163830813134848.json\"  \n#### Response  \nThe following responses may be returned by the API for these requests. Non-200 responses should be retried, utilizing an exponential backoff for subsequent requests.  \n| Status | Text | Description |\n| --- | --- | --- |\n| 200 | OK  | The request was successful, and the current rule is returned in JSON format. |\n| 400 | Bad Request | Generally relates to poorly formatted JSON, and includes an \"Invalid JSON\" message in the response. |\n| 401 | Unauthorized | HTTP authentication failed due to invalid credentials. Log in to console.gnip.com with your credentials to ensure you are using them correctly with your request. |\n| 429 | Rate Limited | Your app has exceeded the limit on requests to add, delete, or list rules for this stream. |\n| 503 | Service Unavailable | Twitter server issue. Reconnect using an exponential backoff pattern. If no notice about this issue has been posted on the [Twitter API Status Page](https://api.twitterstat.us/) contact support. |  \n**Example Response**  \nHTTP/1.1 200 OK\n{\n\"rules\": [{\n\"value\": \"from:twitterdev\",\n\"tag\": \"tweetsfromtwitterdev123\",\n\"id\": 735163830813134848\n\"id_str\":\"735163830813134848\"\n}],\n\"sent\": \"2016-06-01T15:52:37.341Z\"\n}\n",
        "line_start": 1323,
        "line_end": 1355,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "47": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack Rules API\n\tPOST /rules \\_method=get\u00a0[\u00b6](#post-rules--method-get- \"Permalink to this headline\")\n\nContent: \n## POST /rules \\_method=get\u00a0[\u00b6](#post-rules--method-get- \"Permalink to this headline\")  \nRetrieves requested existing rules by list of rule IDs currently on a stream.  \n#### Request Specifications  \n|     |     |\n| --- | --- |\n| **Request Method** | HTTP POST |\n| **URL** | Found on the API Help page, and uses the following structure:  <br>  <br>`https://data-api.twitter.com/rules/powertrack/accounts/{gnip_account_name}/publishers/twitter/{stream_label}.json?_method=get` |\n| **Character Encoding** | UTF-8 |\n| **Request Body Format** | JSON |\n| **Request Body Size Limit** | 5 MB |\n| **Rate Limit** | 60 requests per minute, aggregated across all requests to /rules endpoint for the specific stream's API (POST and GET). |\n| **Compression** | Gzip compression is supported, but not required for these requests. |  \n**Example curl Request**  \nThe following example request demonstrates how to add rules using cURL on the command line.  \ncurl -v -X POST -uexample@customer.com \\\n\"https://data-api.twitter.com/rules/powertrack/accounts/:account_name/publishers/twitter/:stream_label.json?_method=get\" \\\n-d '{\"rule_ids\":[734938587381145604,734938587381174273]}\"  \n#### Response  \nThe following responses may be returned by the API for these requests. Non-200 responses should be retried, utilizing an exponential backoff for subsequent requests.  \n| Status | Text | Description |\n| --- | --- | --- |\n| 200 | OK  | The request was successful, and the current ruleset is returned in JSON format. |\n| 400 | Bad Request | Generally relates to poorly formatted JSON, and includes an \"Invalid JSON\" message in the response. |\n| 401 | Unauthorized | HTTP authentication failed due to invalid credentials. Log in to console.gnip.com with your credentials to ensure you are using them correctly with your request. |\n| 429 | Rate Limited | Your app has exceeded the limit on requests to add, delete, or list rules for this stream. |\n| 503 | Service Unavailable | Twitter server issue. Reconnect using an exponential backoff pattern. If no notice about this issue has been posted on the [Twitter API Status Page](https://api.twitterstat.us/) contact support. |  \n**Example Response**  \nHTTP/1.1 200 OK\n{\n\"rules\": [{\n\"value\": \"from:furiouscamper\",\n\"tag\": null,\n\"id\": 734938587381145604\n}, {\n\"value\": \"fish \ud83d\udc1f\",\n\"tag\": null,\n\"id\": 734938587381174273\n}],\n\"sent\": \"2016-06-01T15:52:37.341Z\"\n}  \n{\n\"error\": {\n\"message\": \"Invalid JSON. The body must be in the format {\\\"rules\\\":[{\\\"value\\\":\\\"rule1\\\", \\\"tag\\\":\\\"tag1\\\"}, {\\\"value\\\":\\\"rule2\\\"}]} or {\\\"rule_ids\\\": [rule_id1, rule_id2, rule_id3, rule_id4, rule_id5]}\",\n\"sent\": \"2013-08-16T00:50:00+00:00\"\n}\n}\n",
        "line_start": 1376,
        "line_end": 1422,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "48": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack Rules API\n\tPOST /rules \\_method=delete\u00a0[\u00b6](#post-rules--method-delete- \"Permalink to this headline\")\n\nContent: \n## POST /rules \\_method=delete\u00a0[\u00b6](#post-rules--method-delete- \"Permalink to this headline\")  \nDeletes requested existing rules by list of rule values or rule IDs currently on a stream.  \n#### Request Specifications  \n|     |     |\n| --- | --- |\n| **Request Method** | HTTP POST |\n| **Authentication** | Basic Authentication. Your login credentials must be included in the header of the request. |\n| **Content Type** | \"application/json\". The request should specify this as the \"Content-type\". |\n| **URL** | Found on the API Help page, and uses the following structure:  <br>  <br>`https://data-api.twitter.com/rules/powertrack/accounts/{gnip_account_name}/publishers/twitter/{stream_label}.json?_method=delete` |\n| **Character Encoding** | UTF-8 |\n| **Request Body Format** | JSON |\n| **Request Body Size Limit** | 5 MB |\n| **Rate Limit** | 60 requests per minute, aggregated across all requests to /rules endpoint for the specific stream's API (POST and GET). |  \n#### Request Body Content  \nYour request should provide rule data in the following formats:  \nContent-type: \"application/json\"\n{\n\"rules\":\n[\n{\"value\":\"rule1\"},\n{\"value\":\"rule2\"}\n]\n}  \nContent-type: \"application/json\"\n{\n\"rule_ids\":\n[\n734938587381145604,\n734938587381174273\n]\n}  \n**Example curl Request**  \nThe following example request demonstrates how to add rules using cURL on the command line.  \ncurl -v -X POST -uexample@customer.com \\\n\"https://data-api.twitter.com/rules/powertrack/accounts/:account_name/publishers/twitter/:stream_label.json?_method=delete\" \\\n-d '{\"rules\":[{\"value\":\"testrule\"}]}\"  \ncurl -v -X POST -uexample@customer.com \\\n\"https://data-api.twitter.com/rules/powertrack/accounts/:account_name/publishers/twitter/:stream_label.json?_method=delete\" \\\n-d '{\"rule_ids\":[734938587381145604,734938587381174273]}\"  \n#### Responses  \nThe following responses may be returned by the API for these requests. Non-200 responses should be retried following any necessary modifications to the rules being deleted.  \n| Status | Text | Description |\n| --- | --- | --- |\n| 200 | OK  | Indicates that the rule data supplied with the request consisted of valid JSON. However, note that if no rules are found in the ruleset for the PowerTrack stream based on a case-sensitive search, no rules will be deleted. |\n| 400 | Bad Request | Generally relates to poorly formatted JSON, and includes an \"Invalid JSON\" message in the response. |\n| 401 | Unauthorized | HTTP authentication failed due to invalid credentials. Log in to console.gnip.com with your credentials to ensure you are using them correctly with your request. |\n| 429 | Rate Limited | Your app has exceeded the limit on requests to add, delete, or list rules for this stream. |\n| 503 | Service Unavailable | Twitter server issue. Reconnect using an exponential backoff pattern. If no notice about this issue has been posted on the [Twitter API Status Page](https://api.twitterstat.us/), contact support. |  \n**Example Responses**  \nHTTP/1.1 200 OK\n{\n\"summary\": {\n\"deleted\": 3,\n\"not_deleted\": 0\n},\n\"detail\": [],\n\"sent\": \"2016-06-01T15:46:48.654Z\"\n}  \nHTTP/1.1 200 OK\n{\n\"summary\": {\n\"deleted\": 0,\n\"not_deleted\": 3\n},\n\"detail\": [{\n\"rule\": {\n\"value\": \"Pizza\",\n\"tag\": null\n},\n\"deleted\": false,\n\"message\": \"Rule does not exist\"\n}, {\n\"rule\": {\n\"value\": \"eggplant\",\n\"tag\": null\n},\n\"deleted\": false,\n\"message\": \"Rule does not exist\"\n}, {\n\"rule\": {\n\"value\": \"fish\",\n\"tag\": null\n},\n\"deleted\": false,\n\"message\": \"Rule does not exist\"\n}],\n\"sent\": \"2016-06-01T15:49:15.951Z\"\n}  \nHTTP/1.1 400 Bad Request\n{\n\"error\": {\n\"message\": \"Invalid JSON. The body must be in the format {\\\"rules\\\":[{\\\"value\\\":\\\"rule1\\\", \\\"tag\\\":\\\"tag1\\\"}, {\\\"value\\\":\\\"rule2\\\"}]} or {\\\"rule_ids\\\": [rule_id1, rule_id2, rule_id3, rule_id4, rule_id5]}\",\n\"sent\": \"2013-08-16T00:50:00+00:00\"\n}\n}  \n**Important note on rule management:** Rule sets are indexed by the value or ruleID, not the tag; therefore, all rule additions must reference the rule value or ruleID. In order to to make a tag update to an existing rule, you must first delete it and then add it back with the new tag value.  \nRules must be unique per stream based on rule value, see below for a rule management example scenario:  \n**CREATE RULE**  \nAction: POST rule {\"value\":\"#TwitterData\",\"tag\":\"tagtextA\"} {\"summary\":{\"created\":1,\"not\\_created\":0},\"detail\":\\[{\"rule\":{\"value\":\"#TwitterData\",\"tag\":\"tagtextA\",\"id\":961664522481119232,\"id\\_str\":\"961664522481119232\"},\"created\":true}\\],\"sent\":\"2018-02-08T18:14:23.691Z\"} System: {\"value\":\"#TwitterData\",\"tag\":\"tagtextA\",\"id\":961664522481119232,\"id\\_str\":\"961664522481119232\"}  \n**FAILED ATTEMPT TO UPDATE TAG**  \nAction: POST rule {\"value\":\"#TwitterData\",\"tag\":\"tagtextB\"} \\*\\*Rule tags cannot be \"updated\" - This request is ignored because rule value `#TwitterData` already exists. {\"summary\":{\"created\":0,\"not\\_created\":1},\"detail\":\\[{\"rule\":{\"value\":\"#TwitterData\",\"tag\":\"tagtextB\",\"id\":961664522481119232,\"id\\_str\":\"961664522481119232\"},\"created\":false,\"message\":\"A rule with this value already exists\"} System: {\"value\":\"#TwitterData\",\"tag\":\"tagtextA\",\"id\":961664522481119232,\"id\\_str\":\"961664522481119232\"}  \n**FAILED ATTEMPT TO DELETE BY TAG**  \nAction: POST method=delete rule {\"tag\":\"tagtextA\"} \\*\\*Rules cannot be deleted by tag. {\"summary\":{\"deleted\":0,\"not\\_deleted\":1},\"detail\":\\[{\"rule\":{\"value\":\"\",\"tag\":null},\"deleted\":false,\"message\":\"Rule does not exist\"}\\],\"sent\":\"2018-02-08T18:42:37.004Z\"} System: {\"value\":\"#TwitterData\",\"tag\":\"tagtextA\",\"id\":961664522481119232,\"id\\_str\":\"961664522481119232\"}  \n**DELETE BY ID**  \nAction: POST method=delete rule {\"rule\\_ids\":\\[961664522481119232\\]} {\"summary\":{\"deleted\":1,\"not\\_deleted\":0},\"detail\":\\[\\],\"sent\":\"2018-02-08T18:53:54.185Z\"}  \n**DELETE BY VALUE**  \nAction: POST method=delete rule {\"value\":\"#TwitterData\"} {\"summary\":{\"deleted\":1,\"not\\_deleted\":0},\"detail\":\\[\\],\"sent\":\"2018-02-08T18:53:54.185Z\"}  \n**RECREATE RULE- NOW WITH NEW ID**  \nAction: POST rule {\"value\":\"#TwitterData\",\"tag\":\"tagtextB\"} {\"summary\":{\"created\":1,\"not\\_created\":0},\"detail\":\\[{\"rule\":{\"value\":\"#TwitterData\",\"tag\":\"tagtextB\",\"id\":961675641140609025,\"id\\_str\":\"961675641140609025\"},\"created\":true}\\],\"sent\":\"2018-02-08T18:58:34.586Z\"} System: {\"value\":\"#TwitterData\",\"tag\":\"tagtextB\",\"id\":961675641140609025,\"id\\_str\":\"961675641140609025\"}\n",
        "line_start": 1445,
        "line_end": 1554,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "49": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tPowerTrack Rules API\n\tPOST /validation\u00a0[\u00b6](#post-validation- \"Permalink to this headline\")\n\nContent: \n## POST /validation\u00a0[\u00b6](#post-validation- \"Permalink to this headline\")  \nValidates PowerTrack rules.  \n**Note:** Using this endpoint will not impact your PowerTrack streams.  \n#### Request Specifications  \n|     |     |\n| --- | --- |\n| **Request Method** | HTTP POST |\n| **URL** | Found on the API Help page in console, and uses the following structure:  <br>  <br>`https://data-api.twitter.com/rules/powertrack/accounts/:account_name/publishers/twitter/:stream_label/validation.json` |\n| **Character Encoding** | UTF-8 |\n| **Request Body Format** | JSON |\n| **Request Body Size Limit** | 5 MB |\n| **Rate Limit** | 60 requests per minute, aggregated across all requests to /rules endpoint for the specific stream's API (POST and GET). |  \n**Example curl Request**  \nThe following example request demonstrates how to add rules using cURL on the command line.  \ncurl --compressed -v -uexample@customer.com \\\n\"https://data-api.twitter.com/rules/powertrack/accounts/:account_name/publishers/twitter/:stream_label/validation.json\" \\\n-d '{\n\"rules\": [{\n\"value\": \"Pizza OR \ud83c\udf55 OR \\\"\ud83c\udf55\\\" sample:100\"\n}, {\n\"value\": \"from:contains:heart\"\n}, {\n\"value\": \"fish AND bird\"\n}, {\n\"value\": \"(((\\\"#quotedhashtag\\\"\"\n}, {\n\"value\": \"bounding_box:[-71.199636,42.230046,-70.979909,42.398619]\"\n}, {\n\"value\": \"from:jack\"\n}]\n}'  \n#### Response  \nThe following responses may be returned by the API for these requests. Non-200 responses should be retried, utilizing an exponential backoff for subsequent requests.  \n| Status | Text | Description |\n| --- | --- | --- |\n| 200 | OK  | The request was successful, and the rule validation result is returned. |\n| 400 | Bad Request | Generally relates to poorly formatted JSON, and includes an \"Invalid JSON\" message in the response. |\n| 401 | Unauthorized | HTTP authentication failed due to invalid credentials. Log in to console.gnip.com with your credentials to ensure you are using them correctly with your request. |\n| 429 | Rate Limited | Your app has exceeded the limit on requests to add, delete, or list rules for this stream. |\n| 503 | Service Unavailable | Twitter server issue. Reconnect using an exponential backoff pattern. If no notice about this issue has been posted on the [Twitter API Status Page](https://api.twitterstat.us/), contact support. |  \n**Example Response**  \nThis response indicates that one rule is valid and five are not valid. For rules that are not valid, there is a 'message' field explaining why the rule is not valid.  \nHTTP/1.1 200 OK\n{\n\"summary\": {\n\"valid\": 1,\n\"not_valid\": 5\n},\n\"detail\": [{\n\"rule\": {\n\"value\": \"from:jack\",\n\"tag\": null\n},\n\"valid\": true\n}, {\n\"rule\": {\n\"value\": \"Pizza OR \ud83c\udf55 OR \\\"\ud83c\udf55\\\" sample:100\",\n\"tag\": null\n},\n\"valid\": false,\n\"message\": \"The sample operator cannot be used with an OR. To use the sample operator with an OR in the rule, the ORed clauses must be grouped together with parenthesis.  For example, to get 10% of activites that have term1 or term2, the rule should be (excluding the single quotes) '(term1 OR term2) sample:10' (at position 21)\\n\"\n}, {\n\"rule\": {\n\"value\": \"from:contains:heart\",\n\"tag\": null\n},\n\"valid\": false,\n\"message\": \"Cannot parse rule at ':' (position 14)\\n\"\n}, {\n\"rule\": {\n\"value\": \"fish AND bird\",\n\"tag\": null\n},\n\"valid\": false,\n\"message\": \"Ambiguous use of and as a keyword. Use a space to logically join two clauses, or \\\"and\\\" to find occurrences of and in text (at position 6)\\n\"\n}, {\n\"rule\": {\n\"value\": \"(((\\\"#quotedhashtag\\\"\",\n\"tag\": null\n},\n\"valid\": false,\n\"message\": \"mismatched input 'EOF' expecting ')' (at position 20)\\n\\n\"\n}, {\n\"rule\": {\n\"value\": \"bounding_box:[-71.199636,42.230046,-70.979909,42.398619]\",\n\"tag\": null\n},\n\"valid\": false,\n\"message\": \"Cannot parse rule at '71.199636,42.230046,-70.979909,42.398619' (position 16)\\n\"\n}],\n\"sent\": \"2017-03-16T02:33:01.827Z\"\n}  \nReplay API  \nreplay-stream\n",
        "line_start": 1597,
        "line_end": 1691,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "50": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tReplay API\n\nContent: \n# Replay API  \nJump to on this page  \n[Methods](#Methods)  \n[Authentication](#Authentication)  \n[GET /replay](#Stream)\n",
        "line_start": 1711,
        "line_end": 1716,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "51": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tReplay API\n\tMethods\u00a0[\u00b6](#methods- \"Permalink to this headline\")\n\nContent: \n## Methods\u00a0[\u00b6](#methods- \"Permalink to this headline\")  \n| Method | Description |\n| --- | --- |\n| [GET /replay/:stream\\_type](#Stream) | Connect to the replay stream. For realtime PowerTrack, the Stream Type is 'powertrack'. For Volume Streams, Stream Types include 'sample10' (i.e. decahose), 'firehose', 'mentions', and 'compliance'. |  \n* * *\n",
        "line_start": 983,
        "line_end": 988,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "52": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tReplay API\n\tAuthentication\u00a0[\u00b6](#authentication- \"Permalink to this headline\")\n\nContent: \n## Authentication\u00a0[\u00b6](#authentication- \"Permalink to this headline\")  \nAll requests to the Replay API must use HTTP Basic Authentication, constructed from a valid email address and password combination used to log into your account at console.gnip.com. Credentials must be passed as the Authorization header for each request.  \n* * *\n",
        "line_start": 989,
        "line_end": 992,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "53": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tReplay API\n\tGET /replay\u00a0[\u00b6](#get-replay- \"Permalink to this headline\")\n\nContent: \n## GET /replay\u00a0[\u00b6](#get-replay- \"Permalink to this headline\")  \nEstablishes a connection to the Replay data stream. Tweet data will be delivered for the time period specified, and user profile objects will reflect the referenced users at the time when the Replay API is running.  \n**Please see [HERE](https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data) for details on consuming streaming data after the connection is established.**  \n|     |     |\n| --- | --- |\n| **Request Method** | HTTP GET |\n| **Connection Type** | Keep-Alive  <br>  <br>This should be specified in the header of the request. |\n| **URL** | Found on the stream's API Help page of your dashboard, the URL is built with Stream Type, Account Name and Stream Label tokens. For realtime PowerTrack, the Stream Type is 'powertrack'. For Volume Streams, Stream Types include 'sample10' (i.e. decahose), 'firehose', 'mentions', and 'compliance'.  <br>  <br>Replay URLs have the following pattern:  <br>  <br><br>[https://gnip-stream.gnip.com/replay/](https://gnip-stream.gnip.com/replay/){STREAM\\_TYPE}/accounts/{ACCOUNT\\_NAME}/publishers/twitter/{STREAM\\_LABEL}.json<br><br>  <br>For example, the Replay URL for realtime PowerTrack has the following pattern:  <br>  <br><br>[https://gnip-stream.gnip.com/replay/powertrack/accounts/](https://gnip-stream.gnip.com/replay/powertrack/accounts/){ACCOUNT\\_NAME}/publishers/twitter/{STREAM\\_LABEL}.json<br><br>  <br>For example, the Replay URL for Decahose has the following pattern:  <br>  <br><br>[https://gnip-stream.gnip.com/replay/sample10/accounts/](https://gnip-stream.gnip.com/replay/sample10/accounts/){ACCOUNT\\_NAME}/publishers/twitter/{STREAM\\_LABEL}.json |\n| **Compression** | Gzip. To connect to the stream using Gzip compression, simply send an Accept-Encoding header in the connection request. The header should look like the following:  <br>  <br>Accept-Encoding: gzip |\n| **Character Encoding** | UTF-8 |\n| **Response Format** | JSON. The header of your request should specify JSON format for the response. |\n| **Rate Limit** | 5 requests per 5 minutes. |\n| **fromDate** | The oldest (starting) UTC timestamp from which the activities will be provided, must be in 'YYYYMMDDHHMM' format. Timestamp is in minute granularity and is inclusive (i.e. 12:00 includes the 00 minute). Valid times must be within the last 5 days, UTC time, and no more recent than 31 minutes before the current point in time. It's recommended that the fromDate and toDate should be within ~2 hours. |\n| **toDate** | The latest (ending) UTC timestamp to which the activities will be provided, must be in 'YYYYMMDDHHMM' format. Timestamp is in minute granularity and is exclusive (i.e. 12:30 does not include the 30th minute of the hour). Valid times must be within the last 5 days, UTC time, and no more recent than 30 minutes before the current point in time. It's recommended that the fromDate and toDate should be within ~2 hours. |\n| **Read Timeout** | Set a read timeout on your client, and ensure that it is set to a value beyond 30 seconds. |\n| **Support for Tweet edits** | Since all Replay requests are for Tweets posted at least 30 minutes ago, all Tweets returned by Replay will reflect their final edit state. All Tweet objects will include metadata that describes its edit history. See the [\"Edit Tweets\" fundamentals](https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets) page for more details. |  \n#### Responses  \nThe following responses may be returned by the API for these requests. Most error codes are returned with a string with additional details in the body. For non-200 responses, clients should attempt to reconnect.  \n| Status | Text | Description |\n| --- | --- | --- |\n| 200 | Success | The connection was successfully opened, and new activities will be sent through until the end of the requested time period is reached, and a \"Replay Request Completed\" message is sent. |\n| 401 | Unauthorized | HTTP authentication failed due to invalid credentials. Log in to console.gnip.com with your credentials to ensure you are using them correctly with your request. |\n| 406 | Not Acceptable | Generally, this occurs where your client either fails to properly include the headers to accept gzip encoding from the stream, or specifies an unacceptable fromDate or toDate.  <br>  <br>Will contain a JSON message indicating the issue -- e.g. \"This connection requires compression. To enable compression, send an 'Accept-Encoding: gzip' header in your request and be ready to uncompress the stream as it is read on the client end.\" or \"Invalid date for query parameter 'toDate'. Can't ask for tweets from within the past 30 minutes.\" |\n| 429 | Rate Limited | Your app has exceeded the limit on connection requests. |\n| 503 | Service Unavailable | Twitter server issue. Reconnect using an exponential backoff pattern. If no notice about this issue has been posted on the [Twitter API Status Page](https://api.twitterstat.us/), contact support. |  \n#### \"Request Completed\" Message  \nOnce a request has been completed, a \"Replay Request Completed\" message will be delivered through the stream prior to disconnecting inside a \"info\" JSON message. If your stream is disconnected prior to receiving this message, the request was not completed, and you will need to re-run the missing portion of the request.  \nA premature disconnection may occur especially where your client is not consuming activities quickly enough. In this scenario, the connection may send the \"Completed\" message, but the connection may close prior to your client receiving it due to the slow rate of consumption. In this scenario, your client should re-request the end-portion of the data to ensure completeness, based on the timestamps of the last Tweets received.  \nThe \"info\" JSON message has the following structure:  \n{\n\"info\": {\n\"message\": \"Replay Request Completed\",\n\"sent\": \"2016-05-27T22:15:50+00:00\",\n\"activity\\_count\": 8874\n}\n}  \nIf any errors are associated with a completed Replay request, the \"info\" message will indicate that errors occurred and also list the minutes that were effected in the \"minutes\\_failed\" field. Here is an example:  \n{\n\"info\": {\n\"message\": \"Replay Request Completed with Errors\",\n\"sent\": \"2016-05-27T16:00:02+00:00\",\n\"activity\\_count\": 56333,\n\"minutes\\_failed\": \\[\n\"2013-02-20T00:05:00+00:00\",\n\"2013-02-20T00:06:00+00:00\"\n\\]\n}\n}  \nUsers (or their client applications) should monitor for complete success of the Replay stream, and submit new Replay requests for any minutes that failed.  \n#### \"Request Failed to Complete\" Message  \nIf a Replay request fails to complete, the \"info\" message will indicate the failure and also list the time range was was not processed. Here is an example:  \n{\n\"info\": {\n\"message\": \"Replay Request Failed to Complete\",\n\"sent\": \"2016-06-27T16:37:13+00:00\",\n\"unprocessed\\_range\": {\n\"fromDate\": \"2016-06-26T00:00:00+00:00\",\n\"toDate\": \"2016-06-26T00:01:00+00:00\"\n},\n\"activity\\_count\": 1822\n}\n}  \nIf this message is received another Replay request should be made based on the \"fromDate\" and \"toDate\" included in the \"unprocessed\\_range\" attribute.  \n#### Example curl Request  \nThe following example request is accomplished using cURL on the command line, and requests the first hour of data from June 1, 2016.  \ncurl --compressed -v -uexample@customer.com \"https://gnip-stream.gnip.com/replay/powertrack/accounts/{ACCOUNT\\_NAME}/publishers/twitter/{STREAM\\_LABEL}json?fromDate=201606010000&toDate=201606010100\"  \n* * *\n",
        "line_start": 1735,
        "line_end": 1802,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "54": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tReplay API\n\tGET /replay\u00a0[\u00b6](#get-replay- \"Permalink to this headline\")\n\tSample streams Replay Examples (Stream Types include 'sample10' (i.e. decahose), 'firehose', 'mentions')[\u00b6](#sample-streams-replay-examples-stream-types-include-sample10-i-e-decahose-firehose-mentions- \"Permalink to this headline\")\n\nContent: \n### Sample streams Replay Examples (Stream Types include 'sample10' (i.e. decahose), 'firehose', 'mentions')[\u00b6](#sample-streams-replay-examples-stream-types-include-sample10-i-e-decahose-firehose-mentions- \"Permalink to this headline\")  \nDecahose, firehose, mentions note- All partitions from volume streams are delievered in a single Replay connection.  \ncurl --compressed -v -uexample@customer.com\n\"https://gnip-stream.gnip.com/replay/sample10/accounts/{ACCOUNT\\_NAME}/publishers/twitter/{STREAM\\_LABEL}.json?fromDate=201712312330&toDate=201801010130\"\n",
        "line_start": 1831,
        "line_end": 1835,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "55": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tReplay API\n\tGET /replay\u00a0[\u00b6](#get-replay- \"Permalink to this headline\")\n\tCompliance Replay Examples[\u00b6](#compliance-replay-examples \"Permalink to this headline\")\n\nContent: \n### Compliance Replay Examples[\u00b6](#compliance-replay-examples \"Permalink to this headline\")  \nCompliance note- All partitions from Compliance Firehose are delievered in a single Replay connection.  \ncurl --compressed -v -uexample@customer.com\n\"https://gnip-stream.gnip.com/replay/compliance/accounts/{ACCOUNT\\_NAME}/publishers/twitter/{STREAM\\_LABEL}.json?fromDate=201712312330&toDate=201801010130\"\n",
        "line_start": 1838,
        "line_end": 1842,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    },
    "56": {
        "content": "Source document: data/platform-docs-versions-english/X_Twitter-API-Enterprise/PowerTrack API.md\nParagraph location: \n\tReplay API\n\tGET /replay\u00a0[\u00b6](#get-replay- \"Permalink to this headline\")\n\tPowerTrack Replay Examples[\u00b6](#powertrack-replay-examples \"Permalink to this headline\")\n\nContent: \n### PowerTrack Replay Examples[\u00b6](#powertrack-replay-examples \"Permalink to this headline\")  \nConnection to Replay to complete data during the 2018 New Year's eve disconnection:  \ncurl --compressed -v -uexample@customer.com\n\"https://gnip-stream.gnip.com/replay/powertrack/accounts/{ACCOUNT\\_NAME}/publishers/twitter/{STREAM\\_LABEL}.json?fromDate=201712312330&toDate=201801010130\"  \nImportant Note: When using PowerTrack Replay, you must first add or manage the rules currently on the replay stream. PowerTrack rules are not automatically added to a Replay stream from a normal PowerTrack stream. Rules can be managed through the Rules API for a Replay stream. Please see the [PowerTrack Rules API](https://developer.twitter.com/en/docs/tweets/filter-realtime/api-reference/powertrack-rules) for specific details on managing rules.  \nRules management on the PowerTrack replay:  \ncurl -v -X POST -uexample@customer.com\n\"https://gnip-api.twitter.com/rules/powertrack-replay/accounts/{ACCOUNT\\_NAME}/publishers/twitter/{STREAM\\_LABEL}.json\"\n-d '{\"rules\":\\[{\"value\":\"rule1\",\"tag\":\"tag1\"},{\"value\":\"rule2\"}\\]}'\n",
        "line_start": 1845,
        "line_end": 1854,
        "url": "https://developer.twitter.com/en/docs/twitter-api/enterprise/edit-tweets)."
    }
}