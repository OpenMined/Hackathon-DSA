[Home](https://transparency.fb.com/)

[Data](https://transparency.fb.com/reports/)

[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)

Community Standards Enforcement Report
======================================

We want Facebook and Instagram to be places where people have a voice. To create conditions where everyone feels comfortable expressing themselves, we must also protect their safety, privacy, dignity and authenticity. This is why we have the [Facebook Community Standards](https://transparency.fb.com/policies/community-standards/) and [Instagram Community Guidelines](https://www.facebook.com/help/instagram/477434105621119), which define what is and is not allowed in our community.

Facebook

Facebook

Instagram

[Download (CSV)](https://transparency.fb.com/sr/community-standards/)

Q3 2023 report
--------------

We publish the Community Standards Enforcement Report on a quarterly basis to more effectively track our progress and demonstrate our continued commitment to making Facebook and Instagram safe and inclusive.

#### What's new

In this November 2023 quarterly report, we share updated metrics for the reporting period from July to September 2023, detailing our progress on content that violates our policies.

Q2 2023 report
--------------

We publish the Community Standards Enforcement Report on a quarterly basis to more effectively track our progress and demonstrate our continued commitment to making Facebook and Instagram safe and inclusive.

#### What's new

In this August 2023 quarterly report, we share updated metrics for the reporting period from April to June 2023, detailing our progress on content that violates our policies.

#### Facebook and Instagram policies

Facebook and Instagram share content policies. Content that is considered violating on Facebook is also considered violating on Instagram. Throughout this report, we link to our Community Standards, which include the most comprehensive descriptions of these policies.

As we improve our methodologies, measure violations in more languages or across new parts of Facebook and Instagram and update our policies, the way we define and measure enforcement may change. As a result, historical comparisons may be imperfect.

#### Learn more

* [**Review EYâ€™s independent, third-party assessment of our Community Standards Enforcement Report from the fourth quarter of 2021.**](https://about.fb.com/news/2022/05/community-standards-enforcement-report-assessment-results/)
    
* [**Review a report from independent academic experts on their findings and recommendations on our data transparency efforts**](https://law.yale.edu/yls-today/news/facebook-data-transparency-advisory-group-releases-final-report?fbclid=IwAR2xMZr5GdD1GaNpjsXR3_yeeIR4H9iFASfrni5HKcJVAO5oWA52bvwcZxU).
    

[14

Policies on Facebook](https://transparency.fb.com/data/community-standards-enforcement/adult-nudity-and-sexual-activity/facebook)

[12

Policies on Instagram](https://transparency.fb.com/data/community-standards-enforcement/adult-nudity-and-sexual-activity/instagram)

[Read our post about this report


---------------------------------](https://transparency.fb.com/integrity-reports-q3-2023)

Recent trends
-------------

Q3 2023
-------

35.1 million


--------------

Content Actioned on Adult Nudity and Sexual Activity


------------------------------------------------------

Content actioned decreased from 51.2 million in Q2 2023 to 35.1 million in Q3 2023, returning to pre-Q2 levels after an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored.

[](https://transparency.fb.com/reports/community-standards-enforcement/adult-nudity-and-sexual-activity/facebook/#content-actioned)

Q3 2023
-------

92.4%


-------

Proactive Rate on Adult Nudity and Sexual Activity


----------------------------------------------------

Proactive rate decreased from 93.8% in Q2 2023 to 92.4% in Q3 2023, due to a bug in our proactive detection technology.

[](https://transparency.fb.com/reports/community-standards-enforcement/adult-nudity-and-sexual-activity/facebook/#proactive-rate)

Q3 2023
-------

1.6 million


-------------

Appealed Content on Adult Nudity and Sexual Activity


------------------------------------------------------

Appealed content increased from 1.0 million in Q2 2023 to 1.6 million in Q3 2023, as we increased our appeals period to adhere to the Digital Services Act.

[](https://transparency.fb.com/reports/community-standards-enforcement/adult-nudity-and-sexual-activity/instagram/#appealed-content)

Q3 2023
-------

87.8%


-------

Proactive Rate on Bullying and Harassment


-------------------------------------------

Proactive rate increased from 65.8% in Q2 2023 to 87.8% in Q3 2023, due to an update in our calculation to the proactive rate.

[](https://transparency.fb.com/reports/community-standards-enforcement/bullying-and-harassment/facebook/#proactive-rate)

Q3 2023
-------

1.6 million


-------------

Appealed Content on Bullying and Harassment


---------------------------------------------

Appealed content increased from 847K in Q2 2023 to 1.6 million in Q3 2023, as we increased our appeals period to adhere to the Digital Services Act.

[](https://transparency.fb.com/reports/community-standards-enforcement/bullying-and-harassment/instagram/#appealed-content)

Q3 2023
-------

16.9 million


--------------

Content Actioned on Child Endangerment: Sexual Exploitation


-------------------------------------------------------------

Content actioned increased from 7.2 million in Q2 2023 to 16.9 million in Q3 2023, due to a large takedown of coordinated behavior violating our policies.

[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#content-actioned)

Q3 2023
-------

99%


-----

Proactive Rate on Child Endangerment: Sexual Exploitation


-----------------------------------------------------------

Proactive rate increased from 96.9% in Q2 2023 to 99% in Q3 2023, due to an increase in proactive detection technology mentioned in content actioned.

[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#proactive-rate)

Q3 2023
-------

267K


------

Appealed Content on Child Endangerment: Sexual Exploitation


-------------------------------------------------------------

Appealed content increased from 147K in Q2 2023 to 267K in Q3 2023, due to an increase in proactive detection technology taking down content violating our policies.

[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#appealed-content)

Q3 2023
-------

204K


------

Restored Content on Child Endangerment: Sexual Exploitation


-------------------------------------------------------------

Restored content increased from 80K in Q2 2023 to 204K in Q3 2023, due to adjustments in our proactive detection technology.

[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#restored-content)

Q3 2023
-------

750K


------

Content Actioned on Dangerous Organizations and Individuals: Organized Hate


-----------------------------------------------------------------------------

Content actioned decreased from 1.1 million in Q2 2023 to 750K in Q3 2023, returning to Q2 levels after a spike in reported viral links in April.

[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/facebook/#content-actioned)

Q3 2023
-------

129K


------

Content Actioned on Dangerous Organizations and Individuals: Organized Hate


-----------------------------------------------------------------------------

Content actioned decreased from 215K in Q2 2023 to 129K in Q3 2023, returning to pre-Q3 levels after a spike in reported viral links in April.

[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/instagram/#content-actioned)

Q3 2023
-------

77.2%


-------

Proactive Rate on Dangerous Organizations and Individuals: Organized Hate


---------------------------------------------------------------------------

Proactive rate decreased from 84.5% in Q2 2023 to 77.2% in Q3 2023, due to a decrease in proactive actions taken by our media-matching technology.

[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/instagram/#proactive-rate)

Q3 2023
-------

8.2 million


-------------

Content Actioned on Dangerous Organizations and Individuals: Terrorism


------------------------------------------------------------------------

Content actioned decreased from 13.6 million in Q2 2023 to 8.2 million in Q3 2023, due to a decrease in content that violated our policies.

[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/facebook/#content-actioned)

Q3 2023
-------

99K


-----

Restored Content on Dangerous Organizations and Individuals: Terrorism


------------------------------------------------------------------------

Restored content decreased from 952K in Q2 2023 to 99K in Q3 2023, returning to pre-Q2 levels after an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored in Q2.

[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/facebook/#restored-content)

Q3 2023
-------

831K


------

Content Actioned on Dangerous Organizations and Individuals: Terrorism


------------------------------------------------------------------------

Content actioned decreased from 2 million in Q2 2023 to 831K in Q3 2023, due to a decline in content that violated our policies.

[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/instagram/#content-actioned)

Q3 2023
-------

23.7K


-------

Restored Content on Dangerous Organizations and Individuals: Terrorism


------------------------------------------------------------------------

Restored content decreased from 643K in Q2 2023 to 23.7K in Q3 2023, returning to pre-Q2 levels after an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored in Q2.

[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/instagram/#restored-content)

Q3 2023
-------

827 million


-------------

Accounts Actioned on Fake Accounts


------------------------------------

Accounts actioned increased from 676 million in Q2 2023 to 827 million in Q3 2023. Fluctuations in enforcement metrics for fake accounts are expected due to the highly adversarial nature of this space.

[](https://transparency.fb.com/reports/community-standards-enforcement/fake-accounts/facebook/#content-actioned)

Q3 2023
-------

9.6 million


-------------

Content Actioned on Hate Speech


---------------------------------

Content actioned decreased from 18 million in Q2 2023 to 9.6 million in Q3 2023, returning to pre-Q2 levels following an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored. This impacted both platforms in Q2.

[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/facebook/#content-actioned)

Q3 2023
-------

94.8%


-------

Proactive Rate on Hate Speech


-------------------------------

Proactive rate increased from 88.8% in Q2 2023 to 94.8% in Q3 2023, due to an update in our calculation to the proactive rate.

[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/facebook/#proactive-rate)

Q3 2023
-------

313K


------

Restored Content on Hate Speech


---------------------------------

Restored content decreased from 6.92 million in Q2 2023 to 313K in Q3 2023, returning to pre-Q2 levels following an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored. This impacted both platforms in Q2.

[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/facebook/#restored-content)

Q3 2023
-------

7 million


-----------

Content Actioned on Hate Speech


---------------------------------

Content actioned decreased from 9.8 million in Q2 2023 to 7.0 million in Q3 2023, returning to pre-Q2 levels following an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored. This impacted both platforms in Q2.

[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/instagram/#content-actioned)

Q3 2023
-------

977K


------

Appealed Content on Hate Speech


---------------------------------

Appealed content increased from 625K in Q2 2023 to 977K in Q3 2023, as we increased our appeals period to adhere to Digital Services Act.

[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/instagram/#appealed-content)

Q3 2023
-------

87.7K


-------

Restored Content on Hate Speech


---------------------------------

Restored content decreased from 3.92 million in Q2 2023 to 87.7K in Q3 2023, returning to pre-Q2 levels following an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored. This impacted both platforms in Q2.

[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/instagram/#restored-content)

Q3 2023
-------

290K


------

Appealed Content on Restricted Goods and Services: Drugs


----------------------------------------------------------

Appealed content increased from 213K in Q2 2023 to 290K in Q3 2023, as we increased our appeals period to adhere to the Digital Services Act.

[](https://transparency.fb.com/reports/community-standards-enforcement/regulated-goods/instagram/#appealed-content)

Q3 2023
-------

413 million


-------------

Content Actioned on Spam


--------------------------

Content actioned decreased from 1.1 billion in Q2 2023 to 413 million in Q3 2023, due to a decrease in enforcement due to a bug in our proactive detection technology that was later fixed in August. Fluctuations in enforcement metrics for spam are expected due to the highly adversarial nature of this space.

[](https://transparency.fb.com/reports/community-standards-enforcement/spam/facebook/#content-actioned)

Q3 2023
-------

98.2%


-------

Proactive Rate on Spam


------------------------

Proactive rate increased from 95.3% in Q2 2023 to 98.2% in Q3 2023, due to an update in our calculation to the proactive rate.

[](https://transparency.fb.com/reports/community-standards-enforcement/spam/facebook/#proactive-rate)

Q3 2023
-------

16.5 million


--------------

Restored Content on Spam


--------------------------

Restored content decreased from 129 million in Q2 2023 to 16.5 million in Q3 2023, due to updates to our proactive detection technology to improve accuracy.

[](https://transparency.fb.com/reports/community-standards-enforcement/spam/facebook/#restored-content)

Q3 2023
-------

401K


------

Appealed Content on Suicide and Self-Injury


---------------------------------------------

Appealed content increased from 236K in Q2 2023 to 401K in Q3 2023, as we increased our appeals period to adhere to the Digital Services Act.

[](https://transparency.fb.com/reports/community-standards-enforcement/suicide-and-self-injury/instagram/#appealed-content)

Q3 2023
-------

9 million


-----------

Content Actioned on Violent and Graphic Content


-------------------------------------------------

Content actioned decreased from 13.8 million in Q2 2023 to 9.0 million in Q3 2023, due to changes made to our enforcement systems.

[](https://transparency.fb.com/reports/community-standards-enforcement/graphic-violence/facebook/#content-actioned)

Q3 2023
-------

98.2%


-------

Proactive Rate on Violent and Graphic Content


-----------------------------------------------

Proactive rate increased from 97.5% in Q2 2023 to 98.2% in Q3 2023, due to an update in our calculation to the proactive rate.

[](https://transparency.fb.com/reports/community-standards-enforcement/graphic-violence/facebook/#proactive-rate)

Q3 2023
-------

4.1 million


-------------

Content Actioned on Violent and Graphic Content


-------------------------------------------------

Content actioned decreased from 6.2 million in Q2 2023 to 4.1 million in Q3 2023, due to changes made to our enforcement systems.

[](https://transparency.fb.com/reports/community-standards-enforcement/graphic-violence/instagram/#content-actioned)

Q3 2023
-------

8.6 million


-------------

Content Actioned on Violence and Incitement


---------------------------------------------

Content actioned decreased from 10.6 million in Q2 2023 to 8.6 million in Q3 2023, due to a decrease in content that violated our policies.

[](https://transparency.fb.com/reports/community-standards-enforcement/violence-incitement/facebook/#content-actioned)

Q3 2023
-------

97.3%


-------

Proactive Rate on Violence and Incitement


-------------------------------------------

Proactive rate increased from 85.1% in Q2 2023 to 97.3% in Q3 2023, due to an update in our calculation to the proactive rate.

[](https://transparency.fb.com/reports/community-standards-enforcement/violence-incitement/facebook/#proactive-rate)

Q3 2023
-------

1.2 million


-------------

Appealed Content on Violence and Incitement


---------------------------------------------

Appealed content increased from 663K in Q2 2023 to 1.2 million in Q3 2023, as we increased our appeals period to adhere to the Digital Services Act.

[](https://transparency.fb.com/reports/community-standards-enforcement/violence-incitement/instagram/#appealed-content)

Data by policy area
-------------------

VIOLENCE AND CRIMINAL BEHAVIOR
------------------------------

[Dangerous Organizations: Terrorism and Organized Hate](https://transparency.fb.com/data/community-standards-enforcement/dangerous-organizations/)

[Restricted Goods and Services: Drugs and Firearms](https://transparency.fb.com/data/community-standards-enforcement/regulated-goods/)

[Violence and Incitement](https://transparency.fb.com/data/community-standards-enforcement/violence-incitement/)

SAFETY
------

[Suicide and Self-Injury](https://transparency.fb.com/data/community-standards-enforcement/suicide-and-self-injury/)

[Child Endangerment: Nudity and Physical Abuse and Sexual Exploitation](https://transparency.fb.com/data/community-standards-enforcement/child-nudity-and-sexual-exploitation/)

[Bullying and Harassment](https://transparency.fb.com/data/community-standards-enforcement/bullying-and-harassment/)

OBJECTIONABLE CONTENT
---------------------

[Hate Speech](https://transparency.fb.com/data/community-standards-enforcement/hate-speech/)

[Violent and Graphic Content](https://transparency.fb.com/data/community-standards-enforcement/graphic-violence/)

[Adult Nudity and Sexual Activity](https://transparency.fb.com/data/community-standards-enforcement/adult-nudity-and-sexual-activity/)

INTEGRITY AND AUTHENTICITY
--------------------------

[Fake Accounts](https://transparency.fb.com/data/community-standards-enforcement/fake-accounts/)

[Spam](https://transparency.fb.com/data/community-standards-enforcement/spam/)

Learn about our measurements
----------------------------

DEEP DIVE
---------

[Prevalence](https://transparency.fb.com/policies/improving/prevalence-metric/)

[Content actioned](https://transparency.fb.com/policies/improving/content-actioned-metric/)

[Proactive rate](https://transparency.fb.com/policies/improving/proactive-rate-metric/)

[Appealed content](https://transparency.fb.com/policies/improving/appealed-content-metric/)

[Restored content](https://transparency.fb.com/policies/improving/restored-content-metric/)

[Getting better at measurement](https://transparency.fb.com/policies/improving/getting-better-at-measurement/)

[Corrections and adjustments](https://transparency.fb.com/policies/improving/corrections-adjustments/)

[Home](https://transparency.fb.com/)

[Data](https://transparency.fb.com/reports/)

[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)

Adult Nudity and Sexual Activity
================================

We restrict the display of adult nudity and sexual activity on Facebook and Instagram. We make some exceptions when it is clear the content is being shared in the context of a protest, for educational or medical reasons or a similar reason. On the other hand, we default to removing sexual imagery to prevent non-consensual or underage content from being shared.

This report does not include metrics related to our separate policy on the [promotion of sexual assault, violence or exploitation](https://transparency.fb.com/policies/community-standards/sexual-exploitation-adults/).

[Read the policy details](https://transparency.fb.com/policies/community-standards/adult-nudity-sexual-activity)

Facebook

Facebook

Instagram

[Download (CSV)](https://transparency.fb.com/sr/community-standards/)

Recent trends
-------------

Q3 2023
-------

35.1 million


--------------

Content Actioned on Adult Nudity and Sexual Activity


------------------------------------------------------

Content actioned decreased from 51.2 million in Q2 2023 to 35.1 million in Q3 2023, returning to pre-Q2 levels after an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored.

[](https://transparency.fb.com/reports/community-standards-enforcement/adult-nudity-and-sexual-activity/facebook/#content-actioned)

Q3 2023
-------

92.4%


-------

Proactive Rate on Adult Nudity and Sexual Activity


----------------------------------------------------

Proactive rate decreased from 93.8% in Q2 2023 to 92.4% in Q3 2023, due to a bug in our proactive detection technology.

[](https://transparency.fb.com/reports/community-standards-enforcement/adult-nudity-and-sexual-activity/facebook/#proactive-rate)

prevalence
----------

How prevalent were adult nudity and sexual activity violations?

How we calculate it

Prevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.

[Read about this data](https://transparency.fb.com/policies/improving/prevalence-metric/)

content actioned
----------------

How much adult nudity and sexual activity content did we take action on?

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for adult nudity and sexual activity. It includes both content we actioned after someone reported it, and content that we found proactively.

[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)

proactive rate
--------------

Of the violating content we actioned for adult nudity and sexual activity, how much did we find and action before people reported it?

Found and actioned by us

Reported by users

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)

Correcting mistakes

People can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.

appealed content
----------------

How much of the content we actioned for adult nudity and sexual activity did people appeal?

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)

restored content
----------------

How much actioned content for adult nudity and sexual activity was later restored?

Restored without appeal

Restored after appeal

Total

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)

NOTE:

Due to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.

How we calculate it

Prevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for adult nudity and sexual activity. It includes both content we actioned after someone reported it, and content that we found proactively.

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Home](https://transparency.fb.com/)

[Data](https://transparency.fb.com/reports/)

[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)

Bullying and Harassment
=======================

We do not tolerate bullying and harassment on Facebook and Instagram. Because we recognize bullying can be especially harmful for minors, our policies provide heightened protections for them. We want to allow for open and vital discussion of people who are in the news or who have a large public audience, so we do permit more open or critical discourse towards public figures than private individuals.

Because bullying and harassment is highly personal by nature, using technology to proactively detect these behaviors can be more challenging than other types of violations. That's why we also rely on people to report this behavior to us so we can identify and remove it. When measuring prevalence in this area, the metric captures only bullying and harassment where a deeper understanding of context or meaning is not necessary to determine if it violates our policy. We continue to invest in our proactive detection technology to ensure we are tackling the problem and protecting our community.

[Read the policy details](https://transparency.fb.com/policies/community-standards/bullying-harassment)

Facebook

Facebook

Instagram

[Download (CSV)](https://transparency.fb.com/sr/community-standards/)

Recent trends
-------------

Q3 2023
-------

87.8%


-------

Proactive Rate on Bullying and Harassment


-------------------------------------------

Proactive rate increased from 65.8% in Q2 2023 to 87.8% in Q3 2023, due to an update in our calculation to the proactive rate.

[](https://transparency.fb.com/reports/community-standards-enforcement/bullying-and-harassment/facebook/#proactive-rate)

prevalence
----------

How prevalent were bullying and harassment violations?

How we calculate it

Prevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.

[Read about this data](https://transparency.fb.com/policies/improving/prevalence-metric/)

content actioned
----------------

How much bullying and harassment content did we take action on?

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for bullying and harassment. It includes both content we actioned after someone reported it, and content that we found proactively.

[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)

proactive rate
--------------

Of the violating content we actioned for bullying and harassment, how much did we find and action before people reported it?

Found and actioned by us

Reported by users

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)

Correcting mistakes

People can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.

appealed content
----------------

How much of the content we actioned for bullying and harassment did people appeal?

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)

restored content
----------------

How much actioned content for bullying and harassment was later restored?

Restored without appeal

Restored after appeal

Total

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)

NOTE:

Due to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.

How we calculate it

Prevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for bullying and harassment. It includes both content we actioned after someone reported it, and content that we found proactively.

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Home](https://transparency.fb.com/)

[Data](https://transparency.fb.com/reports/)

[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)

Child Endangerment: Nudity and Physical Abuse and Sexual Exploitation
=====================================================================

We do not allow content that endangers children, such as content that contains nudity or physical abuse or content that sexually exploits children on Facebook and Instagram. When we find this type of violating content, we remove it, regardless of the context or the person's motivation for sharing it. We may also disable the account of the person who shared it, unless it appears the intent was not malicious (for example, to spread awareness of child exploitation).

We report apparent child exploitation to the [National Center for Missing and Exploited Children (NCMEC)](https://www.missingkids.org/home), a nonprofit that refers cases to law enforcement globally, in compliance with US law. We choose to remove content depicting non-sexualized child nudity to reduce the potential for abuse of the content by others.

[Read the policy details](https://transparency.fb.com/policies/community-standards/child-sexual-exploitation-abuse-nudity)

Facebook

Facebook

Instagram

[Download (CSV)](https://transparency.fb.com/sr/community-standards/)

Recent trends
-------------

Q3 2023
-------

16.9 million


--------------

Content Actioned on Child Endangerment: Sexual Exploitation


-------------------------------------------------------------

Content actioned increased from 7.2 million in Q2 2023 to 16.9 million in Q3 2023, due to a large takedown of coordinated behavior violating our policies.

[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#content-actioned)

Q3 2023
-------

99%


-----

Proactive Rate on Child Endangerment: Sexual Exploitation


-----------------------------------------------------------

Proactive rate increased from 96.9% in Q2 2023 to 99% in Q3 2023, due to an increase in proactive detection technology mentioned in content actioned.

[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#proactive-rate)

Q3 2023
-------

267K


------

Appealed Content on Child Endangerment: Sexual Exploitation


-------------------------------------------------------------

Appealed content increased from 147K in Q2 2023 to 267K in Q3 2023, due to an increase in proactive detection technology taking down content violating our policies.

[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#appealed-content)

Q3 2023
-------

204K


------

Restored Content on Child Endangerment: Sexual Exploitation


-------------------------------------------------------------

Restored content increased from 80K in Q2 2023 to 204K in Q3 2023, due to adjustments in our proactive detection technology.

[](https://transparency.fb.com/reports/community-standards-enforcement/child-nudity-and-sexual-exploitation/facebook/#restored-content)

prevalence
----------

How prevalent were child endangerment violations?

We cannot estimate prevalence for child endangerment right now. We will continue to expand prevalence measurement to more areas as we confirm accuracy and meaningful data.

content actioned
----------------

How much child endangerment content did we take action on?

Child Nudity and Sexual Exploitation

Child Nudity and Physical Abuse

Child Sexual Exploitation

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for child nudity and physical abuse, child sexual exploitation and child nudity and sexual exploitation. It includes both content we actioned after someone reported it, and content that we found proactively.

[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)

proactive rate
--------------

Of the violating content we actioned for child endangerment, how much did we find and action before people reported it?

Child Nudity and Physical Abuse

Child Nudity and Physical Abuse

Child Sexual Exploitation

Child Nudity and Sexual Exploitation

Found and actioned by us

Reported by users

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)

Correcting mistakes

People can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.

appealed content
----------------

How much of the content we actioned for child endangerment did people appeal?

Child Nudity and Sexual Exploitation

Child Nudity and Physical Abuse

Child Sexual Exploitation

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)

restored content
----------------

How much actioned content for child endangerment was later restored?

Child Nudity and Physical Abuse

Child Nudity and Physical Abuse

Child Sexual Exploitation

Child Nudity and Sexual Exploitation

Restored without appeal

Restored after appeal

Total

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)

NOTE:

Due to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for child nudity and physical abuse, child sexual exploitation and child nudity and sexual exploitation. It includes both content we actioned after someone reported it, and content that we found proactively.

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Home](https://transparency.fb.com/)

[Data](https://transparency.fb.com/reports/)

[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)

Dangerous Organizations: Terrorism and Organized Hate
=====================================================

We do not allow organizations or individuals that proclaim a violent mission, or are engaging in violence, to have a presence on Facebook and Instagram. We do not allow content that praises, supports or represents individuals or groups engaging in terrorist activity or organized hate.

This report does not include data on other dangerous organizations prohibited from having a presence on Facebook and Instagram, including those engaging in mass or multiple murder, human trafficking or organized criminal activity. [Learn more about our latest efforts enforcing our dangerous organizations policy.](https://about.fb.com/news/2020/05/combating-hate-and-dangerous-organizations)

[Read the policy details](https://transparency.fb.com/policies/community-standards/dangerous-individuals-organizations)

Facebook

Facebook

Instagram

[Download (CSV)](https://transparency.fb.com/sr/community-standards/)

Recent trends
-------------

Q3 2023
-------

750K


------

Content Actioned on Dangerous Organizations and Individuals: Organized Hate


-----------------------------------------------------------------------------

Content actioned decreased from 1.1 million in Q2 2023 to 750K in Q3 2023, returning to Q2 levels after a spike in reported viral links in April.

[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/facebook/#content-actioned)

Q3 2023
-------

8.2 million


-------------

Content Actioned on Dangerous Organizations and Individuals: Terrorism


------------------------------------------------------------------------

Content actioned decreased from 13.6 million in Q2 2023 to 8.2 million in Q3 2023, due to a decrease in content that violated our policies.

[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/facebook/#content-actioned)

Q3 2023
-------

99K


-----

Restored Content on Dangerous Organizations and Individuals: Terrorism


------------------------------------------------------------------------

Restored content decreased from 952K in Q2 2023 to 99K in Q3 2023, returning to pre-Q2 levels after an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored in Q2.

[](https://transparency.fb.com/reports/community-standards-enforcement/dangerous-organizations/facebook/#restored-content)

prevalence
----------

How prevalent were dangerous organizations violations?

Terrorism
---------

Views of violating content that contains terrorism are very infrequent, and we remove much of this content before people see it. As a result, many times we do not find enough violating samples to precisely estimate prevalence.

In Q3 2023, this was true for violations of our policies on terrorism, suicide and self-injury and restricted goods and services on Facebook and Instagram. In these cases, we can estimate an upper limit of how often someone would see content that violates these policies.

In Q3 2023, the upper limit was 0.05% for violations of our policy for terrorism on Facebook. This means that out of every 10,000 views of content on Facebook, we estimate no more than 5 of those views contained content that violated the policy.

Organized Hate
--------------

We cannot estimate prevalence for organized hate right now. We will continue to expand prevalence measurement to more areas as we confirm accuracy and meaningful data.

content actioned
----------------

How much dangerous organizations content did we take action on?

Terrorism

Organized Hate

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for terrorism and organized hate. It includes both content we actioned after someone reported it, and content that we found proactively.

[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)

proactive rate
--------------

Of the violating content we actioned for dangerous organizations, how much did we find and action before people reported it?

Terrorism

Terrorism

Organized Hate

Found and actioned by us

Reported by users

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)

Correcting mistakes

People can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.

appealed content
----------------

How much of the content we actioned for dangerous organizations did people appeal?

Terrorism

Organized Hate

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)

restored content
----------------

How much actioned content for dangerous organizations was later restored?

Terrorism

Terrorism

Organized Hate

Restored without appeal

Restored after appeal

Total

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)

NOTE:

Due to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for terrorism and organized hate. It includes both content we actioned after someone reported it, and content that we found proactively.

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Home](https://transparency.fb.com/)

[Data](https://transparency.fb.com/reports/)

[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)

Fake Accounts
=============

Our goal is to remove as many fake accounts on Facebook as we can. These include accounts created with malicious intent to violate our policies and personal profiles created to represent a business, organization or non-human entity, such as a pet.

We prioritize enforcement against fake accounts that seek to cause harm. Many of these accounts are used in spam campaigns and are financially motivated.

We expect the number of accounts we action to vary over time due to the unpredictable nature of adversarial account creation. Our detection technology helps us block millions of attempts to create fake accounts every day and detect millions more, often within minutes after creation. We do not include blocked attempts in the metrics we report here.

[Read the policy details](https://transparency.fb.com/policies/community-standards/account-integrity-and-authentic-identity/)

Facebook

Facebook

Instagram

[Download (CSV)](https://transparency.fb.com/sr/community-standards/)

Recent trends
-------------

Q3 2023
-------

827 million


-------------

Accounts Actioned on Fake Accounts


------------------------------------

Accounts actioned increased from 676 million in Q2 2023 to 827 million in Q3 2023. Fluctuations in enforcement metrics for fake accounts are expected due to the highly adversarial nature of this space.

[](https://transparency.fb.com/reports/community-standards-enforcement/fake-accounts/facebook/#content-actioned)

prevalence
----------

How prevalent were fake account violations?

We estimate that fake accounts represented approximately 4-5% of our worldwide monthly active users (MAU) on Facebook during Q3 2023.

accounts actioned
-----------------

How many fake accounts did we take action on?

How we calculate it

Accounts actioned is the total number of accounts that Facebook took action on for fake accounts. It includes both accounts we actioned after someone reported them, and accounts that we found proactively.

[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)

proactive rate
--------------

Of the violating accounts we actioned, how many did we find and action before people reported them?

Found and actioned by us

Reported by users

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)

How we calculate it

Accounts actioned is the total number of accounts that Facebook took action on for fake accounts. It includes both accounts we actioned after someone reported them, and accounts that we found proactively.

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

[Home](https://transparency.fb.com/)

[Data](https://transparency.fb.com/reports/)

[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)

Hate Speech
===========

We do not allow hate speech on Facebook and Instagram. We define hate speech as violent or dehumanizing speech, statements of inferiority, calls for exclusion or segregation based on protected characteristics or slurs. These characteristics include race, ethnicity, national origin, religious affiliation, sexual orientation, caste, sex, gender, gender identity and serious disability or disease.

When the intent is clear, we may allow people to share someone else's hate speech content to raise awareness or discuss whether the speech is appropriate to use, to use slurs self-referentially in an effort to reclaim the term or for other similar reasons.

[Read the policy details](https://transparency.fb.com/policies/community-standards/hate-speech/)

Facebook

Facebook

Instagram

[Download (CSV)](https://transparency.fb.com/sr/community-standards/)

Recent trends
-------------

Q3 2023
-------

9.6 million


-------------

Content Actioned on Hate Speech


---------------------------------

Content actioned decreased from 18 million in Q2 2023 to 9.6 million in Q3 2023, returning to pre-Q2 levels following an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored. This impacted both platforms in Q2.

[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/facebook/#content-actioned)

Q3 2023
-------

94.8%


-------

Proactive Rate on Hate Speech


-------------------------------

Proactive rate increased from 88.8% in Q2 2023 to 94.8% in Q3 2023, due to an update in our calculation to the proactive rate.

[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/facebook/#proactive-rate)

Q3 2023
-------

313K


------

Restored Content on Hate Speech


---------------------------------

Restored content decreased from 6.92 million in Q2 2023 to 313K in Q3 2023, returning to pre-Q2 levels following an increase in enforcement on non-violating content due to a bug in our proactive detection technology that was later fixed and the content was restored. This impacted both platforms in Q2.

[](https://transparency.fb.com/reports/community-standards-enforcement/hate-speech/facebook/#restored-content)

prevalence
----------

How prevalent were hate speech violations?

How we calculate it

Prevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.

[Read about this data](https://transparency.fb.com/policies/improving/prevalence-metric/)

content actioned
----------------

How much hate speech content did we take action on?

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for hate speech. It includes both content we actioned after someone reported it, and content that we found proactively.

[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)

proactive rate
--------------

Of the violating content we actioned for hate speech, how much did we find and action before people reported it?

Found and actioned by us

Reported by users

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)

Correcting mistakes

People can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.

appealed content
----------------

How much of the content we actioned for hate speech did people appeal?

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)

restored content
----------------

How much actioned content for hate speech was later restored?

Restored without appeal

Restored after appeal

Total

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)

NOTE:

Due to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.

How we calculate it

Prevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for hate speech. It includes both content we actioned after someone reported it, and content that we found proactively.

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Home](https://transparency.fb.com/)

[Data](https://transparency.fb.com/reports/)

[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)

Restricted Goods and Services: Drugs and Firearms
=================================================

We do not allow private individuals, manufacturers or retailers to buy, sell or trade non-medical drugs, pharmaceutical drugs and marijuana on Facebook and Instagram. We also do not allow private individuals to buy, sell, give, exchange or transfer firearms, including firearm parts or ammunition. While drugs and firearms are regulated by different legal restrictions around the world, we enforce these standards consistently across Instagram due to the borderless nature of our community.

This report does not include data on other goods prohibited from being sold on Facebook or Instagram, including human organs, animals and their parts, or on our enforcement of our separate [Commerce Policies](https://www.facebook.com/policies_center/commerce) or [Advertising Policies](https://business.facebook.com/policies/ads).

[Read the policy details](https://transparency.fb.com/policies/community-standards/regulated-goods/)

Facebook

Facebook

Instagram

[Download (CSV)](https://transparency.fb.com/sr/community-standards/)

prevalence
----------

How prevalent were restricted goods and services violations?

Views of violating content that contains restricted goods and services are very infrequent, and we remove much of this content before people see it. As a result, many times we do not find enough violating samples to precisely estimate prevalence.

In Q3 2023, this was true for violations of our policies on restricted goods and services, suicide and self-injury and terrorism on Facebook and Instagram. In these cases, we can estimate an upper limit of how often someone would see content that violates these policies.

In Q3 2023, the upper limit was 0.05% for violations of our policy for restricted goods and services on Facebook. This means that out of every 10,000 views of content on Facebook, we estimate no more than 5 of those views contained content that violated the policy.

content actioned
----------------

How much restricted goods and services content did we take action on?

Drugs

Firearms

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for drugs and firearms. It includes both content we actioned after someone reported it, and content that we found proactively.

[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)

proactive rate
--------------

Of the violating content we actioned for restricted goods and services, how much did we find and action before people reported it?

Drugs

Drugs

Firearms

Found and actioned by us

Reported by users

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)

Correcting mistakes

People can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.

appealed content
----------------

How much of the content we actioned for restricted goods and services did people appeal?

Drugs

Firearms

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)

restored content
----------------

How much actioned content for restricted goods and services were later restored?

Drugs

Drugs

Firearms

Restored without appeal

Restored after appeal

Total

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)

NOTE:

Due to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for drugs and firearms. It includes both content we actioned after someone reported it, and content that we found proactively.

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Home](https://transparency.fb.com/)

[Data](https://transparency.fb.com/reports/)

[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)

Spam
====

We do not allow spam on Facebook. Spam is a broad term used to describe content that is designed to be shared in deceptive and annoying ways or attempts to mislead users to drive engagement. Spam spreads in a number of ways: It can be automated (published by bots or scripts) or coordinated (when an actor uses multiple accounts to spread deceptive content).

Spammers aim to build audiences to inflate their content's distribution and reach, typically for financial gain. The tactics spammers use, and our ability to detect them, drive the amount of content we take action on as well as our proactive rate.

[Read the policy details](https://transparency.fb.com/policies/community-standards/spam/)

Facebook

Facebook

Instagram

[Download (CSV)](https://transparency.fb.com/sr/community-standards/)

Recent trends
-------------

Q3 2023
-------

413 million


-------------

Content Actioned on Spam


--------------------------

Content actioned decreased from 1.1 billion in Q2 2023 to 413 million in Q3 2023, due to a decrease in enforcement due to a bug in our proactive detection technology that was later fixed in August. Fluctuations in enforcement metrics for spam are expected due to the highly adversarial nature of this space.

[](https://transparency.fb.com/reports/community-standards-enforcement/spam/facebook/#content-actioned)

Q3 2023
-------

98.2%


-------

Proactive Rate on Spam


------------------------

Proactive rate increased from 95.3% in Q2 2023 to 98.2% in Q3 2023, due to an update in our calculation to the proactive rate.

[](https://transparency.fb.com/reports/community-standards-enforcement/spam/facebook/#proactive-rate)

Q3 2023
-------

16.5 million


--------------

Restored Content on Spam


--------------------------

Restored content decreased from 129 million in Q2 2023 to 16.5 million in Q3 2023, due to updates to our proactive detection technology to improve accuracy.

[](https://transparency.fb.com/reports/community-standards-enforcement/spam/facebook/#restored-content)

prevalence
----------

How prevalent were spam violations?

We cannot estimate this metric right now. We are working on new methods to measure the prevalence of spam on Facebook. Our existing methods for measuring prevalence, which rely on people to manually review samples of content, do not fully capture this type of highly adversarial violation, which includes deceptive behavior as well as content. Spammy behavior cannot always be detected by reviewing the content alone. We are working on ways to review and classify spammers' behavior to build a comprehensive picture.

content actioned
----------------

How much spam content did we take action on?

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for spam. It includes both content we actioned after someone reported it, and content that we found proactively.

[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)

proactive rate
--------------

Of the violating content we actioned for spam, how much did we find and action before people reported it?

Found and actioned by us

Reported by users

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)

Correcting mistakes

People can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.

appealed content
----------------

How much of the content we actioned for spam did people appeal?

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)

restored content
----------------

How much actioned content for spam was later restored?

Restored without appeal

Restored after appeal

Total

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)

NOTE:

Due to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for spam. It includes both content we actioned after someone reported it, and content that we found proactively.

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Home](https://transparency.fb.com/)

[Data](https://transparency.fb.com/reports/)

[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)

Suicide and Self-Injury
=======================

We remove content that encourages suicide or self-injury on Facebook and Instagram. Self-injury is defined as the intentional and direct injuring of the body, including self-mutilation and eating disorders. We also remove content that identifies and negatively targets victims or survivors of self-injury or suicide.

We do allow people to discuss suicide and self-injury because we want Facebook and Instagram to be spaces where people can raise awareness about these issues and seek support.

[Read the policy details](https://transparency.fb.com/policies/community-standards/suicide-self-injury/)

Facebook

Facebook

Instagram

[Download (CSV)](https://transparency.fb.com/sr/community-standards/)

prevalence
----------

How prevalent were suicide and self-injury violations?

Views of violating content that contains suicide and self-injury are very infrequent, and we remove much of this content before people see it. As a result, many times we do not find enough violating samples to precisely estimate prevalence.

In Q3 2023, this was true for violations of our policies on suicide and self-injury, terrorism and restricted goods and services on Facebook and Instagram. In these cases, we can estimate an upper limit of how often someone would see content that violates these policies.

In Q3 2023, the upper limit was 0.05% for violations of our policy for suicide and self-injury on Facebook. This means that out of every 10,000 views of content on Facebook, we estimate no more than 5 of those views contained content that violated the policy.

content actioned
----------------

How much suicide and self-injury content did we take action on?

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for suicide and self injury. It includes both content we actioned after someone reported it, and content that we found proactively.

[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)

proactive rate
--------------

Of the violating content we actioned for suicide and self-injury, how much did we find and action before people reported it?

Found and actioned by us

Reported by users

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)

Correcting mistakes

People can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.

appealed content
----------------

How much of the content we actioned for suicide and self-injury did people appeal?

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)

restored content
----------------

How much actioned content for suicide and self-injury was later restored?

Restored without appeal

Restored after appeal

Total

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)

NOTE:

Due to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for suicide and self injury. It includes both content we actioned after someone reported it, and content that we found proactively.

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Home](https://transparency.fb.com/)

[Data](https://transparency.fb.com/reports/)

[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)

Violence and Incitement
=======================

We aim to prevent potential offline harm that may be related to content on Facebook. While we understand that people commonly edddxpress disdain or disagreement by threatening or calling for violence in non-serious ways, we remove language that incites or facilitates serious violence. We remove content, disable accounts and work with law enforcement when we believe there is a genuine risk of physical harm or direct threats to public safety. We also try to consider the language and context in order to distinguish casual statements from content that constitutes a credible threat to public or personal safety.

[Read the policy details](https://transparency.fb.com/policies/community-standards/violence-incitement/)

Facebook

Facebook

Instagram

[Download (CSV)](https://transparency.fb.com/sr/community-standards/)

Recent trends
-------------

Q3 2023
-------

8.6 million


-------------

Content Actioned on Violence and Incitement


---------------------------------------------

Content actioned decreased from 10.6 million in Q2 2023 to 8.6 million in Q3 2023, due to a decrease in content that violated our policies.

[](https://transparency.fb.com/reports/community-standards-enforcement/violence-incitement/facebook/#content-actioned)

Q3 2023
-------

97.3%


-------

Proactive Rate on Violence and Incitement


-------------------------------------------

Proactive rate increased from 85.1% in Q2 2023 to 97.3% in Q3 2023, due to an update in our calculation to the proactive rate.

[](https://transparency.fb.com/reports/community-standards-enforcement/violence-incitement/facebook/#proactive-rate)

Prevalence
----------

How prevalent were violence and incitement violations?

How we calculate it

Prevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.

[Read about this data](https://transparency.fb.com/policies/improving/prevalence-metric/)

Content Actioned
----------------

How much violence and incitement content did we take action on?

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for violence and incitement. It includes both content we actioned after someone reported it, and content that we found proactively.

[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)

Proactive Rate
--------------

Of the violating content we actioned for violence and incitement content, how much did we find and action before people reported it?

Found and actioned by us

Reported by users

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)

Correcting mistakes

People can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.

Appealed Content
----------------

How much of the content we actioned for violence and incitement content did people appeal?

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)

Restored Content
----------------

How much actioned content for violence and incitement content was later restored?

Restored without appeal

Restored after appeal

Total

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)

NOTE:

Due to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.

How we calculate it

Prevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for violence and incitement. It includes both content we actioned after someone reported it, and content that we found proactively.

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Home](https://transparency.fb.com/)

[Data](https://transparency.fb.com/reports/)

[Community Standards Enforcement Report](https://transparency.fb.com/reports/community-standards-enforcement/)

Violent and Graphic Content
===========================

We remove content that glorifies violence or celebrates the suffering or humiliation of others on Facebook and Instagram. We do allow people to share some graphic content to raise awareness about current events and issues. In these cases, we may hide the content from people under 18 and cover it with a warning for those over 18, so people are aware it is graphic or violent before they choose to view it.

[Read the policy details](https://transparency.fb.com/policies/community-standards/violent-graphic-content/)

Facebook

Facebook

Instagram

[Download (CSV)](https://transparency.fb.com/sr/community-standards/)

Recent trends
-------------

Q3 2023
-------

9 million


-----------

Content Actioned on Violent and Graphic Content


-------------------------------------------------

Content actioned decreased from 13.8 million in Q2 2023 to 9.0 million in Q3 2023, due to changes made to our enforcement systems.

[](https://transparency.fb.com/reports/community-standards-enforcement/graphic-violence/facebook/#content-actioned)

Q3 2023
-------

98.2%


-------

Proactive Rate on Violent and Graphic Content


-----------------------------------------------

Proactive rate increased from 97.5% in Q2 2023 to 98.2% in Q3 2023, due to an update in our calculation to the proactive rate.

[](https://transparency.fb.com/reports/community-standards-enforcement/graphic-violence/facebook/#proactive-rate)

prevalence
----------

How prevalent were violent and graphic content violations?

How we calculate it

Prevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.

[Read about this data](https://transparency.fb.com/policies/improving/prevalence-metric/)

content actioned
----------------

How much violent and graphic content did we take action on?

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for graphic violence. It includes both content we actioned after someone reported it, and content that we found proactively.

[Read about this data](https://transparency.fb.com/policies/improving/content-actioned-metric/)

proactive rate
--------------

Of the violating content we actioned for violent and graphic content, how much did we find and action before people reported it?

Found and actioned by us

Reported by users

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

[Read about this data](https://transparency.fb.com/policies/improving/proactive-rate-metric/)

Correcting mistakes

People can appeal our decisions, unless there are extreme safety concerns. We restore content we incorrectly removed or when circumstances change. Restores can happen from appeals or when we identify issues ourselves.

appealed content
----------------

How much of the content we actioned for violent and graphic content did people appeal?

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

[Read about this data](https://transparency.fb.com/policies/improving/appealed-content-metric/)

restored content
----------------

How much actioned content for violent and graphic content was later restored?

Restored without appeal

Restored after appeal

Total

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.

[Read about this data](https://transparency.fb.com/policies/improving/restored-content-metric/)

NOTE:

Due to a temporary reduction in our review capacity as a result of COVID-19, we could not always offer people the option to appeal. We still gave people the option to tell us they disagreed with our decision, which helped us review many of these instances and restore content when appropriate. Starting in Q2 2022, we [updated our methodology](https://transparency.fb.com/policies/improving/corrections-adjustments/) for how we count appeals to include all instances where content was submitted for additional review, including after people told us that they disagreed with our decision.

How we calculate it

Prevalence is the estimated number of views that showed violating content, divided by the estimated number of total content views on Facebook.

How we calculate it

Content actioned is the total number of pieces of content that Facebook took action on for graphic violence. It includes both content we actioned after someone reported it, and content that we found proactively.

How we calculate it

Proactive rate is the number of pieces of content acted on that we found and actioned before people using Facebook reported them, divided by the total number of pieces of content we took action on.

How we calculate it

Appealed content counts the number of pieces of content actioned which were submitted for another review during the reporting period.

How we calculate it

Restored content is the number of pieces of content that we restored during the reporting period after previously actioning it. We restore content both when it is appealed and when we discover issues ourselves.